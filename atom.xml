<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SolitudeAB</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2025-09-16T08:47:56.611Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>SolitudeAB</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>BN（Batch Normalization）</title>
    <link href="http://example.com/2025/09/16/BasicKnowledge/BN/"/>
    <id>http://example.com/2025/09/16/BasicKnowledge/BN/</id>
    <published>2025-09-15T16:00:00.000Z</published>
    <updated>2025-09-16T08:47:56.611Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、什么是BN？"><a href="#一、什么是BN？" class="headerlink" title="一、什么是BN？"></a>一、什么是BN？</h2><p>Batch Normalization是2015年一篇论文中提出的数据归一化方法，往往用在<a href="https://zhida.zhihu.com/search?content_id=108939343&amp;content_type=Article&amp;match_order=1&amp;q=深度神经网络&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTY4MTg4OTYsInEiOiLmt7HluqbnpZ7nu4_nvZHnu5wiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxMDg5MzkzNDMsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.M-vLAfUYEdeMRe-teHbY0cZxEn-nNIE13uAQl97QVaQ&amp;zhida_source=entity">深度神经网络</a>中激活层之前。其作用可以加快模型训练时的收敛速度，使得模型训练过程更加稳定，避免<a href="https://zhida.zhihu.com/search?content_id=108939343&amp;content_type=Article&amp;match_order=1&amp;q=梯度爆炸&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTY4MTg4OTYsInEiOiLmoq_luqbniIbngrgiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxMDg5MzkzNDMsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.LKgbtq6WIz8X1FEIaEZLQBtZ0UxDEbeD73aX8nyxz6o&amp;zhida_source=entity">梯度爆炸</a>或者<a href="https://zhida.zhihu.com/search?content_id=108939343&amp;content_type=Article&amp;match_order=1&amp;q=梯度消失&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTY4MTg4OTYsInEiOiLmoq_luqbmtojlpLEiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxMDg5MzkzNDMsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.hGcsgcZH-nro-FgPqHGgdqccFF-eMb0VqzUz12BWYEY&amp;zhida_source=entity">梯度消失</a>。并且起到一定的正则化作用，几乎代替了Dropout。</p><h2 id="二、BN核心公式是什么？"><a href="#二、BN核心公式是什么？" class="headerlink" title="二、BN核心公式是什么？"></a>二、BN核心公式是什么？</h2><p>如下：</p><script type="math/tex; mode=display">Input:B=\{x_{1...m}\};\gamma ,\beta (parameters\ to\ be\ learned)\\Output:\{y_i=BN_{\gamma ,\beta}(x_i)\}\\u_{B} \leftarrow\frac{1}{m}\sum_{i=1}^{m}{x_i}\\ \sigma_{B}^2\leftarrow\frac{1}{m}\sum_{i=1}^m(x_i-\mu_B)^2\\ \tilde{x}_i\leftarrow\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}\\ y_i\leftarrow\gamma\tilde{x}_i+\beta\\</script><p>解释一下上述公式：</p><ol><li>输入为数值集合（ $B$ ），可训练参数 $\gamma$、$\beta$ ；</li><li>BN的具体操作为：先计算 $B$ 的<a href="https://zhida.zhihu.com/search?content_id=108939343&amp;content_type=Article&amp;match_order=1&amp;q=均值&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTY4MTg4OTYsInEiOiLlnYflgLwiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxMDg5MzkzNDMsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.XdidcCMBb-J_HSIUeWNBTk0edzr527AA6yH-zeFLI8I&amp;zhida_source=entity">均值</a>和<a href="https://zhida.zhihu.com/search?content_id=108939343&amp;content_type=Article&amp;match_order=1&amp;q=方差&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTY4MTg4OTYsInEiOiLmlrnlt64iLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxMDg5MzkzNDMsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.eJy_gJpaZbBpuXV4ZjmFXJp0NoiDEu70WNtM9EHlyFc&amp;zhida_source=entity">方差</a>，之后将 $B$ 集合的均值、方差变换为0、1（对应上式中 ）$\tilde{x}_i\leftarrow\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}$，最后将 $B$  中每个元素乘以 $\gamma$ 再加 $\beta$，输出。 $\gamma$、$\beta$ 是可训练参数，参与整个网络的BP；</li><li>归一化的目的：将数据规整到统一区间，减少数据的发散程度，降低网络的学习难度。BN的精髓在于归一之后，使用 、 作为还原参数，在一定程度上保留原数据的分布。</li></ol><h2 id="三、BN中均值、方差通过哪些维度计算得到？"><a href="#三、BN中均值、方差通过哪些维度计算得到？" class="headerlink" title="三、BN中均值、方差通过哪些维度计算得到？"></a>三、BN中均值、方差通过哪些维度计算得到？</h2><p>神经网络中传递的张量数据，其维度通常记为[N, H, W, C]，其中N是batch_size，H、W是行、列，C是通道数。那么上式中BN的输入集合 就是下图中蓝色的部分。</p><p><img src="v2-73b3fe43dd4bc9e917ecc7d6cc7b5374_1440w-1756646213000-7.jpg" alt="img"></p><p>图一 BN输入维度示意图</p><p>均值的计算，就是在一个批次内，将每个通道中的数字单独加起来，再除以 。举个例子：该批次内有10张图片，每张图片有三个通道RBG，每张图片的高、宽是H、W，那么均值就是计算<strong>10张图片R通道的像素数值总和</strong>除以 ，再计算B通道全部像素值总和除以，最后计算G通道的像素值总和除以。方差的计算类似。</p><p>可训练参数 、 的维度等于<strong>张量的通道数</strong>，在上述例子中，RBG三个通道分别需要一个 和一个 ，所以 、 的维度等于3。</p><h2 id="四、训练与推理时BN中的均值、方差分别是什么？"><a href="#四、训练与推理时BN中的均值、方差分别是什么？" class="headerlink" title="四、训练与推理时BN中的均值、方差分别是什么？"></a>四、训练与推理时BN中的均值、方差分别是什么？</h2><p>此问题是BN争议最大之处，正确答案是：</p><p><strong>训练</strong>时，均值、方差分别是<strong>该批次</strong>内数据相应维度的均值与方差；</p><p><strong>推理</strong>时，均值、方差是<strong>基于所有批次</strong>的期望计算所得，公式如下：</p><p>其中 表示 x 的期望。</p><p>为了证明正确性，贴上原论文中的公式：</p><p><img src="v2-a0006ca492615897231c878770b9416a_1440w-1756646213000-9.jpg" alt="img"></p><p>图二 BN在训练与推理中的详细计算步骤</p><h2 id="五、在tensorflow中如何实现BN？"><a href="#五、在tensorflow中如何实现BN？" class="headerlink" title="五、在tensorflow中如何实现BN？"></a>五、在tensorflow中如何实现BN？</h2><p>如果使用tensorflow的slim框架，BN就已经集成在内了，直接打开相应的参数即可。如果调用tf.nn.batch_normalization这个接口，那么需要自己在外部做一些事。</p><p>下述代码是基于tf.nn.batch_normalization封装好的BN函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.python.training import moving_averages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def batch_normalization(input, is_training, name=&quot;BN&quot;, </span><br><span class="line">                        moving_decay=0.999, eps=1e-5):</span><br><span class="line">    input_shape = input.get_shape()</span><br><span class="line">    params_shape = input_shape[-1]</span><br><span class="line">    axis = list(range(len(input_shape) - 1))</span><br><span class="line">    with tf.variable_scope(name, reuse=tf.AUTO_REUSE) as scope:</span><br><span class="line">        beta = tf.get_variable(&#x27;beta&#x27;,</span><br><span class="line">                               params_shape,</span><br><span class="line">                               initializer=tf.zeros_initializer)</span><br><span class="line">        gamma = tf.get_variable(&#x27;gamma&#x27;,</span><br><span class="line">                                params_shape,</span><br><span class="line">                                initializer=tf.ones_initializer)</span><br><span class="line">        moving_mean = tf.get_variable(&#x27;moving_mean&#x27;,</span><br><span class="line">                                      params_shape,</span><br><span class="line">                                      initializer=tf.zeros_initializer,</span><br><span class="line">                                      trainable=False</span><br><span class="line">                                      )</span><br><span class="line">        moving_var = tf.get_variable(&#x27;moving_var&#x27;,</span><br><span class="line">                                     params_shape,</span><br><span class="line">                                     initializer=tf.ones_initializer,</span><br><span class="line">                                     trainable=False</span><br><span class="line">                                     )</span><br><span class="line">        def train():</span><br><span class="line">            # These ops will only be preformed when training.</span><br><span class="line">            mean, var = tf.nn.moments(input, axis)</span><br><span class="line">            update_moving_mean = moving_averages.assign_moving_average(moving_mean,</span><br><span class="line">                                                                       mean, </span><br><span class="line">                                                                       moving_decay)</span><br><span class="line">            update_moving_var = moving_averages.assign_moving_average(</span><br><span class="line">                moving_var, var, moving_decay)</span><br><span class="line">            return tf.identity(mean), tf.identity(var)</span><br><span class="line"></span><br><span class="line">        mean, var = tf.cond(tf.equal(is_training, True), train,</span><br><span class="line">                                 lambda: (moving_mean, moving_var))</span><br><span class="line"></span><br><span class="line">        return tf.nn.batch_normalization(input, mean, var, beta, gamma, eps)</span><br></pre></td></tr></table></figure><p>在代码实现中有一个技巧，如果训练几百万个Batch，那么是不是要将其均值方差全部储存，最后再计算推理时所用的均值和方差？这样显然太过笨拙，占用内存随着训练次数不断上升。为了避免该问题，上述代码使用了<strong><a href="https://zhida.zhihu.com/search?content_id=108939343&amp;content_type=Article&amp;match_order=1&amp;q=滑动平均&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTY4MTg4OTYsInEiOiLmu5HliqjlubPlnYciLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxMDg5MzkzNDMsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.QSTMRXJkRRMENClrEOZfgqQLYtH9aA8ie4iNbf5iRI0&amp;zhida_source=entity">滑动平均</a></strong>，储存固定个数Batch的均值和方差，不断迭代更新推理时需要的 与 。</p><p>注意到代码中：</p><ol><li>beta、gamma在训练状态下，是<strong>可训练参数</strong>，在推理状态下，直接加载训练好的数值。</li><li>moving_mean、moving_var在训练、推理中都是<strong>不可训练参数</strong>，只根据滑动平均计算公式更新数值，不会随着网络的训练BP而改变数值；在推理时，直接加载储存计算好的滑动平均之后的数值，作为推理时的均值和方差。</li></ol><h2 id="六、在网络中使用了BN，效果如何？"><a href="#六、在网络中使用了BN，效果如何？" class="headerlink" title="六、在网络中使用了BN，效果如何？"></a>六、在网络中使用了BN，效果如何？</h2><p>BN目前仍然是一个黑盒，论文中有一定的理论推导，但是普遍还是通过对比提升来验证BN的效果。原作者给出的效果如下图：</p><p><img src="v2-0a9861c516dbb2fe19d48ca8b2bb87ee_1440w-1756646213000-11.jpg" alt="img"></p><p>图三 正确率（纵坐标）与训练步数（横坐标）</p><p>上图可见BN的两大收益：</p><ul><li>收敛速率增加</li><li>可以达到更好的精度</li></ul><p>在目标检测算法中，BN已经成为了标配。比如<a href="https://zhida.zhihu.com/search?content_id=108939343&amp;content_type=Article&amp;match_order=1&amp;q=Yolov3&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTY4MTg4OTYsInEiOiJZb2xvdjMiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxMDg5MzkzNDMsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.hByX6q7IbxFogowlsv9yMDennoZ10s6QADHUrspsbvk&amp;zhida_source=entity">Yolov3</a>引入了BN后，mAP提升了两个百分点。在更多实验中可以看到，BN同时起到了正则化作用，防止模型在训练集上过拟合，通常有BN的网络不再需要Dropout层。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>论文链接：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></p><p>更多归一化方法：<a href="https://zhuanlan.zhihu.com/p/72589565">BN、LN、IN、GN</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、什么是BN？&quot;&gt;&lt;a href=&quot;#一、什么是BN？&quot; class=&quot;headerlink&quot; title=&quot;一、什么是BN？&quot;&gt;&lt;/a&gt;一、什么是BN？&lt;/h2&gt;</summary>
    
    
    
    <category term="基础知识" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
    <category term="神经网络" scheme="http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Week7</title>
    <link href="http://example.com/2025/09/16/LearningSchedule/Week7/"/>
    <id>http://example.com/2025/09/16/LearningSchedule/Week7/</id>
    <published>2025-09-15T16:00:00.000Z</published>
    <updated>2025-09-16T08:47:56.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="三、Dilated-Convolution膨胀卷积（空洞卷积）"><a href="#三、Dilated-Convolution膨胀卷积（空洞卷积）" class="headerlink" title="三、Dilated Convolution膨胀卷积（空洞卷积）"></a>三、Dilated Convolution膨胀卷积（空洞卷积）</h1><h3 id="（一）膨胀卷积和一般卷积的区别"><a href="#（一）膨胀卷积和一般卷积的区别" class="headerlink" title="（一）膨胀卷积和一般卷积的区别"></a>（一）膨胀卷积和一般卷积的区别</h3><p><img src="image-20250828120139433.png" alt="image-20250828120139433"></p><p>r是普通卷积和空洞卷积的差别所在，我们称之为<strong>膨胀因子</strong>。当r=1时，表示卷积核各元素之前没有空隙，即相邻两个元素间位置相差1，此时其实就是我们正常的卷积，所以广义上说，普通的卷积是一种特殊的空洞卷积；当r=2时，表示卷积核各元素之前有一个空隙，即相邻两个元素间位置相差2，此时就是我们上图中的卷积核，为方便大家理解，我把上图r=2时的卷积核提取出来，如下图所示：</p><p><img src="3f109228860742978c8bd0a4709370fftplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220826220545773"></p><p>当然了当r=3、r=4都是同样的道理，这里就不过多叙述了。</p><h3 id="（二）为什么使用膨胀卷积？"><a href="#（二）为什么使用膨胀卷积？" class="headerlink" title="（二）为什么使用膨胀卷积？"></a>（二）为什么使用膨胀卷积？</h3><p>在语言分割任务当中，通常会使用分类网络作为网络的 <strong>backbone</strong><sup><a href="#fn_1" id="reffn_1">1</a></sup> 。</p><p>首先，通过backbone，将我们的图片进行一系列的下采样，然后再通过一系列的上采样还原我们原图的大小。平常在使用图像分类网络中，我们一般会将我们的高度和宽度下采样32倍。由于后续我们需要通过上采用还原回原图的尺寸，所以如果我们将特征图的高宽下采样倍率调的太大的话，对我们还原原因的影响是很大的。比如 <strong>VGG网络</strong>，它是通过最大池化下采样，即maxpooling层进行池化操作的。通过maxpooling操作之后，首先会降低特征图或者特征层的高度和宽度。其次，最大池化会丢失一些细节信息记忆一些比较小的目标，导致无法通过后续的上采样进行还原，造成语义分割中分割的效果不是特别的理想。</p><p><strong>简单粗暴的去掉最大池化下采样层？</strong></p><p>这会导致得到特征图对应原图的感受野变小（因为最大池化下采样层是能够增大图层的感受野的），而对于最大池化下采样层之后的一系列卷积层又是在之前所对应的感受野之上进一步的操作。如果简单粗暴的去掉最大池化下采样层，肯定会后面的卷积层也会带来一定的问题。</p><p>因此，需要使用到膨胀卷积。</p><p><strong>优势</strong>：既能增大感受野，有你保持输入输出特征矩阵或特征图的高和宽不会发生变化</p><p>那么，是不是只要在语义分割任务当中简单粗暴的堆叠膨胀卷积层就可以？很明显不是</p><h3 id="（三）膨胀卷积的缺点"><a href="#（三）膨胀卷积的缺点" class="headerlink" title="（三）膨胀卷积的缺点"></a>（三）膨胀卷积的缺点</h3><p>在使用膨胀卷积的过程中经常会遇到一个名为 <strong>gridding effect</strong><sup><a href="#fn_2" id="reffn_2">2</a></sup> 的问题</p><p><img src="image-20250828121841132.png" alt="image-20250828121841132"></p><p><strong>gridding effect</strong></p><ol><li><p>膨胀系数均为2</p><p><img src="image-20250828151504404.png" alt="image-20250828151504404"></p><ul><li><p>Layer4 上的 pixel 利用的Layer1的数据并不是连续的，每个非零元素之间都有一定的间隔</p></li><li><p>Layer4 上的像素并没有利用到范围内所有的像素值，而是利用到了期间的一部分，这样肯定会导致缺失一些细节上的信息</p></li></ul></li><li><p>膨胀系数分别为1，2，3</p><p><img src="image-20250828151932930.png" alt="image-20250828151932930"></p><ul><li>Layer4 利用到了13 * 13 像素的参数，且这些参数间是相邻的</li><li>该实验的卷积核和膨胀卷积均为2的尺寸是一样的，参数一样的，只不过膨胀系数是不一样的</li><li>该图的视野和膨胀卷积均为2的一样，不过膨胀卷积均为2的很多像素并没有利用到，所以更倾向于使用膨胀系数分别为1，2，3。</li><li>如此对于高层的pixel而言，使用到的低层的数据是一个<strong>连续</strong>的区域</li></ul></li><li><p>全部用普通卷积，即膨胀系数全部为1</p><p><img src="image-20250828202706685.png" alt="image-20250828202706685"></p><ul><li>在参数数量相同的情况下，很明显使用了膨胀卷积之后的感受野增大了很多，从7 <em> 7（全部普通卷积） 变成了13 </em> 13（有膨胀卷积，不过根据设置的不用，像素的利用率也不同）</li></ul></li></ol><h3 id="（四）常见的Hybrid-Dilated-Convolution-HDC-膨胀因子的设计准则"><a href="#（四）常见的Hybrid-Dilated-Convolution-HDC-膨胀因子的设计准则" class="headerlink" title="（四）常见的Hybrid Dilated Convolution (HDC)膨胀因子的设计准则"></a>（四）常见的Hybrid Dilated Convolution (HDC)膨胀因子的设计准则</h3><h4 id="建议一："><a href="#建议一：" class="headerlink" title="建议一："></a>建议一：</h4><p>根据前面几次的实验可以轻松得到，第二次实验中膨胀系数为1，2，3的膨胀卷积得到的效果比最开始采用三个系数均为2的膨胀卷积的效果要更好，因为引出合理的膨胀系数——<strong>Hybrid Dilated Convolution(HDC)。</strong></p><p><img src="image-20250828203604250.png" alt="image-20250828203604250"></p><p>假设堆叠n个膨胀卷积，每个卷积核都是 <script type="math/tex">k * k</script>，如何每一个膨胀卷积的膨胀系数分别对应 <script type="math/tex">r_1</script> 到  <script type="math/tex">r_n</script> 。这里的HDC目标其实就是通过一系列膨胀卷积在之后，是能够完全覆盖底层特征层的一个方形区域的，而且这个方形区域没有任何的孔洞。定义为 <strong>“maximum distance between two nonzero values”</strong> 。（即先前实验图示当中非零元素距离为一的，就是没有间隔一列或行零元素）。</p><p>因为希望在高层特征层当中的一个pixel利用到底层整个区域的所有像素的话，<strong>$M_1$应该要等于1</strong>（意味着非零元素之间没有间隙）。因为$M_1$是三个数中取最大，那么$M_1$应该大于或等于$r_1$，所以$r_1$要从1开始。</p><p>$M_i$：表示对应第$i$层两非零元素之间的最大距离</p><p>$r_i$：对应的是第$i$层的膨胀系数</p><p>$M_n$：表示最后一次非零元素之间的最大距离等于2n</p><h5 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h5><ol><li><p><code>dilated_rates = [1, 2, 5]</code></p><ul><li><p><strong>统计实验像素的代码</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from matplotlib.colors import LinearSegmentedColormap</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dilated_conv_one_pixel(center: (int, int),</span><br><span class="line">                           feature_map: np.ndarray,</span><br><span class="line">                           k: int = 3,</span><br><span class="line">                           r: int = 1,</span><br><span class="line">                           v: int = 1):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    膨胀卷积核中心在指定坐标center处时，统计哪些像素被利用到，</span><br><span class="line">    并在利用到的像素位置处加上增量v</span><br><span class="line">    Args:</span><br><span class="line">        center: 膨胀卷积核中心的坐标</span><br><span class="line">        feature_map: 记录每个像素使用次数的特征图</span><br><span class="line">        k: 膨胀卷积核的kernel大小</span><br><span class="line">        r: 膨胀卷积的dilation rate</span><br><span class="line">        v: 使用次数增量</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    assert divmod(3, 2)[1] == 1</span><br><span class="line"></span><br><span class="line">    # left-top: (x, y)</span><br><span class="line">    left_top = (center[0] - ((k - 1) // 2) * r, center[1] - ((k - 1) // 2) * r)</span><br><span class="line">    for i in range(k):</span><br><span class="line">        for j in range(k):</span><br><span class="line">            feature_map[left_top[1] + i * r][left_top[0] + j * r] += v</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dilated_conv_all_map(dilated_map: np.ndarray,</span><br><span class="line">                         k: int = 3,</span><br><span class="line">                         r: int = 1):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    根据输出特征矩阵中哪些像素被使用以及使用次数，</span><br><span class="line">    配合膨胀卷积k和r计算输入特征矩阵哪些像素被使用以及使用次数</span><br><span class="line">    Args:</span><br><span class="line">        dilated_map: 记录输出特征矩阵中每个像素被使用次数的特征图</span><br><span class="line">        k: 膨胀卷积核的kernel大小</span><br><span class="line">        r: 膨胀卷积的dilation rate</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    new_map = np.zeros_like(dilated_map)</span><br><span class="line">    for i in range(dilated_map.shape[0]):</span><br><span class="line">        for j in range(dilated_map.shape[1]):</span><br><span class="line">            if dilated_map[i][j] &gt; 0:</span><br><span class="line">                dilated_conv_one_pixel((j, i), new_map, k=k, r=r, v=dilated_map[i][j])</span><br><span class="line"></span><br><span class="line">    return new_map</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot_map(matrix: np.ndarray):</span><br><span class="line">    plt.figure()</span><br><span class="line"></span><br><span class="line">    c_list = [&#x27;white&#x27;, &#x27;blue&#x27;, &#x27;red&#x27;]</span><br><span class="line">    new_cmp = LinearSegmentedColormap.from_list(&#x27;chaos&#x27;, c_list)</span><br><span class="line">    plt.imshow(matrix, cmap=new_cmp)</span><br><span class="line"></span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    ax.set_xticks(np.arange(-0.5, matrix.shape[1], 1), minor=True)</span><br><span class="line">    ax.set_yticks(np.arange(-0.5, matrix.shape[0], 1), minor=True)</span><br><span class="line"></span><br><span class="line">    # 显示color bar</span><br><span class="line">    plt.colorbar()</span><br><span class="line"></span><br><span class="line">    # 在图中标注数量</span><br><span class="line">    thresh = 5</span><br><span class="line">    for x in range(matrix.shape[1]):</span><br><span class="line">        for y in range(matrix.shape[0]):</span><br><span class="line">            # 注意这里的matrix[y, x]不是matrix[x, y]</span><br><span class="line">            info = int(matrix[y, x])</span><br><span class="line">            ax.text(x, y, info,</span><br><span class="line">                    verticalalignment=&#x27;center&#x27;,</span><br><span class="line">                    horizontalalignment=&#x27;center&#x27;,</span><br><span class="line">                    color=&quot;white&quot; if info &gt; thresh else &quot;black&quot;)</span><br><span class="line">    ax.grid(which=&#x27;minor&#x27;, color=&#x27;black&#x27;, linestyle=&#x27;-&#x27;, linewidth=1.5)</span><br><span class="line">    plt.show()</span><br><span class="line">    plt.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    # bottom to top</span><br><span class="line">    dilated_rates = [1, 2, 3]</span><br><span class="line">    # init feature map</span><br><span class="line">    size = 31</span><br><span class="line">    m = np.zeros(shape=(size, size), dtype=np.int32)</span><br><span class="line">    center = size // 2</span><br><span class="line">    m[center][center] = 1</span><br><span class="line">    # print(m)</span><br><span class="line">    # plot_map(m)</span><br><span class="line"></span><br><span class="line">    for index, dilated_r in enumerate(dilated_rates[::-1]):</span><br><span class="line">        new_map = dilated_conv_all_map(m, r=dilated_r)</span><br><span class="line">        m = new_map</span><br><span class="line">    print(m)</span><br><span class="line">    plot_map(m)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></li><li><p><strong>执行效果</strong>：</p><p><img src="image-20250828210735163.png" alt="image-20250828210735163"></p></li><li><p>解析：</p><p>很明显，已经将整个区域当中的所有的像素都利用到了，即不存在 gridding effect 的我呢提</p></li></ul></li><li><p><code>dilated_rates = [1, 2, 9]</code></p><ul><li><p>效果</p><p><img src="image-20250828211147137.png" alt="image-20250828211147137"></p></li><li><p>解析</p><p>很明显在整个区域内，非零元素之间的最大距离应该等于3，即元素与元素之间有两个或者两列零</p></li></ul></li></ol><h4 id="建议二："><a href="#建议二：" class="headerlink" title="建议二："></a>建议二：</h4><p><img src="image-20250828211918136.png" alt="image-20250828211918136"></p><p>但是以下情况仍存在gridding effect效应：</p><p><img src="image-20250828212114344.png" alt="image-20250828212114344"></p><p>实例：<code>dilated_rates = [2, 4, 8]</code></p><p><img src="image-20250828212212906.png" alt="image-20250828212212906"></p><p>可见非零元素之间还是存在零的，即高层当中依然没有使用到第一层当中的部分信息，故而这种情况是不行的。</p><h3 id="（五）效果对比"><a href="#（五）效果对比" class="headerlink" title="（五）效果对比"></a>（五）效果对比</h3><p><img src="image-20250828212417327.png" alt="image-20250828212417327"></p><h2 id="四、U-Net网络结构讲解（语义分割）"><a href="#四、U-Net网络结构讲解（语义分割）" class="headerlink" title="四、U-Net网络结构讲解（语义分割）"></a>四、U-Net网络结构讲解（语义分割）</h2><blockquote><p>论文地址：<a href="https://arxiv.org/abs/1505.04597">https://arxiv.org/abs/1505.04597</a></p></blockquote><p><img src="image-20250829122819822.png" alt="image-20250829122819822"></p><h3 id="结构图示"><a href="#结构图示" class="headerlink" title="结构图示"></a>结构图示</h3><p><img src="image-20250831211132316.png" alt="image-20250831211132316"></p><ul><li>Encoder：U形左半部分（contracting path），特征提取以及下采样的部分</li><li>Decoder：U形右半部分（expansive path），解码以及通过上采样得到最终的分割图的分割图</li><li>图中每一个长条都表示一个特征层，箭头表示一种操作（图示右下角有标注箭头对应的操作类型）</li></ul><h3 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h3><ul><li><p>输入为572 * 572 的单通道图片</p></li><li><p>首先通过卷积核为3 <em> 3、激励函数为ReLU、步距为1、没有进行 padding 的卷积层，此后图像的高和宽都会减少，（572 </em> 572）-&gt;（570 <em> 570）- &gt;（568 </em> 568）</p></li></ul><blockquote id="fn_1"><sup>1</sup>. 指的是提取特征的网络，其作用就是提取图片中的信息，共后面的网络使用。这些网络经常使用的是resnet、VGG等，而不是我们自己设计的网络，因为这些网络已经证明了在分类等问题上的特征提取能力是很强的。在用这些网络作为backbone的时候，都是直接加载官方已经训练好的模型参数，后面接着我们自己的网络。让网络的这两个部分同时进行训练，因为加载的backbone模型已经具有提取特征的能力了，在我们的训练过程中，会对他进行微调，使得其更适合于我们自己的任务。<a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a></blockquote><blockquote id="fn_2"><sup>2</sup>. Understanding Convolution for Semantic Segmentation<a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a></blockquote><p><a href="https://zhuanlan.zhihu.com/p/93643523">【基础算法】六问透彻理解BN(Batch Normalization） - 知乎</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;三、Dilated-Convolution膨胀卷积（空洞卷积）&quot;&gt;&lt;a href=&quot;#三、Dilated-Convolution膨胀卷积（空洞卷积）&quot; class=&quot;headerlink&quot; title=&quot;三、Dilated Convolution膨胀卷积（空洞卷积）&quot;&gt;&lt;/a&gt;三、Dilated Convolution膨胀卷积（空洞卷积）&lt;/h1&gt;</summary>
    
    
    
    <category term="504医学AI" scheme="http://example.com/categories/504%E5%8C%BB%E5%AD%A6AI/"/>
    
    
    <category term="504医学AI入门" scheme="http://example.com/tags/504%E5%8C%BB%E5%AD%A6AI%E5%85%A5%E9%97%A8/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络基础</title>
    <link href="http://example.com/2025/09/16/BasicKnowledge/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"/>
    <id>http://example.com/2025/09/16/BasicKnowledge/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</id>
    <published>2025-09-15T16:00:00.000Z</published>
    <updated>2025-09-16T08:47:56.613Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><ol><li>卷积神经网络</li><li>全连接层</li><li>卷积层</li><li>池化层</li></ol><h1 id="一、卷积神经网络"><a href="#一、卷积神经网络" class="headerlink" title="一、卷积神经网络"></a>一、卷积神经网络</h1><h2 id="（一）CNN（Convolutional-Neural-NetWork）"><a href="#（一）CNN（Convolutional-Neural-NetWork）" class="headerlink" title="（一）CNN（Convolutional Neural NetWork）"></a>（一）CNN（Convolutional Neural NetWork）</h2><p>卷积神经网络：所有包含了卷积层的网络</p><p><img src="image-20250829125056575.png" alt="image-20250829125056575"></p><ul><li>雏形：LeCun 的 LeNet（1998）的网络结构（卷积神经网络发展史中的第一个卷积神经网络）</li></ul><h2 id="（二）卷积神经网络（CNN）的发展史"><a href="#（二）卷积神经网络（CNN）的发展史" class="headerlink" title="（二）卷积神经网络（CNN）的发展史"></a>（二）卷积神经网络（CNN）的发展史</h2><p><img src="image-20250829125736805.png" alt="image-20250829125736805"></p><h2 id="（三）卷积神经网络（CNN）的应用"><a href="#（三）卷积神经网络（CNN）的应用" class="headerlink" title="（三）卷积神经网络（CNN）的应用"></a>（三）卷积神经网络（CNN）的应用</h2><ol><li><strong>图像分类</strong></li><li><strong>图像检索</strong></li><li><strong>目标检测</strong></li><li><strong>图像分割</strong></li><li><strong>无人驾驶</strong></li><li><strong>图像描述</strong></li><li><strong>图像风格迁移</strong></li></ol><p><img src="image-20250829125937831.png" alt="image-20250829125937831"></p><p><img src="image-20250829125948555.png" alt="image-20250829125948555"></p><p><img src="image-20250829130854396.png" alt="image-20250829130854396"></p><p><img src="image-20250829130935732.png" alt="image-20250829130935732"></p><p><img src="image-20250829131010931.png" alt="image-20250829131010931"></p><h1 id="二、全连接层"><a href="#二、全连接层" class="headerlink" title="二、全连接层"></a>二、全连接层</h1><h2 id="（一）BP（back-propagation）算法"><a href="#（一）BP（back-propagation）算法" class="headerlink" title="（一）BP（back propagation）算法"></a>（一）BP（back propagation）算法</h2><p><img src="image-20250829131325672.png" alt="image-20250829131325672"></p><p>BP（back propagation）算法包括<strong>信号的前向传播</strong>和<strong>误差的反向传播</strong>两个过程。即计算误差输出时按从输入到输出的方向进行，而调整权值和阈值则从输出到输入的方向进行。</p><ul><li>信号从左到右的正向传播过程中能够得到一个输出值，然后将输出值和我们所期望得到的输出值进行对比得到误差值</li><li>通过计算每一个节点的偏导数，计算得到每个节点的误差梯度</li><li>将得到的损失值反向应用到损失梯度上，就达到了误差的反向传播</li></ul><h2 id="（二）实例：利用BP神经网络左车牌数字识别"><a href="#（二）实例：利用BP神经网络左车牌数字识别" class="headerlink" title="（二）实例：利用BP神经网络左车牌数字识别"></a>（二）实例：利用BP神经网络左车牌数字识别</h2><p><img src="image-20250829132722909.png" alt="image-20250829132722909"></p><h3 id="1、输入层"><a href="#1、输入层" class="headerlink" title="1、输入层"></a>1、输入层</h3><p><strong>图片的读取与转换</strong></p><p><img src="image-20250829132855841.png" alt="image-20250829132855841"></p><ol><li>首先，读入一张彩色的RGB图像，可以看到每个像素中都有三个值，即RGB分量</li><li>对图像进行灰度化，得到中间的图像，此时每个像素值只有一个分类了</li><li>二值化处理，得到黑白图像</li></ol><p><strong>滑动窗口（卷积核）</strong></p><p><img src="image-20250829133227813.png" alt="image-20250829133227813"></p><ol><li>用 5行3列 的窗口在整个图像上进行滑动，每滑动到一个地方就计算白色像素占整个像素的一个比例</li><li>如果窗口滑动时越界，可以再边界补一行或列的零，或者提前判断是否越界，然后改变窗口大小即可</li><li>得到一个 5 * 5 大小的矩阵</li></ol><p><strong>处理结果矩阵得到输入层</strong></p><p><img src="image-20250829164516588.png" alt="image-20250829164516588"></p><ol><li>将5 * 5 大小的矩阵按行展开得到一个一行25列的的行向量</li><li>将得到的行向量当成输入神经网络的一个输入层</li></ol><h3 id="2、输出层"><a href="#2、输出层" class="headerlink" title="2、输出层"></a>2、输出层</h3><p><strong>one-hot 编码</strong>：是常见的一种对标签进行编码的方式</p><p><img src="image-20250829164844035.png" alt="image-20250829164844035"></p><h3 id="3、网络训练"><a href="#3、网络训练" class="headerlink" title="3、网络训练"></a>3、网络训练</h3><p>有了输入和期望的输出，就能对网络进行训练</p><p><img src="image-20250829165110582.png" alt="image-20250829165110582"></p><ul><li>在实际的训练过程中，我们可以将输入层节点数设为25个节点，输出层的基数设为10个节点，中间的隐层可以按情况进行设置，这样就可以完整的对神经网络进行设置了</li></ul><h1 id="三、卷积层"><a href="#三、卷积层" class="headerlink" title="三、卷积层"></a>三、卷积层</h1><blockquote><p> CNN中独特的网络结构</p></blockquote><h3 id="一维卷积计算过程"><a href="#一维卷积计算过程" class="headerlink" title="一维卷积计算过程"></a>一维卷积计算过程</h3><p><div><table frame="void">    <!--用了<div>进行封装-->    <tr>        <td><div><center>    <!--每个格子内是图片加标题-->            <img src="%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-08-29%20165724.png" alt height="300">    <!--高度设置-->            <br>    <!--换行-->                <!--标题1-->        </center></div>&lt;/td&gt;<br>         </td><td><div><center>    <!--第二张图片--><br>            <img src="image-20250829165711894.png" alt height="300"><br>            <br></center></div></td></tr></table></div></p><ul><li>把卷积核覆盖到要计算的特征层上，将卷积核上的值与特征层上的值进行相乘，然后再进行相加，就得到了结果中的一个值</li><li>每滑动一步计算一个值</li><li>全部值摆成一个矩阵，就是最后的卷积计算结果了</li></ul><h3 id="卷积的目的"><a href="#卷积的目的" class="headerlink" title="卷积的目的"></a>卷积的目的</h3><p>进行图像的特征提取</p><h3 id="卷积特性"><a href="#卷积特性" class="headerlink" title="卷积特性"></a>卷积特性</h3><p><img src="image-20250829170655717.png" alt="image-20250829170655717"></p><ol><li>拥有<strong>局部感知</strong>机制：因为是卷积以滑动窗口的形式在要计算的特征层上滑动计算</li><li><strong>权值共享</strong>：在滑动计算过程中，卷积核的值不会发生变化</li></ol><h3 id="卷积优势——权值共享"><a href="#卷积优势——权值共享" class="headerlink" title="卷积优势——权值共享"></a>卷积优势——权值共享</h3><p> <img src="image-20250829170935266.png" alt="image-20250829170935266"></p><p><strong>普通网络和卷积网络神经元的个数是如何确定的？</strong></p><h3 id="多维特征矩阵的卷积计算"><a href="#多维特征矩阵的卷积计算" class="headerlink" title="多维特征矩阵的卷积计算"></a>多维特征矩阵的卷积计算</h3><p><img src="image-20250829171606715.png" alt="image-20250829171606715"></p><ul><li>输入有RGB三分量的彩色图片</li><li>卷积核需要与输出特征矩阵深度分别对应的深度保持一致</li><li>将卷积核的每一个维度放到对应的维度上进行滑动卷积</li><li>最后将各个维度的卷积结果进行求和操作得到一个卷积层</li><li>再利用卷积核2对输入特征层进行卷积并得到另一个输出矩阵</li><li>将输出特征矩阵进行拼接，就得到了整个输出的特征矩阵</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>卷积核的 channel 与输入特征层的 channel 相同</li><li>输出的特征矩阵 channel 与卷积核个数相同</li></ol><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><ol><li><p>加上<strong>偏移量bias</strong>该如何计算?</p><p>将卷积计算结果的各个值加上偏移量即可</p></li><li><p>加上<strong>激活函数</strong>该如何计算?</p><p><img src="image-20250829172044129.png" alt="image-20250829172044129"></p><ul><li>计算过程是线性计算过程，所以需要引入非线性因素</li><li>再反向传播误差的过程中，经过 sigmoid 激励函数的结果求导起来很复杂，而 Relu 激励函数求导方便，俩各有优缺点</li><li><strong>Relu 激励函数的缺点？？</strong></li><li>在训练过程中建议不要一开始就使用特别大的学习率，因为这样很可能会导致很多神经元失活</li></ul></li><li><p>如果卷积过程中出现越界的情况该怎么办?</p><ul><li>补零</li></ul><p><img src="image-20250829173019479.png" alt="image-20250829173019479"></p><ul><li>图中卷积后的矩阵大小：$(4 - 3 + 1) / 2 + 1 = 2$</li><li>P：一般 padding 是两边同时的，但是图示只 padding 了右和下，所以P=1</li></ul></li></ol><h1 id="四、池化层"><a href="#四、池化层" class="headerlink" title="四、池化层"></a>四、池化层</h1><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><p>对特征层进行稀疏处理，减少数据运算量</p><h3 id="MaxPooling-下采样层"><a href="#MaxPooling-下采样层" class="headerlink" title="MaxPooling 下采样层"></a>MaxPooling 下采样层</h3><p><img src="image-20250831174411351.png" alt="image-20250831174411351"></p><h3 id="AveragePooling-下采样层"><a href="#AveragePooling-下采样层" class="headerlink" title="AveragePooling 下采样层"></a>AveragePooling 下采样层</h3><p><img src="image-20250831174248835.png" alt="image-20250831174248835"></p><h3 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h3><ol><li><strong>没有训练参数</strong>（卷积层中的卷积核是有参数的），池化只需要在原始的特征层上求最大值或者平均数</li><li><strong>只改变特征矩阵的宽度（w）和高度（h），不改变深度（channel）</strong></li><li><strong>一般池化和大小和（poolsize）和步距（stride）是相同的</strong></li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h1&gt;</summary>
    
    
    
    <category term="基础知识" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
    <category term="神经网络" scheme="http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>卷积</title>
    <link href="http://example.com/2025/09/16/BasicKnowledge/%E5%8D%B7%E7%A7%AF/"/>
    <id>http://example.com/2025/09/16/BasicKnowledge/%E5%8D%B7%E7%A7%AF/</id>
    <published>2025-09-15T16:00:00.000Z</published>
    <updated>2025-09-16T08:47:56.612Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、线性滤波与卷积的基本概念"><a href="#一、线性滤波与卷积的基本概念" class="headerlink" title="一、线性滤波与卷积的基本概念"></a>一、线性滤波与卷积的基本概念</h2><p><strong>线性滤波</strong>可以说是图像处理最基本的方法，它可以允许我们对图像进行处理，产生很多不同的效果。做法很简单：</p><p>首先，我们有一个二维的<strong>滤波器矩阵</strong>（有个高大上的名字叫<strong>卷积核</strong>）和一个要处理的二维图像。然后，对于图像的每一个像素点，计算它的邻域像素和<strong>滤波器矩阵</strong>的<strong>对应元素的乘积</strong>，然后加起来，作为该像素位置的值。这样就完成了滤波过程。</p><p><img src="Center.png" alt="img"></p><p>对图像和滤波矩阵进行逐个元素相乘再求和的操作就相当于将一个二维的函数移动到另一个二维函数的所有位置，这个操作就叫<strong>卷积</strong>或者<strong>协相关</strong>。卷积和协相关的<strong>差别</strong>是，<strong>卷积需要先对滤波矩阵进行180的翻转</strong>，但如果矩阵是对称的，那么两者就没有什么差别了。</p><p>Correlation（协相关）和 Convolution（卷积）可以说是图像处理最基本的操作，但却非常有用。这两个操作有两个非常关键的特点：它们是线性的，而且具有平移不变性shift-invariant。平移不变性指我们在图像的每个位置都执行相同的操作。线性指这个操作是线性的，也就是我们用每个像素的邻域的线性组合来代替这个像素。这两个属性使得这个操作非常简单，因为线性操作是最简单的，然后在所有地方都做同样的操作就更简单了。</p><p>实际上，在信号处理领域，卷积有广泛的意义，而且有其严格的数学定义，但在这里不关注这个。</p><p>2D卷积需要4个嵌套循环4-double loop，所以它并不快，除非我们使用很小的卷积核。这里一般使用3x3或者5x5。而且，对于滤波器，也有一定的规则要求：</p><ol><li><p>滤波器的大小应该是奇数，这样它才有一个中心，例如3x3，5x5或者7x7。有中心了，也有了半径的称呼，例如5x5大小的核的半径就是2。</p></li><li><p>滤波器矩阵所有的元素之和应该要等于1，这是为了保证滤波前后图像的亮度保持不变。当然了，这不是硬性要求了。</p></li><li><p>如果滤波器矩阵所有元素之和大于1，那么滤波后的图像就会比原图像更亮，反之，如果小于1，那么得到的图像就会变暗。如果和为0，图像不会变黑，但也会非常暗。</p></li><li><p>对于滤波后的结构，可能会出现负数或者大于255的数值。对这种情况，我们将他们直接截断到0和255之间即可。对于负数，也可以取绝对值。</p></li></ol><h2 id="二、神奇的卷积核"><a href="#二、神奇的卷积核" class="headerlink" title="二、神奇的卷积核"></a>二、神奇的卷积核</h2><p>   上面说到，对图像的滤波处理就是对图像应用一个小小的卷积核，那这个小小的卷积核到底有哪些魔法，能让一个图像从惨不忍睹变得秀色可餐。下面我们一起来领略下一些简单但不简单的卷积核的魔法。</p><h3 id="2-1、啥也不做"><a href="#2-1、啥也不做" class="headerlink" title="2.1、啥也不做"></a>2.1、啥也不做</h3><p>哈哈，大家可以看到啥了吗？这个滤波器啥也没有做，得到的图像和原图是一样的。因为只有中心点的值是1。邻域点的权值都是0，对滤波后的取值没有任何影响。</p><p><img src="Center-1756040571420-75.png" alt="img"></p><p>   下面我们动点真格的。</p><h3 id="2-2、图像锐化滤波器Sharpness-Filter"><a href="#2-2、图像锐化滤波器Sharpness-Filter" class="headerlink" title="2.2、图像锐化滤波器Sharpness Filter"></a>2.2、图像锐化滤波器Sharpness Filter</h3><p>图像的锐化和边缘检测很像，首先找到边缘，然后把边缘加到原来的图像上面，这样就强化了图像的边缘，使图像看起来更加锐利了。这两者操作统一起来就是锐化滤波器了，也就是在边缘检测滤波器的基础上，再在中心的位置加1，这样滤波后的图像就会和原始的图像具有同样的亮度了，但是会更加锐利。</p><p><img src="Center-1756040571420-76.png" alt="img"></p><p>我们把核加大，就可以得到更加精细的锐化效果</p><p><img src="Center-1756040571420-77.png" alt="img"></p><p>另外，下面的滤波器会更强调边缘：</p><p><img src="Center-1756040571421-78.png" alt="img"></p><p>主要是强调图像的细节。最简单的3x3的锐化滤波器如下：</p><p><img src="Center-1756040571421-79.png" alt="img"></p><p>实际上是计算当前点和周围点的差别，然后将这个差别加到原来的位置上。另外，中间点的权值要比所有的权值和大于1，意味着这个像素要保持原来的值。</p><h3 id="2-3、边缘检测Edge-Detection"><a href="#2-3、边缘检测Edge-Detection" class="headerlink" title="2.3、边缘检测Edge Detection"></a>2.3、边缘检测Edge Detection</h3><p>我们要找水平的边缘：需要注意的是，这里矩阵的元素和是0，所以滤波后的图像会很暗，只有边缘的地方是有亮度的。</p><p><img src="Center-1756040571421-80.png" alt="img">为什么这个滤波器可以寻找到水平边缘呢？因为用这个滤波器卷积相当于求导的离散版本：你将当前的像素值减去前一个像素值，这样你就可以得到这个函数在这两个位置的差别或者斜率。下面的滤波器可以找到垂直方向的边缘，这里像素上和下的像素值都使用：</p><p><img src="Center-1756040571421-81.png" alt="img"></p><p>再下面这个滤波器可以找到45度的边缘：取-2不为了什么，只是为了让矩阵的元素和为0而已。</p><p><img src="Center-1756040571421-82.png" alt="img"></p><p>那下面这个滤波器就可以检测所有方向的边缘:</p><p><img src="Center-1756040571421-83.png" alt="img"></p><p>为了检测边缘，我们需要在图像对应的方向计算梯度。用下面的卷积核来卷积图像，就可以了。但在实际中，这种简单的方法会把噪声也放大了。另外，需要注意的是，矩阵所有的值加起来要是0.</p><p><img src="Center-1756040571421-84.png" alt="img"></p><h3 id="2-4、浮雕Embossing-Filter"><a href="#2-4、浮雕Embossing-Filter" class="headerlink" title="2.4、浮雕Embossing Filter"></a>2.4、浮雕Embossing Filter</h3><p>浮雕滤波器可以给图像一种3D阴影的效果。只要将中心一边的像素减去另一边的像素就可以了。这时候，像素值有可能是负数，我们将负数当成阴影，将正数当成光，然后我们对结果图像加上128的偏移。这时候，图像大部分就变成灰色了。</p><p>下面是45度的浮雕滤波器</p><p><img src="Center-1756040571421-85.png" alt="img"></p><p>我们只要加大滤波器，就可以得到更加夸张的效果了</p><p><img src="Center-1756040571421-86.png" alt="img"></p><p>这种效果非常的漂亮，就像是将一副图像雕刻在一块石头上面一样，然后从一个方向照亮它。它和前面的滤波器不同，它是非对称的。另外，它会产生负数值，所以我们需要将结果偏移，以得到图像灰度的范围。</p><p><img src="Center-1756040571421-87.png" alt="img"></p><p><img src="Center-1756040571421-88.png" alt="img"></p><blockquote><p>A：原图像。B：锐化。C：边缘检测。D：浮雕</p></blockquote><h3 id="2-5、均值模糊Box-Filter-Averaging"><a href="#2-5、均值模糊Box-Filter-Averaging" class="headerlink" title="2.5、均值模糊Box Filter (Averaging)"></a>2.5、均值模糊Box Filter (Averaging)</h3><p>我们可以将当前像素和它的四邻域的像素一起取平均，然后再除以5，或者直接在滤波器的5个地方取0.2的值即可，如下图：</p><p><img src="Center-1756040571421-89.png" alt="img"></p><p>可以看到，这个模糊还是比较温柔的，我们可以把滤波器变大，这样就会变得粗暴了：注意要将和再除以13.</p><p><img src="Center-1756040571421-90.png" alt="img"></p><p>所以，如果你想要更模糊的效果，加大滤波器的大小即可。或者对图像应用多次模糊也可以。</p><p><img src="Center-1756040571421-91.png" alt="img"></p><p><img src="Center-1756040571421-92.png" alt="img"></p><h3 id="2-6、高斯模糊"><a href="#2-6、高斯模糊" class="headerlink" title="2.6、高斯模糊"></a>2.6、高斯模糊</h3><p>均值模糊很简单，但不是很平滑。高斯模糊就有这个优点，所以被广泛用在图像降噪上。特别是在边缘检测之前，都会用来移除细节。高斯滤波器是一个低通滤波器。</p><p><img src="Center-1756040571421-93.png" alt="img"></p><p><img src="Center-1756040571421-94.png" alt="img"></p><h3 id="2-7、运动模糊Motion-Blur"><a href="#2-7、运动模糊Motion-Blur" class="headerlink" title="2.7、运动模糊Motion Blur"></a>2.7、运动模糊Motion Blur</h3><p>运动模糊可以通过只在一个方向模糊达到，例如下面9x9的运动模糊滤波器。注意，求和结果要除以9。</p><p><img src="Center-1756040571421-95.png" alt="img"></p><p>这个效果就好像，摄像机是从左上角移动的右下角。</p><h2 id="三、卷积的计算"><a href="#三、卷积的计算" class="headerlink" title="三、卷积的计算"></a>三、卷积的计算</h2><p>对图像处理而言，存在两大类的方法：空域处理和频域处理！空域处理是指直接对原始的像素空间进行计算，频率处理是指先对图像变换到频域，再做滤波等处理。</p><h3 id="3-1、空域计算-直接2D卷积"><a href="#3-1、空域计算-直接2D卷积" class="headerlink" title="3.1、空域计算-直接2D卷积"></a>3.1、空域计算-直接2D卷积</h3><h4 id="3-1-1、2D卷积"><a href="#3-1-1、2D卷积" class="headerlink" title="3.1.1、2D卷积"></a>3.1.1、2D卷积</h4><p>直接2D卷积就是一开始说的那样，对于图像的每一个像素点，计算它的邻域像素和滤波器矩阵的对应元素的乘积，然后加起来，作为该像素位置的值。</p><p><img src="Center-1756040571421-96.png" alt="img"></p><p>直接的实现也称为暴力实现brute force，因为它严格按照定义来实现，没有任何优化。当然了，在并行实现里面，它也是比较灵活的。另外，也存在一个优化版本，如果我们的kernel是separable可分的，那么就可以得到一个快5倍左右的卷积方法。</p><h4 id="3-1-2、边界处理"><a href="#3-1-2、边界处理" class="headerlink" title="3.1.2、边界处理"></a>3.1.2、边界处理</h4><p>那卷积核遇到图像边缘怎么办？例如图像顶部的像素，它的上面已经没有像素了，那么它的值如何计算？目前有四种主流的处理方法，我们用一维卷积和均值滤波来说明下。</p><p>我们在1D图像中，用每个像素和它的二邻域的平均值来取代它的值。假设我们有个1D的图像I是这样的：</p><p><img src="Center-1756040571421-97.png" alt="img"></p><p>对非图像边界的像素的操作比较简单。假设我们对I的第四个像素3做局部平均。也就是我们用2,3和7做平均，来取代这个位置的像素值。也就是，平均会产生一副新的图像J，这个图像在相同位置<script type="math/tex">J (4) = (I(3)+I(4)+I(5))/3 = (2+3+7)/3 = 4</script>。同样，我们可以得到<script type="math/tex">J(3) = (I(2)+I(3)+I(4))/3 =(4+2+3)/3 = 3</script>。需要注意的是，新图像的每个像素都取决于旧的图像，在计算<script type="math/tex">J (4)</script>的时候用<script type="math/tex">J (3)</script>是不对的，而是用<script type="math/tex">I(3)</script>，<script type="math/tex">I(4)</script>和<script type="math/tex">I(5)</script>。所以每个像素都是它和它邻域两个像素的平均。平均是线性的操作，因为每个新的像素都是旧像素的线性组合。</p><p><img src="Center-1756040571421-98.png" alt="img"></p><p>对卷积，也有必须要考虑的情况是，在图像边界的时候，怎么办？<script type="math/tex">J(1)</script>的值应该是什么？它取决于I(0)，<script type="math/tex">I(1)</script>和<script type="math/tex">I(2)</script>。但是我们没有 <script type="math/tex">I(0)</script>呀！图像左边没有值了。有四种方式来处理这个问题：</p><ol><li><p>第一种就是想象<script type="math/tex">I</script>是无限长的图像的一部分，除了我们给定值的部分，其他部分的像素值都是0。在这种情况下，<script type="math/tex">I(0)=0</script>。所以<script type="math/tex">J(1) = (I(0) + I(1) + I(2))/3 = (0 + 5 + 4)/3= 3</script>。同样，<script type="math/tex">J(10) = (I(9)+I(10)+I(11))/3 = (3+ 6 + 0)/3 = 3</script>。</p><p><img src="Center-1756040571421-99.png" alt="img"></p></li><li><p>第二种方法也是想象I是无限图像的一部分。但没有指定的部分是用图像边界的值进行拓展。在我们的例子中，因为图像I最左边的值I(1)=5，所以它左边的所有值，我们都认为是5 。而图像右边的所有的值，我们都认为和右边界的值I(10)一样，都是6。这时候<script type="math/tex">J(1) = (I(0) + I(1) + I(2))/3 = (5 + 5 + 4)/3= 14/3</script>. 而<script type="math/tex">J(10) = (I(9)+I(10)+I(11))/3 = (3 + 6 + 6)/3 = 5</script>。</p><p><img src="Center-1756040571421-100.png" alt="img"></p></li><li><p>第三种情况就是认为图像是周期性的。也就是I不断的重复。周期就是I的长度。在我们这里，I(0)和<script type="math/tex">I(10)</script>的值就是一样的，<script type="math/tex">I(11)</script>的值和<script type="math/tex">I(1)</script>的值也是一样的。所以<script type="math/tex">J(1) = (I(0) + I(1) + I(2))/3= (I(10) + I(1)+ I(2))/3 = (6 + 5 + 4)/3 = 5</script>。</p><p><img src="Center-1756040571421-101.png" alt="img"></p></li><li><p>最后一种情况就是不管其他地方了。我们觉得I之外的情况是没有定义的，所以没办法使用这些没有定义的值，所以要使用图像I没有定义的值的像素都没办法计算。在这里，<script type="math/tex">J(1)</script>和<script type="math/tex">J(10)</script>都没办法计算，所以输出J会比原图像<script type="math/tex">I</script>要小。</p><p>这四种方法有各自的优缺点。如果我们想象我们使用的图像只是世界的一个小窗口，然后我们需要使用窗口边界外的值，那么一般来说，外面的值和边界上的值是几乎相似的，所以第二种方法可能更说得过去。</p></li></ol><h3 id="2-2、频域计算-快速傅里叶变换FFT卷积"><a href="#2-2、频域计算-快速傅里叶变换FFT卷积" class="headerlink" title="2.2、频域计算-快速傅里叶变换FFT卷积"></a>2.2、频域计算-快速傅里叶变换FFT卷积</h3><p>这个快速实现得益于卷积定理：时域上的卷积等于频域上的乘积。所以将我们的图像和滤波器通过算法变换到频域后，直接将他们相乘，然后再变换回时域（也就是图像的空域）就可以了。</p><p><img src="Center-1756040571421-102.png" alt="img"></p><p>o表示矩阵逐元素相乘。那用什么方法将空域的图像和滤波器变换到频域了。那就是鼎鼎大名的Fast Fourier Transformation 快速傅里叶变换FFT（其实，在CUDA里面，已经实现了FFT了）。</p><p>要在频域中对一副图像进行滤波，滤波器的大小和图像的大小必须要匹配，这样两者的相乘才容易。因为一般滤波器的大小比图像要小，所以我们需要拓展我们的kernel，让它和图像的大小一致。</p><p><img src="Center-1756040571421-103.png" alt="img"></p><p>因为CUDA中的FFT实现是周期的，所以kernel的值也要安排成这样，以支持这种周期性。</p><p>为了保证图像边界的像素也可以得到响应输出，我们也需要拓展我们的输入图像。同时，拓展的方式也要支持周期表达。</p><p><img src="Center-1756040571421-104.png" alt="img"></p><p>如果只是使用卷积定理，没有对输入进行任何修改的话，那么我们得到的是周期卷积的结果。但这可能不是我们要的，因为周期卷积会对输入数据进行周期填补，引入一些artifacts。</p><p>给定N长度的I和K，为了得到线性卷积，我们需要对I和K进行zero padding。为什么要补0，因为DFT假定了输入是无限和周期的，周期是N。　</p><p><img src="Center-1756040571422-105.png" alt="img"></p><p>如上图，对于I和K，如果没有padding的话，隐含着会假定I和K是周期的，以他们的长度N为周期。图中本来N长度的I和K都是黑色虚线的部分，然后如果没有padding，隐含着就会在N之外，加上同样的无数个I，如红色虚线部分，加上了一个周期。对K也是这样。如果是zero padding的话，在黑色虚线的其他地方都全是0了，如图中蓝色部分。将I和K卷积，如果没有padding，如黑色虚线，会有红色那部分的artifact。如果有padding，就是蓝色实线。</p><p> <strong>四、实验代码</strong></p><p>   这是第二部分的Matlab实验代码：</p><p><strong>五、参考文献</strong></p><p>[1] Correlation and Convolution.pdf</p><p>[2] <a href="http://lodev.org/cgtutor/filtering.html">Lode’s Computer GraphicsTutorial Image Filtering</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、线性滤波与卷积的基本概念&quot;&gt;&lt;a href=&quot;#一、线性滤波与卷积的基本概念&quot; class=&quot;headerlink&quot; title=&quot;一、线性滤波与卷积的基本概念&quot;&gt;&lt;/a&gt;一、线性滤波与卷积的基本概念&lt;/h2&gt;</summary>
    
    
    
    <category term="基础知识" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
    <category term="神经网络" scheme="http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络基础补充</title>
    <link href="http://example.com/2025/09/16/BasicKnowledge/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E8%A1%A5%E5%85%85/"/>
    <id>http://example.com/2025/09/16/BasicKnowledge/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E8%A1%A5%E5%85%85/</id>
    <published>2025-09-15T16:00:00.000Z</published>
    <updated>2025-09-16T08:47:56.614Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、误差的计算"><a href="#一、误差的计算" class="headerlink" title="一、误差的计算"></a>一、误差的计算</h1><h2 id="（一）图示各个符号的含义"><a href="#（一）图示各个符号的含义" class="headerlink" title="（一）图示各个符号的含义"></a>（一）图示各个符号的含义</h2><p><img src="image-20250831175229775.png" alt="image-20250831175229775"></p><p>$x$：输入</p><p>$σ$：隐层</p><p>$w_{ij}^{(k)}$：$i$表示上一层的第$i$的节点，$j$表示本层中第$j$个节点，$k$表示该节点位于第$k$层</p><h2 id="（二）计算"><a href="#（二）计算" class="headerlink" title="（二）计算"></a>（二）计算</h2><h3 id="1、第一层节点的输出，即-w-ij-1-权值对应的输出"><a href="#1、第一层节点的输出，即-w-ij-1-权值对应的输出" class="headerlink" title="1、第一层节点的输出，即$w_{ij}^{(1)}$权值对应的输出"></a>1、第一层节点的输出，即$w_{ij}^{(1)}$权值对应的输出</h3><p><img src="image-20250831175848542.png" alt="image-20250831175848542"></p><h3 id="2、最后一层节点的输入，即-w-ij-2-权值对应的输出（-y-1-、-y-2-）"><a href="#2、最后一层节点的输入，即-w-ij-2-权值对应的输出（-y-1-、-y-2-）" class="headerlink" title="2、最后一层节点的输入，即$w_{ij}^{(2)}$权值对应的输出（$y_1$、$y_2$）"></a>2、最后一层节点的输入，即$w_{ij}^{(2)}$权值对应的输出（$y_1$、$y_2$）</h3><p><img src="image-20250831180329197.png" alt="image-20250831180329197"></p><ul><li>注意，最后一层的计算中并没有使用激活函数，因为在计算多位损失的过程中，一般最后一层的激活函数统一使用 softmax 函数</li></ul><h3 id="3、Softmax-函数的计算过程"><a href="#3、Softmax-函数的计算过程" class="headerlink" title="3、Softmax 函数的计算过程"></a>3、Softmax 函数的计算过程</h3><blockquote><p>前面计算得到的$y_1$、$y_2$并不符合任一分布，而我们的目的是为了得到一个概率分布，所以我们需要对输出的结果进行Softmax 处理</p></blockquote><p><img src="image-20250831180925523.png" alt="image-20250831180925523"></p><h2 id="（三）Cross-Entropy-Loss-交叉熵损失"><a href="#（三）Cross-Entropy-Loss-交叉熵损失" class="headerlink" title="（三）Cross Entropy Loss 交叉熵损失"></a>（三）Cross Entropy Loss 交叉熵损失</h2><ol><li><p>针对多分类问题（Softmax 输出，所有输出概率和为1）</p><p><img src="image-20250831181721290.png" alt="image-20250831181721290"></p></li><li><p>针对二分类问题（Sigmoid 输出，每个输出节点之间互不相干）</p><p><img src="image-20250831181731992.png" alt="image-20250831181731992"></p><p>sigmoid 输出的结果不会满足任何一个经验分布（概率分布——和为1）</p></li></ol><p>其中$o_i^<em>$为真实标签值，$o_i$为预测值，<em>*默认$log$以$e$为底等于$ln$</em></em></p><p><img src="image-20250831182043966.png" alt="image-20250831182043966"></p><h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><ul><li><strong>多分类问题</strong> Softmax 输出的结果只可能归于某一种类别，如图片可能是猫的概率为0.9，狗的概率为0.1，结果只可能是两者中的一个</li><li><strong>二分类问题</strong> Sigmoid 输出的结果是归于不同种类别的，如这个照片是人的概率为0.97，是男人的概率为0.7，两者分布不满足经验分布（和不为1）</li><li>但是实际使用中针对更多的是多分类问题，也就是使用 Softmax 函数</li></ul><h3 id="图示结果"><a href="#图示结果" class="headerlink" title="图示结果"></a>图示结果</h3><p><img src="image-20250831182142318.png" alt="image-20250831182142318"></p><h1 id="二、误差的反向传播"><a href="#二、误差的反向传播" class="headerlink" title="二、误差的反向传播"></a>二、误差的反向传播</h1><h3 id="以损失-Loss-对-w-11-2-的损失梯度为例"><a href="#以损失-Loss-对-w-11-2-的损失梯度为例" class="headerlink" title="以损失$Loss$对$w_{11}^{(2)}$的损失梯度为例"></a>以损失$Loss$对$w_{11}^{(2)}$的损失梯度为例</h3><p><img src="image-20250831182529635.png" alt="image-20250831182529635"></p><p><img src="image-20250831183016462.png" alt="image-20250831183016462"></p><p><img src="image-20250831183125727.png" alt="image-20250831183125727"></p><p>如此，便将我们得到的误差反向传播到了每一个节点，得到了每一个节点的损失梯度</p><h1 id="三、权重的更新"><a href="#三、权重的更新" class="headerlink" title="三、权重的更新"></a>三、权重的更新</h1><p><img src="image-20250831183511922.png" alt="image-20250831183511922"></p><p>难道以上结果便是我们所需要的？我们所求的梯度是否指向了全局最优的方向？或者说损失减少最快的方向？</p><p><img src="image-20250831184151200.png" alt="image-20250831184151200"></p><p>在实际应用中往往不可能一次性将所有数据载入内存（算力也不够），所以只能分批次（batch）训练。</p><p>例如，ImageNet 项目是一个用于视觉对象识别软件研究的大型可视化数据库。超过1400万的图像被 ImageNet 手动注释，以指示图片中的对象。在使用ImageNet 项目时，不可能一口气使用整个样本集进行求解吧，这需要的算力资源太大了，不是做不到，而是没有必要，所以，可以使用分批次训练。</p><p>求解得到的结果不是最优的，所以需要用到<strong>优化器 optimazer</strong>。</p><h2 id="优化器-optimazer"><a href="#优化器-optimazer" class="headerlink" title="优化器 optimazer"></a>优化器 optimazer</h2><p><img src="image-20250831184907287.png" alt="image-20250831184907287"></p><p><strong>优化器 optimazer</strong> 的目的是<strong>为了让网络更快的得到收敛</strong>。</p><p>分批次训练训练指的是对每一个批次进行损失的计算以及误差的反向传播，即 <strong>SGD</strong> 优化器</p><h3 id="1、-SGD-优化器（Stochastic-Gradient-Descent）"><a href="#1、-SGD-优化器（Stochastic-Gradient-Descent）" class="headerlink" title="1、 SGD 优化器（Stochastic Gradient Descent）"></a>1、 SGD 优化器（Stochastic Gradient Descent）</h3><p><img src="image-20250831185652547.png" alt="image-20250831185652547"></p><p><strong>缺点：</strong></p><ol><li><strong>易受样本噪声影响</strong>，如果训练集中标注的结果是错误的，那么计算出来的损失梯度就有问题，可能与理想的梯度方向向背</li><li><strong>可能陷入局部最优解</strong></li></ol><p>为了解决这些缺点，可以加上 <strong>Momentum</strong></p><h3 id="2、SGD-Momentum-优化器"><a href="#2、SGD-Momentum-优化器" class="headerlink" title="2、SGD + Momentum 优化器"></a>2、SGD + Momentum 优化器</h3><ul><li>相比 SGD，多了动量部分，即除了计算当前的梯度之外，还会加上之前的梯度</li><li>引入动量之后，最终的梯度方向就不仅需要考虑本次计算出了的方向，还需要考虑<strong>上一次梯度</strong>的方向了</li><li>结果：能够有效抑制噪声的影响</li></ul><p><img src="image-20250831185829291.png" alt="image-20250831185829291"></p><h3 id="3、Adagrad-优化器（自适应学习率）"><a href="#3、Adagrad-优化器（自适应学习率）" class="headerlink" title="3、Adagrad 优化器（自适应学习率）"></a>3、Adagrad 优化器（自适应学习率）</h3><p><img src="image-20250831190441084.png" alt="image-20250831190441084"></p><p>$s_t$ 不断累加梯度的平方和，相当于给学习率加了一个持续变小的权重，以致于达到自适应的效果</p><p>但是学习率下降的太快，可能还没收敛就停止训练了</p><h3 id="4、RMSProp-优化器（自适应学习率）"><a href="#4、RMSProp-优化器（自适应学习率）" class="headerlink" title="4、RMSProp 优化器（自适应学习率）"></a>4、RMSProp 优化器（自适应学习率）</h3><p><img src="image-20250831190724771.png" alt="image-20250831190724771"></p><p>加上了两个系数来控制衰减速度</p><h3 id="5、Adam-优化器（自适应学习率）"><a href="#5、Adam-优化器（自适应学习率）" class="headerlink" title="5、Adam 优化器（自适应学习率）"></a>5、Adam 优化器（自适应学习率）</h3><p><img src="image-20250831191032846.png" alt="image-20250831191032846"></p><p>使用的话，一般 <strong>SGD + Momentum</strong> 优化器用的更多</p><p>SGD：速度比较慢，但梯度是沿着比较理想的方向更新的</p><p>Momentum：一开始的方向比较偏，但是很快纠正了</p><p>Adagrad 和 RMSProp 不仅方向正确，而且速度更新也很快</p><blockquote><p>代码的实践留一留</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;一、误差的计算&quot;&gt;&lt;a href=&quot;#一、误差的计算&quot; class=&quot;headerlink&quot; title=&quot;一、误差的计算&quot;&gt;&lt;/a&gt;一、误差的计算&lt;/h1&gt;</summary>
    
    
    
    <category term="基础知识" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
    <category term="神经网络" scheme="http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>池化（pooling）</title>
    <link href="http://example.com/2025/09/16/BasicKnowledge/%E6%B1%A0%E5%8C%96(pooling)/"/>
    <id>http://example.com/2025/09/16/BasicKnowledge/%E6%B1%A0%E5%8C%96(pooling)/</id>
    <published>2025-09-15T16:00:00.000Z</published>
    <updated>2025-09-16T08:47:56.616Z</updated>
    
    <content type="html"><![CDATA[<h1 id="池化（pooling）"><a href="#池化（pooling）" class="headerlink" title="池化（pooling）"></a>池化（pooling）</h1><blockquote><p>意即“缩并”</p></blockquote><p>池化过程在一般卷积过程后。池化（pooling） 的本质，其实就是采样。Pooling 对于输入的 Feature Map，选择某种方式对其进行降维压缩，以加快运算速度。</p><p>采用较多的一种池化过程叫<strong>最大池化（Max Pooling）</strong>，其具体操作过程如下：</p><p><img src="%E6%B1%A0%E5%8C%96(pooling" alt="img">/v2-2ce695fbd365c2be94521992d52ccefd_1440w.jpg)</p><p>池化过程类似于卷积过程，如上图所示，表示的就是对一个 feature map邻域内的值，用一个 的filter，步长为2进行‘扫描’，选择最大值输出到下一层，这叫做 Max Pooling。</p><p>max pooling常用的 ， 的效果：特征图高度、宽度减半，通道数不变。</p><p>还有一种叫<strong>平均池化（Average Pooling）</strong>,就是从以上取某个区域的最大值改为求这个区域的平均值，其具体操作过程如下：</p><p><img src="%E6%B1%A0%E5%8C%96(pooling" alt="img">/v2-a47095dd0902990d387e21ae24e6f0b9_1440w.jpg)</p><p>如上图所示，表示的就是对一个 feature map邻域内的值，用一个 的filter，步长为2进行‘扫描’，计算平均值输出到下一层，这叫做 Mean Pooling。</p><p><strong>【池化层没有参数、池化层没有参数、池化层没有参数】</strong> （重要的事情说三遍）</p><p><strong>池化的作用：</strong></p><p>（1）保留主要特征的同时减少参数和计算量，防止过拟合。</p><p>（2）invariance(不变性)，这种不变性包括translation(平移)，rotation(旋转)，scale(尺度)。</p><p>Pooling 层说到底还是一个特征选择，信息过滤的过程。也就是说我们损失了一部分信息，这是一个和计算性能的一个妥协，随着运算速度的不断提高，我认为这个妥协会越来越小。</p><p>现在有些网络都开始少用或者不用pooling层了。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;池化（pooling）&quot;&gt;&lt;a href=&quot;#池化（pooling）&quot; class=&quot;headerlink&quot; title=&quot;池化（pooling）&quot;&gt;&lt;/a&gt;池化（pooling）&lt;/h1&gt;</summary>
    
    
    
    <category term="基础知识" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
    <category term="神经网络" scheme="http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Week6</title>
    <link href="http://example.com/2025/08/24/LearningSchedule/Week6/"/>
    <id>http://example.com/2025/08/24/LearningSchedule/Week6/</id>
    <published>2025-08-23T16:00:00.000Z</published>
    <updated>2025-08-28T04:03:26.197Z</updated>
    
    <content type="html"><![CDATA[<h2 id="模型基础"><a href="#模型基础" class="headerlink" title="模型基础"></a>模型基础</h2><h2 id="一、语义分割概念"><a href="#一、语义分割概念" class="headerlink" title="一、语义分割概念"></a>一、语义分割概念</h2><blockquote><p>学习视频</p><p><a href="https://www.bilibili.com/video/BV1ev411P7dR/?spm_id_from=333.1391.0.0&amp;vd_source=f087eabd3aa1e0f48fafe303a9a3a49b">语义分割前言_哔哩哔哩_bilibili</a></p></blockquote><p><strong>目标：</strong></p><ul><li>什么是语义分割</li><li>暂定的学习规划</li><li>语义分割任务常见数据集格式</li><li>语义分割得到结果的具体形式</li><li>语义分割常见评价标准</li><li><p>语义分割标注工具</p><h3 id="（一）常见分割任务"><a href="#（一）常见分割任务" class="headerlink" title="（一）常见分割任务"></a>（一）常见分割任务</h3><ol><li><p>语义分割（FCN）：对每一个像素进行分类</p></li><li><p>实例分割（Mask R-CNN）：针对同一个类别的不同目标也采用不同颜色进行分类，结果更精细，只关注目标背景</p></li><li><p>全景分割（Panoptic FPN）语义 + 实例 + 背景划分</p><blockquote><p>精细程度逐级递增</p></blockquote><p><img src="d4feeb82775c742b95f2bca8aa9444954dd05abe.jpg@682w_!web-note.webp" alt="img"></p><h3 id="（二）pytorch-官方提供的语义分割网络"><a href="#（二）pytorch-官方提供的语义分割网络" class="headerlink" title="（二）pytorch 官方提供的语义分割网络"></a>（二）pytorch 官方提供的语义分割网络</h3></li></ol></li></ul><p><img src="460884667254062d83d862562f79021274b71feb.jpg@682w_!web-note.webp" alt="img"></p><h3 id="（三）语义分割任务常见数据集格式"><a href="#（三）语义分割任务常见数据集格式" class="headerlink" title="（三）语义分割任务常见数据集格式"></a>（三）语义分割任务常见数据集格式</h3><ol><li><p>Pascal VOC</p><blockquote><p><a href="https://blog.csdn.net/qq_37541097/article/details/115787033">PASCAL VOC2012数据集介绍_pascal voc 2012-CSDN博客</a></p></blockquote><p>语义分割中提供的是png图片（记录每个像素所属的一个类别信息），这个png图片使用调色板的模式进行存储。</p><p>图片（第二张图片）实际是一个一通道的图片（黑白图片），但看到的确实彩色的。</p><p>用 python 的 Pillow 去读取 png 图片的话，默认读取的是调色板的模式（P模式），通道数为1（单通道）。</p><p>但是读取图片进行训练的时候只需要关注每个像素所属的类别索引即可</p><p>目标的边缘都会有一个特殊的颜色进行分割，或者图片中的一些特殊去也会用这个颜色进行填充，而这些位置对应的像素值是255万。在训练过程中，会抛弃像素值为255万的地方，因为这些地方并不好严格确定其所属类型。</p><p>除此之外，有一些不好区分类别的地方，也可用这个颜色进行填充。例如图中的长方形区域，在原图中是有一个飞机的尾翼部分的，但是并不好进行分割，故直接使用了像素值为255的数值进行填充，填充遮蔽之后再训练网络的时候就不会去计算这部分的损失。</p><p><img src="image-20250208151458501.png" alt="image-20250208151458501"></p><blockquote><p>像素值指的是数字图像的基本单位像素所具有的数值信息。它是用来定义图像的亮度或颜色等级的，对彩色图像而言，每个像素通常包含了红、绿、蓝三个颜色通道的数值信息，这三个颜色通道的数值组合决定了该像素呈现的颜色。</p><p>像素值是三维数值</p></blockquote><p><img src="image-20250208152753100.png" alt="image-20250208152753100"></p></li><li><p><strong>MS COCO</strong></p><blockquote><p><a href="https://blog.csdn.net/qq_37541097/article/details/113247318">MS COCO数据集介绍以及pycocotools简单使用_coco数据集最多一张图有多少个instance-CSDN博客</a></p><p>这篇论文是关于读取每张图片的分割信息的部分，如何读取并得到每个图像所对应的标签图片</p></blockquote><p>针对图像中的每一个目标都给出了一个<strong>多边形</strong>的一个<strong>坐标形式</strong>（x坐标.y坐标，两个一组一个坐标点，点连成线，得到目标），将图像中的所有目标绘制出来，即可得到右下角抽离出来的训练图案。</p><p>这个结果图片与 Pascal 的 png 图片结果是一样的，不过并没有标注边缘信息，因此使用MS COCO数据集就需要自己将多边形信息解码成png图片（期望的标签图片）。计算损失时，就是拿预测的每个像素对应的类别与真实标签的每个类型进行对比计算。</p><p>另外，记录的多边形信息除可用于语义分割外，还可以用于进行实例分割，因这样已经记录了每个目标的，是能够将每个目标都区分出来的</p></li></ol><h3 id="（四）语义分割得到结果的具体形式"><a href="#（四）语义分割得到结果的具体形式" class="headerlink" title="（四）语义分割得到结果的具体形式"></a>（四）语义分割得到结果的具体形式</h3><blockquote><p>单通道图片</p></blockquote><ul><li>以下是单通道 + 调色板，利用 PyTorch 官方的 FCN 网络预测的结果（背景位置像素值为0， 飞机位置像素值为1，人位置的像素值为15）。</li></ul><p>如果直接以灰度图片显示的话，看到的图片是一幅黑色的（因为不同目标的像素值实际都很小—-1和15），肉眼根本看不出区别，加上调色板，可以让每个像素对应一个彩色，方便可视化我们的预测结果。</p><ul><li>每个像素的数值对应类别索引</li></ul><p><img src="image-20250208154730540.png" alt="image-20250208154730540"></p><h3 id="（五）常见语义分割评价指标"><a href="#（五）常见语义分割评价指标" class="headerlink" title="（五）常见语义分割评价指标"></a>（五）常见语义分割评价指标</h3><ol><li><p>Pixel Accuracy（Global Acc）</p><ul><li>分子是预测标签图像中所有预测正确的像素个数的总和</li><li>分母是图片的总像素个数</li></ul></li><li><p><strong>mean Acc</strong></p><p>将每个类别的 Acc 计算出来，然后再进行一个求和，然后再取平均</p></li><li><p>mean IoU</p><p>计算每一个类别的 IoU，然后再对每个类别 IoU 的累和求平均</p><p>其实和目标检测 IoU 理论上是一样的，都是两个目标面积的交集比上他们面积的并集 </p><ul><li>假设绿色的圆圈对应的是真实的标签，蓝色的圆圈对应的是预测的标签，那么n~ii~ 对应的是这两个圈重合的部分，即预测正确的部分</li><li>t~i~ 对应的是类别 i 的总个数，即绿色圆圈部分的面积，而<img src="image-20250208162640581.png" alt="image-20250208162640581">对应的是预测标签中所有预测为类别 i 一个像素总个数，即蓝色圆圈部分的面积，由于计算的时候中间部分计算了两次，所以还需要减去一次中间部分 n~ii~</li></ul><p>论文中最常见的是 mean IoU</p></li></ol><blockquote><p>n~ii~ ：针对类别i，预测正确的总像素个数</p></blockquote><p><img src="image-20250208160252213.png" alt="image-20250208160252213"></p><h4 id="Pytorch-官方的一个计算方法——通过构建一个混淆矩阵来进行计算"><a href="#Pytorch-官方的一个计算方法——通过构建一个混淆矩阵来进行计算" class="headerlink" title="Pytorch 官方的一个计算方法——通过构建一个混淆矩阵来进行计算"></a>Pytorch 官方的一个计算方法——通过构建一个混淆矩阵来进行计算</h4><p><img src="image-20250208163130675.png" alt="image-20250208163130675"></p><ol><li><strong>Global ACC</strong></li></ol><ul><li>为了方便理解，现将所有标注为0的位置设置为白色，非0标注的位置全部设置为灰色，这样把所有预测标签为0的结果全部提取出来了，</li><li>然后预测正确的位置用绿色进行表示，预测错误的位置用红色表示</li><li>右图中16是预测为0的正确像素总是（即绿色像素总个数），2为预测为0的预测错误的像素总个数（即红色像素总个数），错误像素原本对应的索引是3</li></ul><p><img src="image-20250208163420330.png" alt="image-20250208163420330"></p><ul><li>同样在预测标签当中，将所有预测为1的结果全部提取出来，预测正确的用绿色表示，预测错误的用红色表示</li></ul><p><img src="image-20250208163907857.png" alt="image-20250208163907857"></p><ul><li>以此类推，可以分别预测出类别2，类别3，类别4对应的参数</li><li>最终得到一个混淆矩阵<ul><li>分子是预测标签图像中所有预测正确的像素个数的总和</li><li>分母是图片的总像素个数</li><li>对角线对应的全部是预测正确的像素个数，即分子是混淆矩阵对角线上的数字之和</li><li>可以将混淆矩阵的所有个数相加得到分母，或者直接使用标签（8行8列8*8=64）得到像素值</li></ul></li></ul><p><img src="image-20250208165128870.png" alt="image-20250208165128870"></p><ol><li><strong>mean ACC</strong></li></ol><p><img src="image-20250208165950994.png" alt="image-20250208165950994"></p><ol><li><strong>mean IoU</strong></li></ol><p><img src="image-20250208170239310.png" alt="image-20250208170239310"></p><p><img src="image-20250208170304472.png" alt="image-20250208170304472"></p><h3 id="（六）标注工具"><a href="#（六）标注工具" class="headerlink" title="（六）标注工具"></a>（六）标注工具</h3><ol><li><strong>Labelme</strong></li></ol><blockquote><p><a href="https://blog.csdn.net/qq_37541097/article/details/120162702">Labelme分割标注软件使用_labelme2voc.py-CSDN博客</a></p></blockquote><p><img src="image-20250208170416293.png" alt="image-20250208170416293"></p><ol><li><strong>EISeg</strong> —- 百度开源的深度学习框架</li></ol><blockquote><p><a href="https://blog.csdn.net/qq_37541097/article/details/120154543">EISeg分割标注软件使用_eiseg使用-CSDN博客</a></p></blockquote><p><img src="image-20250208170854204.png" alt="image-20250208170854204"></p><p>开源仓库：<a href="https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.10/EISeg">PaddleSeg/EISeg at release/2.10 · PaddlePaddle/PaddleSeg</a></p><h2 id="二、转置卷积（Transposed-Convolution）"><a href="#二、转置卷积（Transposed-Convolution）" class="headerlink" title="二、转置卷积（Transposed Convolution）"></a>二、转置卷积（Transposed Convolution）</h2><blockquote><p><a href="https://arxiv.org/abs/1603.07285">[1603.07285] A guide to convolution arithmetic for deep learning</a></p></blockquote><h3 id="（一）-介绍"><a href="#（一）-介绍" class="headerlink" title="（一） 介绍"></a>（一） 介绍</h3><p><img src="image-20250209142613047.png" alt="image-20250209142613047"></p><ul><li>在语义分割和对抗神经网络 gan 当中的作用：<strong>采样</strong>（upsampling）</li><li>左侧的图是一个传统的卷积，输入的是高宽为 4 <em> 4 的特征层，克隆大小是 3 </em> 3的，padding = 0， strides = 1，通过卷积之后，得到的输出特征层的高宽是 2 * 2 的</li><li><p>右边的图是转置卷积，对于输入的是 2 <em> 2 的特征层，同时在四周填充一些零元素，填充之后同样使用 3 </em> 3 的卷积核来进行卷积处理，通过转置卷积之后，发现输入特征层大小是 2 <em> 2，输出特征层大小变成了 4 </em> 4，输出变大了，这也是转置卷积最常用的一种情况，就是<strong>伤采样</strong>。</p><ol><li><p>转置卷积不是卷积的逆运算</p><ul><li><p>deconvolution卷积逆运算的名称，但同时在某些地方也被认为是转置卷积，这很容易混淆，所以一般不用这个做称呼</p></li><li><p>转置卷积只是将特征层的大小还原回卷积之前的大小，但其数值是和输入特征层的数值不一样，所以转置卷积并不算一个卷积逆运算的过程</p></li></ul></li></ol></li></ul><ol><li>转置卷积也是卷积</li></ol><blockquote><p>第一次听到转置卷积是在李宏毅老师课上，印象深刻的一句话：转置卷积就是卷积。对了，补充一下，把卷积核矩阵转置乘原图矩阵就是转置卷积，因此卷积运算的反向传播就是通过转置卷积实现的。以及转置卷积在生成任务中如果卷积核大小为3，步长为2，会有非常明显的棋盘效应，因此更推荐使用最临近插值或双线性插值后再接一个卷积来取代转置卷积。</p></blockquote><h3 id="（二）转置卷积运算步骤"><a href="#（二）转置卷积运算步骤" class="headerlink" title="（二）转置卷积运算步骤"></a>（二）转置卷积运算步骤</h3><blockquote><p><a href="https://www.bilibili.com/video/BV1mh411J7U4/?spm_id_from=333.788.videopod.sections&amp;vd_source=1f6cc2c08a78961ffd2fe66fb4012d73">转置卷积（transposed convolution）_哔哩哔哩_bilibili</a></p></blockquote><p><img src="image-20250209161051085-1755856019960-19.png" alt="image-20250209161051085"></p><p><strong>具体步骤</strong></p><ol><li><p>首先对特征图进行处理：在特征图每个元素间填充 <strong>s-1行、列</strong> 0元素，在特征图四周填充<strong>k-p-1行、列</strong> 0元素</p><p>注：此处的s，p，k为得到该特征图所进行的相应卷积操作的步长、填充及卷积核大小，即原来下采样(正向卷积)时相应的参数</p><p>(s-stricks p-paddingk-卷积核大小kernel-size)</p></li><li><p>然后对原始卷积核(下采样用的卷积核)进行上下翻转+左右翻转</p></li><li>最后用翻转后的卷积核对步骤1处理后的特征图进行卷积操作，步距为1，填充为0</li></ol><p><img src="image-20250823104408559.png" alt="image-20250823104408559"></p><h2 id="三、Dilated-Convolution膨胀卷积（空洞卷积）"><a href="#三、Dilated-Convolution膨胀卷积（空洞卷积）" class="headerlink" title="三、Dilated Convolution膨胀卷积（空洞卷积）"></a>三、Dilated Convolution膨胀卷积（空洞卷积）</h2><h3 id="（一）什么是膨胀卷积？"><a href="#（一）什么是膨胀卷积？" class="headerlink" title="（一）什么是膨胀卷积？"></a>（一）什么是膨胀卷积？</h3><ul><li>膨胀卷积：最早由MULTI-SCALE CONTEXT AGGREGATION BY DILATED CONVOLUTIONS(基于膨胀卷积的多尺度上下文融合.2015)提出</li><li>最初膨胀卷积概念的提出是为了解决图像分割的问题——常见的图像分割算法通常使用<strong>池化</strong>层和<strong>卷积</strong>层来增加感受野(Receptive Filed)，同时也缩小了特征图尺寸(resolution)，然后再利用<strong>上采样</strong>还原图像尺寸，特征图缩小再放大的过程造成了精度上的损失，因此需要一种操作可以在增加感受野的同时保持特征图的尺寸不变，从而代替下采样和上采样操作，即<strong>膨胀卷积</strong>。</li></ul><p><img src="1e73bb7c86f94eaabe511c9cd11e0d13tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="no_padding_no_strides"></p><ul><li>上图展示了一般卷积的过程，其卷积核大小为3×3，步长s=1。</li><li>看完了熟悉的卷积操作，接着我们来看看何为空洞卷积，如下图所示：</li></ul><p><img src="3b9ee00fa3694432b07e1cb17e998a50tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="dilation"></p><p>上图展示了空洞卷积的过程，其卷积核大小为3×3，步长s=1，r=2。你或许会问了，这个r是什么呢，其实啊，这个r正是普通卷积和空洞卷积的差别所在，我们称之为<strong>膨胀因子</strong>。当r=1时，表示卷积核各元素之前没有空隙，即相邻两个元素间位置相差1，此时其实就是我们正常的卷积，所以广义上说，普通的卷积是一种特殊的空洞卷积；当r=2时，表示卷积核各元素之前有一个空隙，即相邻两个元素间位置相差2，此时就是我们上图中的卷积核，为方便大家理解，我把上图r=2时的卷积核提取出来，如下图所示：</p><p><img src="3f109228860742978c8bd0a4709370fftplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220826220545773"></p><p>​          当然了当r=3、r=4都是同样的道理，这里就不过多叙述了。</p><h3 id="（二）为何要用空洞卷积？"><a href="#（二）为何要用空洞卷积？" class="headerlink" title="（二）为何要用空洞卷积？"></a>（二）为何要用空洞卷积？</h3><p>知道了什么是空洞卷积，自然想要问为什么要用空洞卷积呢？其实使用空洞卷积最主要的用途就是<strong>增大感受野</strong>。enmmm，先来介绍一下什么是感受野？</p><p>感受野就是指特征图上的一个像素对应原图多少尺寸的像素，画一个简单的图来解释一下：</p><p><img src="b18327aa37174715a6145d40f9b80a66tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220826224134320"></p><p>上图是一个普通卷积的过程，卷积核大小为3×3，步长s=1。可以发现，所得特征图中一个1×1像素区域（灰绿色）对应了原图中的3×3大小的区域，这就是3×3大小卷积核的感受野。</p><p>再来看，对刚刚得到的特征图（橙色）再经过一次3×3卷积，如下图所示：</p><p><img src="50e9ca98559d4497857cceb4b4f8ceb7tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220826224904623"></p><p>很显然，此时最后一层特征图中一个1×1像素区域（青蓝色）对应了橙色特征图中的3×3大小的区域，这也是3×3大小卷积核的感受野。</p><p>那么，现在将上述两步放在一起，如下图所示：</p><p><img src="a78dd374ebc34d418796eeed163803b9tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220826225156520"></p><p>此时最后一层特征图中一个1×1像素区域（青蓝色）对应原图多少尺寸大小的区域是5×5，因为青蓝色像素感受野包含了<strong>整个橙色</strong>的区域，而<strong>整个橙色</strong>区域的感受野正是下方5×5区域大小的范围。<strong>【这里应该也好理解吧，可以自己动手画画理解理解】</strong></p><p>通过上文叙述，知道了感受野是怎么计算的了，下面给出计算感受野的公式，如下：</p><script type="math/tex; mode=display">Fi=(F_{i-1}-1)×stride + k</script><p>其中，<script type="math/tex">F_{i}</script>表示第<script type="math/tex">i</script>层的感受野，<script type="math/tex">F_{i-1}</script>表示<script type="math/tex">i−1</script>层的感受野，<script type="math/tex">srtide</script>表示步长，<script type="math/tex">k</script>表示卷积核大小。可以将公式代入到上面的例子中验算一下是否正确。首先，蓝色、橙色、青蓝色特征图分别表示3层、2层、1层，现我们要计算1层相对于3层的感受野，首先要计算出1层对于2层的感受野，即</p><script type="math/tex; mode=display">F_2=(F_1−1)×1 + 3 = (1−1)×1+3=3</script><p>得到了<script type="math/tex">F_2</script>，就可以计算1层相对于3层的感受野，即</p><script type="math/tex; mode=display">F_3=(F_2−1)×1 + 3=(3−1)×1+3=5</script><p><strong>【注：对于感受野，我觉得很有必要很大家强调一点，即我们所说的感受野都是相对于原图说的，即某层特征图中一个像素尺寸对应原图多少像素尺寸】</strong></p><hr><p>通过上文的解释，对感受野的计算已经有所了解了。再回到本节的问题上——为什么要使用空洞卷积。使用空洞卷积一个关键原因就是可以增大感受野，这样在检测、分割任务中就能对大尺寸物体表现出较好的效果。至于空洞卷积为什么可以增大感受野，我觉得也非常好理解啊，如下图所示：</p><p><img src="ef7a19c327e24d2e82597273d48cdcc9tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="img"></p><p>上图表示使用3×3的卷积核进行空洞卷积，r=2，很明显，此时灰色特征层的感受野为5×5。其实呢，计算空洞卷积感受野也有公式，我们这样来思考，上图是3×3的卷积核，r=2，这样构成的一个空洞卷积核（乱起的名字哈，不用在意）的尺寸就相当于是5×5大小了，这时候我们感受野的计算就相当于5×5卷积核的感受野了。既然这样，我们能否找到空洞卷积核大小和原始卷积核大小的关系呢？当然可以啦，如下：</p><script type="math/tex; mode=display">k′=k+(k−1)(r−1)</script><script type="math/tex; mode=display">k′$$表示空洞卷积核大小，$$k$$表示原始卷积核大小，$$r$$表示膨胀因子。大家可以试着将这个公式代入进去，验证公式的正确性！！！既然有了$$k'$$，我们就可以利用原来计算感受野的公式得到计算空洞卷积感受野的公式了，如下：</script><p>F<em>i=(F</em>{i-1}-1)×stride + k’=(F_{i-1}-1) × stride + k + (k-1)(r-1)</p><p>$$</p><h3 id="（三）空洞卷积存在的缺陷"><a href="#（三）空洞卷积存在的缺陷" class="headerlink" title="（三）空洞卷积存在的缺陷"></a>（三）空洞卷积存在的缺陷</h3><p>上文谈及了空洞卷积可以增大感受野，这是空洞卷积本身的优势。那空洞卷积是否有缺陷呢？关于这点大家可以看看这篇<a href="https://link.juejin.cn?target=https%3A%2F%2Farxiv.org%2Fabs%2F1702.08502">论文</a>，该篇论文就主要介绍了空洞卷积存在的缺陷以及解决方案。</p><p>其实啊，空洞卷积的缺陷主要体现在存在网格效应，我们可以来看一下下图：</p><p><img src="e65f155d71cd468f98f97cf0a80c916dtplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220827102952147"></p><p>上图的卷积核大小都是3×3，r=2。第一次空洞卷积后的感受野为5×5，第二次空洞卷积后感受野大小为9×9，第三次空洞卷积后感受野大小为13×13。<strong>【这很容易得到，大家套我上文给出的公式即可】</strong></p><p>我们可以看到，连续使用三次r=2的空洞卷积会导致中间有很多空格，即很多像素没有利用到，这会导致出现网格效应，我们拿语义分割为例，如下图所示：</p><p><img src="0714492a39b74665af1863722f20dc39tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220827104153134"></p><p>可以看到，在分割结果中存在很多很多的不连续的小网格区域，这就是网格效应，也是空洞卷积带来的副作用。</p><p>我们再来看看本小节的第一张图，你可以发现，小网格上颜色的深度是不一致的。其实啊，颜色的深度表示该像素利用了原始特征图上像素的次数。是不是不好理解呢，这里我详细的说一下。【这一部分推荐视频中也没有介绍的很清楚，下面几张图片都来自视频】</p><p>首先我们来看一下，经过第一次3×3的卷积，每个像素都只利用了原图上的一个像素，这很好理解，如下图：</p><p><img src="498194d8d88a418b93b6e23e9b81574ctplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220827105119123"></p><p>​          接下来，经过第二次空洞卷积，得到的结果如下：</p><p><img src="4b9b188b53c740689268e144d5b00aa9tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220827105359169"></p><p>这次看着复杂多了，但其实你要明白了某个数字是怎么得到的，其它的都很简单了。我们来看上图最中间红色的9怎么得到的，如下图所示：</p><p><img src="8e1177df42af460792d97b8c6a535f01tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220827105921173"></p><p>右图中的一个像素是由左图的9个像素得到，而左图9个像素都只对应原图上了一个像素，故右图红色点上数字为9。我们再以左上角的一个像素为例，如下：</p><p><img src="fbf33b9e5354461cbbca1f310bab78e3tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220827110322298"></p><p>上面右图中左上角的一个像素对应左图中9个像素，而这9个像素只有包含一个红色像素，故左上角的数字为1。介绍了这两个例子后，大家可以尝试其它的数值。</p><p>最后，经过第3次空洞卷积后，得到下图：</p><p><img src="f2cb1d4b00d1429bb5a6496ca82b036ftplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220827110748582"></p><h3 id="（四）如何高效利用空洞卷积"><a href="#（四）如何高效利用空洞卷积" class="headerlink" title="（四）如何高效利用空洞卷积"></a>（四）如何高效利用空洞卷积</h3><p>既然空洞卷积存在着网格效应，那有什么方法可以解决这个问题吗。开门见山，论文中巧妙的使用了不同膨胀因子的空洞卷积，这样就能有效解决空洞卷积网格效应的问题，如下图所示：</p><p><img src="e27a5843273f450a9ab9ff5f3269aa0btplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220827113243464"></p><p>是不是发现没有网格了呢，而且感受野大小也是一样的。这里在来看看使用这种方式在语义分割中的效果，如下图：</p><p><img src="8df4c69b40fb4674a74a4fac5236e082tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220827113521393"></p><p>能很直观的感受到使用不同r的空洞卷积的效果要更好。</p><h2 id="四、UNet"><a href="#四、UNet" class="headerlink" title="四、UNet"></a>四、UNet</h2>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;模型基础&quot;&gt;&lt;a href=&quot;#模型基础&quot; class=&quot;headerlink&quot; title=&quot;模型基础&quot;&gt;&lt;/a&gt;模型基础&lt;/h2&gt;</summary>
    
    
    
    <category term="504医学AI" scheme="http://example.com/categories/504%E5%8C%BB%E5%AD%A6AI/"/>
    
    
    <category term="504医学AI入门" scheme="http://example.com/tags/504%E5%8C%BB%E5%AD%A6AI%E5%85%A5%E9%97%A8/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络（CNN）</title>
    <link href="http://example.com/2025/08/24/BasicKnowledge/CNN/"/>
    <id>http://example.com/2025/08/24/BasicKnowledge/CNN/</id>
    <published>2025-08-23T16:00:00.000Z</published>
    <updated>2025-09-16T08:45:38.956Z</updated>
    
    <content type="html"><![CDATA[<h1 id="卷积神经网络（CNN）的原理"><a href="#卷积神经网络（CNN）的原理" class="headerlink" title="卷积神经网络（CNN）的原理"></a>卷积神经网络（CNN）的原理</h1><h2 id="引言："><a href="#引言：" class="headerlink" title="引言："></a>引言：</h2><blockquote><p>可查看前篇文章——神经网络：构建人工智能的基石</p></blockquote><p>卷积神经网络（Convolutional Neural Network，CNN）是一种在计算机视觉领域取得了巨大成功的深度学习模型。它们的设计灵感来自于生物学中的视觉系统，旨在模拟人类视觉处理的方式。在过去的几年中，CNN已经在图像识别、目标检测、图像生成和许多其他领域取得了显著的进展，成为了计算机视觉和深度学习研究的重要组成部分。</p><h2 id="一、图像原理"><a href="#一、图像原理" class="headerlink" title="一、图像原理"></a>一、图像原理</h2><p>在了解卷积神经网络前，我们先来看看图像的原理：</p><p>图像在计算机中是一堆按顺序排列的数字，<strong>数值为0到255</strong>。0表示最暗，255表示最亮。 如下图：</p><p><img src="287528d32ff227a9af61142bafa481a3.gif" alt="img"></p><p>上图是只有黑白颜色的灰度图，而更普遍的图片表达方式是RGB颜色模型，即红、绿、蓝三原色的色光以不同的比例相加，以产生多种多样的色光。RGB颜色模型中，单个矩阵就扩展成了有序排列的三个矩阵，也可以用三维张量去理解。</p><p>其中的<strong>每一个矩阵</strong>又叫这个图片的一个<strong>channel（通道），宽, 高, 深</strong>来描述。</p><p><img src="3ee4d843020005e6c6eca4a7fa1ae539.png" alt="img"></p><h2 id="二、为什么要学习卷积神经网络？"><a href="#二、为什么要学习卷积神经网络？" class="headerlink" title="二、为什么要学习卷积神经网络？"></a>二、为什么要学习卷积神经网络？</h2><p>在传统神经网络中，我们要识别下<strong>图红色框中</strong>的图像时，我们很可能识别不出来，因为这六张图的<img src="d871cc8ec807852aab00f6e1595dbdd2.png" alt="img">位置都不同，计算机<strong>无法分辨出</strong>他们其实是一种形状或物体。</p><p><img src="4328b16077353c4f549246917d140cac.png" alt="img"></p><p> <strong>传统神经网络</strong>原理如下图：</p><p><img src="8cbc62e0ef1552e85c47a13cbbe57f08.png" alt="img"></p><p>我们希望一个物体不管在画面左侧还是右侧，都会被识别为同一物体，这一特点就是<strong>不变性</strong>。为了实现平移不变性，<strong>卷积神经网络</strong>（CNN）等深度学习模型<strong>在卷积层中使用了卷积操作</strong>，这个操作可以捕捉到图像中的局部特征而不受其位置的影响。</p><p><img src="6e3f9cbdf2b3caa4ca3e9b2ade9856bf.png" alt="img"></p><h2 id="三、什么是卷积？"><a href="#三、什么是卷积？" class="headerlink" title="三、什么是卷积？"></a>三、什么是卷积？</h2><p>在卷积神经网络中，卷积操作是指将一个<strong>可移动的小窗口</strong>（称为数据窗口，如下图绿色矩形）与图像进行<strong>逐元素相乘然后相加</strong>的操作。这个小窗口其实是<strong>一组固定的权重</strong>，它可以被看作是一个特定的<strong>滤波器</strong>（filter）或<strong>卷积核</strong>。这个操作的名称“卷积”，源自于这种元素级相乘和求和的过程。这一操作是卷积神经网络名字的来源。</p><p><img src="7e9292ea51a94bae998fc2a3239eedfc.png" alt="img"></p><p>上图这个绿色小窗就是数据窗口。简而言之，<strong>卷积操作就是用一个可移动的小窗口来提取图像中的特征</strong>，这个小窗口包含了一组特定的权重，通过与图像的不同位置进行卷积操作，网络能够学习并捕捉到不同特征的信息。文字解释可能太难懂，下面直接上动图：</p><p><img src="d0172774f7e42ae2f6310b63e59b4906.gif" alt="img"></p><p>这张图中<strong>蓝色的框</strong>就是指一个数据窗口，红色框为卷积核（滤波器），最后得到的绿色方形就是卷积的结果（数据窗口中的数据与卷积核逐个元素相乘再求和）</p><h4 id="一张图带你了解卷积计算过程："><a href="#一张图带你了解卷积计算过程：" class="headerlink" title="一张图带你了解卷积计算过程："></a>一张图带你了解卷积计算过程：</h4><p><img src="7b8af7c9507e7652df6ff7e3c14f8a1f.png" alt="img"></p><h4 id="卷积需要注意哪些问题？"><a href="#卷积需要注意哪些问题？" class="headerlink" title="卷积需要注意哪些问题？"></a>卷积需要注意哪些问题？</h4><p>a. <strong>步长stride</strong>：每次滑动的位置步长。</p><p>b. <strong>卷积核的个数</strong>：决定输出的depth厚度。同时代表卷积核的个数。</p><p>c. <strong>填充值zero-padding</strong>：在外围边缘补充若干圈0，方便从初始位置以步长为单位可以刚好滑倒末尾位置，通俗地讲就是为了总长能被步长整除。</p><p>以上图为例，那么：</p><ul><li>数据窗口每次移动两个步长取 3*3 的局部数据，即 stride=2 。</li><li>两个神经元，即 depth=2 ，意味着有两个滤波</li><li>zero-padding=1 。</li></ul><h4 id="为什么要进行数据填充："><a href="#为什么要进行数据填充：" class="headerlink" title="为什么要进行数据填充："></a>为什么要进行数据填充：</h4><p>假设有一个大小为 4x4 的输入图像：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[1,  2,  3,  4 ],</span><br><span class="line"> [5,  6,  7,  8 ], </span><br><span class="line"> [9,  10, 11, 12], </span><br><span class="line"> [13, 14, 15, 16]]</span><br></pre></td></tr></table></figure><p>现在，我们要应用一个 3x3 的卷积核进行卷积操作，步幅（stride）为 1，且要使用填充（padding）为 1。如果不使用填充，<strong>卷积核的中心将无法对齐到输入图像的边缘</strong>，导致输出特征图尺寸变小。假设我们使用步幅（stride）为 1 进行卷积，那么在不使用填充的情况下，输出特征图的尺寸将是 2x2。</p><p>所以我们要在它的周围填充一圈0，填充为 1 意味着在输入图像的周围添加一圈零值。添加填充后的图像：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[0, 0,  0,  0,  0,  0], </span><br><span class="line"> [0, 1,  2,  3,  4,  0], </span><br><span class="line"> [0, 5,  6,  7,  8,  0], </span><br><span class="line"> [0, 9,  10, 11, 12, 0], </span><br><span class="line"> [0, 13, 14, 15, 16, 0], </span><br><span class="line"> [0, 0,  0,  0,  0,  0]]</span><br></pre></td></tr></table></figure><p>现在，我们将 3x3 的卷积核应用于这个填充后的输入图像，计算卷积结果，得到大小不变的特征图。</p><p>数据填充的主要目的是<strong>确保卷积核能够覆盖输入图像的边缘区域，同时保持输出特征图的大小</strong>。这对于在CNN中保留空间信息和有效处理图像边缘信息非常重要。</p><h4 id="卷积神经网络的模型是什么样的？"><a href="#卷积神经网络的模型是什么样的？" class="headerlink" title="卷积神经网络的模型是什么样的？"></a>卷积神经网络的模型是什么样的？</h4><p><img src="e76acb80eeb8bff2a722727bcc090336.png" alt="img"></p><p>上面红框框起来的部分便可以<strong>理解为一个滤波器</strong>，即带着<strong>一组固定权重的神经元</strong>。<strong>多个滤波器叠加便成了卷积层</strong>。</p><h2 id="四、卷积神经网络的构造"><a href="#四、卷积神经网络的构造" class="headerlink" title="四、卷积神经网络的构造"></a>四、卷积神经网络的构造</h2><p><img src="3c266da23107494b04b09683b8427f0e.png" alt="img"></p><ol><li><p><strong>输入层</strong><br>输入层接收原始图像数据。图像通常由三个颜色通道（红、绿、蓝）组成，形成一个二维矩阵，表示像素的强度值。</p></li><li><p><strong>卷积和激活</strong><br>卷积层将输入图像与卷积核进行卷积操作。然后，通过应用激活函数（如ReLU）来引入非线性。这一步使网络能够学习复杂的特征。</p></li><li><p><strong>池化层</strong><br>池化层通过减小特征图的大小来减少计算复杂性。它通过选择池化窗口内的最大值或平均值来实现。这有助于提取最重要的特征。</p></li><li><p><strong>多层堆叠</strong><br>CNN通常由多个卷积和池化层的堆叠组成，以逐渐提取更高级别的特征。深层次的特征可以表示更复杂的模式。</p></li><li><p><strong>全连接和输出</strong><br>最后，全连接层将提取的特征映射转化为网络的最终输出。这可以是一个分类标签、回归值或其他任务的结果。</p></li></ol><p>形象的过程如下图：</p><div><table frame="void">    <!--用了<div>进行封装-->    <tr>        <td><div><center>    <!--每个格子内是图片加标题-->            <img src="487282ce8ead390f92a390a1471bb65b-1756040177840-66.gif" alt height="300">    <!--高度设置-->            <br>    <!--换行-->            展开形式    <!--标题1-->        </center></div></td>             <td><div><center>    <!--第二张图片-->            <img src="22ee60a67e1fad3d7dba9cbef60c9c11.png" alt="Typora-Logo" height="300">                <br>            未展开形式        </center></div></td>    </tr></table></div><h2 id="五、图片经过卷积后的样子"><a href="#五、图片经过卷积后的样子" class="headerlink" title="五、图片经过卷积后的样子"></a>五、图片经过卷积后的样子</h2><p>与人眼观看事物原理相似，卷积神经网络可以看到事物的轮廓</p><p><img src="34501738b7bedc58964269aef8305ee3.png" alt="img"></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;卷积神经网络（CNN）的原理&quot;&gt;&lt;a href=&quot;#卷积神经网络（CNN）的原理&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络（CNN）的原理&quot;&gt;&lt;/a&gt;卷积神经网络（CNN）的原理&lt;/h1&gt;</summary>
    
    
    
    <category term="504医学AI" scheme="http://example.com/categories/504%E5%8C%BB%E5%AD%A6AI/"/>
    
    
    <category term="神经网络" scheme="http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>神经网络</title>
    <link href="http://example.com/2025/08/24/BasicKnowledge/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://example.com/2025/08/24/BasicKnowledge/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</id>
    <published>2025-08-23T16:00:00.000Z</published>
    <updated>2025-09-16T08:44:51.519Z</updated>
    
    <content type="html"><![CDATA[<h1 id="神经网络：构建人工智能的基石"><a href="#神经网络：构建人工智能的基石" class="headerlink" title="神经网络：构建人工智能的基石"></a>神经网络：构建人工智能的基石</h1><h2 id="引言："><a href="#引言：" class="headerlink" title="引言："></a>引言：</h2><p>神经网络是一种受到生物神经系统启发的人工智能模型，它重现了大脑中神经元之间相互连接的方式。神经网络在诸多领域中取得了显著成就，如图像识别、自然语言处理和语音识别等。这篇博客将为您解释神经网络的构造，让您能够理解这个令人着迷的领域的基本工作原理。</p><h2 id="第一部分：神经元-生物的灵感"><a href="#第一部分：神经元-生物的灵感" class="headerlink" title="第一部分：神经元 - 生物的灵感"></a>第一部分：神经元 - 生物的灵感</h2><p>在理解神经网络之前，我们首先需要了解神经元，这是神经网络的基本构建块。神经元是生物神经系统的工作单位，也是人工神经网络的灵感来源。</p><ol><li><strong>神经元的结构</strong>：每个神经元都由细胞体、树突和轴突组成。细胞体包含核心部分，树突接收来自其他神经元的信号，而轴突将信号传递给其他神经元。</li></ol><p><img src="433a95388fe6d77be007a09297c55689.png" alt="img"></p><ol><li><strong>信号传递</strong>：神经元之间的通信是通过电化学信号完成的。当信号通过树突传递到细胞体时，如果达到一定阈值，神经元就会触发并将信号传递给下一个神经元。</li></ol><h2 id="第二部分：人工神经元-数学的力量"><a href="#第二部分：人工神经元-数学的力量" class="headerlink" title="第二部分：人工神经元 - 数学的力量"></a>第二部分：人工神经元 - 数学的力量</h2><p>现在，让我们将生物神经元的概念转化为数学模型，即人工神经元。人工神经元是神经网络的基本构建块，负责对输入进行处理和传递信号。输入可以类比为神经元的树突，而输出可以类比为神经元的轴突，计算则可以类比为细胞核。</p><p><strong>输入和权重</strong>：人工神经元接收多个输入，每个输入都有一个相关联的权重，这相当于人工神经网络的记忆。这些权重决定了每个输入对神经元的影响程度。</p><p><img src="c93d132a57bb9b8c00efeb7722306eef.png" alt="img"></p><p><strong>激活函数</strong>：在人工神经元中，激活函数决定了神经元是否激活（发送信号）。常见的激活函数包括Sigmoid、ReLU和Tanh。</p><p><img src="image-20250824204023063.png" alt="image-20250824204023063"></p><p><strong>神经网络</strong>：是由大量的节点（或称“神经元”）和之间相互的联接构成。而由两层神经元组成的神经网络称之为—“感知器”（Perceptron）,感知器只能线性划分数据。在输入和权值的线性加权和叠加了一个<strong>函数g（激活函数），</strong>加权计算公式为：</p><script type="math/tex; mode=display">g(W * x) = z</script><h2 id="第三部分：神经网络-层层堆叠"><a href="#第三部分：神经网络-层层堆叠" class="headerlink" title="第三部分：神经网络 - 层层堆叠"></a>第三部分：神经网络 - 层层堆叠</h2><p>现在我们可以将多个人工神经元组合在一起，形成神经网络。神经网络由多个层组成，包括输入层、隐藏层和输出层，也称为<strong>多层感知器</strong>。</p><p>在神经网络中需要默认增加偏置神经元（节点），这些节点是默认存在的。它本质上是一个只含有存储功能，且存储值永远为1的单元。在神经网络的每个层次中，除了输出层以外，都会含有这样一个<strong>偏置单元</strong>。（如下图）</p><p><img src="image-20250824204143959.png" alt="image-20250824204143959"></p><p><strong>输入层</strong>：接收原始数据的输入，例如图像像素或文本单词。</p><p><strong>隐藏层</strong>：这是神经网络的核心部分，包含多个层次的神经元。隐藏层负责从输入中学习特征并生成有用的表示。</p><p><strong>输出层</strong>：根据学到的特征生成最终的输出，可以是分类标签、数值或其他任务相关的结果。</p><p><strong>如何设计</strong>：</p><p>输入层的节点数：与特征的维度匹配</p><p>输出层的节点数：与目标的维度匹配。</p><p>中间层的节点数：目前业界没有完善的理论来指导这个决策。一般是根据经验来设置。较好的方法就是预先设定几个可选值，通过切换这几个值来看整个模型的预测效果，选择效果最好的值作为最终选择。</p><p><strong>注意事项：</strong></p><ol><li><p>设计一个神经网络时，输入层与输出层的节点数往往是固定的，中间层则可以自由指定；</p></li><li><p>神经网络结构图中的拓扑与箭头代表着预测过程时数据的流向，跟训练时的数据流有一定的区别；</p></li><li><p>结构图里的关键不是圆圈（代表“神经元”），而是连接线（代表“神经元”之间的连接）。每个连接线对应一个不同的权重（其值称为权值），这是需要训练得到的。</p></li></ol><h2 id="第四部分：训练神经网络-损失函数和反向传播算法"><a href="#第四部分：训练神经网络-损失函数和反向传播算法" class="headerlink" title="第四部分：训练神经网络 - 损失函数和反向传播算法"></a>第四部分：训练神经网络 - 损失函数和反向传播算法</h2><p>神经网络的关键部分之一是训练过程。在训练中，神经网络通过与真实数据进行比较来调整权重，以使其能够做出准确的预测。</p><ol><li><p><strong>反向传播算法</strong>：是训练神经网络的核心算法。它通过计算误差并反向传播，以更新每个神经元的权重和偏差，从而减小预测误差。具体过程如何实现，可以看我的这篇博客：（了解BP神经网络：从原理到应用-CSDN博客）</p></li><li><p><strong>损失函数</strong>：损失函数用于度量预测和实际值之间的差异。训练的目标是最小化损失函数。具体过程如何实现，可以看我的这篇博客：（交叉熵损失函数）</p></li></ol><h2 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h2><p>神经网络是人工智能领域的关键技术，它们的构造基于神经元的灵感，并结合了数学、统计和机器学习的原理。通过构建和训练神经网络，我们能够解决各种各样的问题，从图像识别到自然语言处理。希望这篇博客能够帮助您更好地理解神经网络的构造和工作原理。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;神经网络：构建人工智能的基石&quot;&gt;&lt;a href=&quot;#神经网络：构建人工智能的基石&quot; class=&quot;headerlink&quot; title=&quot;神经网络：构建人工智能的基石&quot;&gt;&lt;/a&gt;神经网络：构建人工智能的基石&lt;/h1&gt;</summary>
    
    
    
    <category term="基础知识" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
    <category term="神经网络" scheme="http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Week5</title>
    <link href="http://example.com/2025/08/17/LearningSchedule/Week5/"/>
    <id>http://example.com/2025/08/17/LearningSchedule/Week5/</id>
    <published>2025-08-16T16:00:00.000Z</published>
    <updated>2025-08-22T04:49:11.694Z</updated>
    
    <content type="html"><![CDATA[<h1 id="图像处理方法"><a href="#图像处理方法" class="headerlink" title="图像处理方法"></a>图像处理方法</h1><h2 id="一、Sobel算子"><a href="#一、Sobel算子" class="headerlink" title="一、Sobel算子"></a>一、Sobel算子</h2><ul><li><a href="https://solitudeab.github.io/2025/08/17/膨胀与腐蚀/">OpenCV 图像处理之膨胀与腐蚀 | SolitudeAB</a></li></ul><h3 id="（一）什么是Sobel算子？"><a href="#（一）什么是Sobel算子？" class="headerlink" title="（一）什么是Sobel算子？"></a>（一）什么是Sobel算子？</h3><blockquote><p>Sobel 算子是图像一种图像边缘</p></blockquote><ol><li><p>图像<strong>边缘检测</strong>重要算子之一</p></li><li><p>与<strong>梯度</strong>密度密不可分 -&gt; 目的：图像边缘检测的方法，本质是==梯度运算==</p></li></ol><h3 id="（二）什么情况下会产生梯度？"><a href="#（二）什么情况下会产生梯度？" class="headerlink" title="（二）什么情况下会产生梯度？"></a>（二）什么情况下会产生梯度？</h3><p>利用 3 * 3 的卷积核放在二值图像中有三种位置关系，如下</p><p><img src="image-20250812210603222.png" alt="image-20250812210603222"></p><ul><li><p>全黑全白的像素值是相同的，只有在边缘部位时会有梯度产生。所有，梯度是进行边缘你检测的一个核心(边缘的梯度：255 - 0 = 255)</p><p><img src="image-20250812210754025.png" alt="image-20250812210754025"></p></li></ul><h3 id="（三）Sobel-算子原理"><a href="#（三）Sobel-算子原理" class="headerlink" title="（三）Sobel 算子原理"></a>（三）Sobel 算子原理</h3><ol><li><p>遍历过程</p><ul><li>卷积核顺序放到原图上</li></ul><p><img src="image-20250812211458650.png" alt="image-20250812211458650"></p><ul><li><p>卷积核固定（中间列都是0）</p></li><li><p>卷积核中心位置在中间4x3区域内（对于边缘位置，卷积核暂时无法顾及到）</p></li><li><p>但是卷积核的核心无法顾及到原图像的边缘，如下</p><p><img src="image-20250812211643071.png" alt="image-20250812211643071"></p></li><li><p>解决方法：</p><ul><li><p>法一：边缘列（行）取均值或均值</p></li><li><p>法二（官方给的理论可能性）：<strong>paddng</strong>（边缘加一行 ”补0” ）</p><p><img src="image-20250812212018427.png" alt="image-20250812212018427"></p><blockquote><p>padding为0不改变原图像，此法可以顾及到每一个像素点</p></blockquote></li></ul></li></ul></li><li><p>梯度计算</p><ul><li><p>利用3 <em> 3 的卷积核与原图上顺序遍历的3 </em> 3矩阵（9个像素点）进行梯度计算，得到卷积核中心的梯度（包括 x 方向和 y 方向）</p></li><li><p>Sobel 算子本质上就是一个<strong>权值</strong>矩阵分布：越近的像素权值越高，类似<a href="https://zhuanlan.zhihu.com/p/355263110">高斯滤波</a></p></li><li><p><strong>x 方向</strong>上的梯度</p><ul><li><p>计算结果相当于<code>右边的 * 对应权值 - 左边的 * 对应权值</code></p><p><img src="image-20250813140734644.png" alt="image-20250813140734644"></p></li><li><p>梯度的本质</p><p><img src="image-20250813140951912.png" alt="image-20250813140951912"></p></li><li><p>x 方向上梯度应该考虑的问题：</p><ol><li><p>目标像素点求得的值小于0或者大于255怎么办？</p><p>Opencv默认的是<strong>截断</strong>的操作，即小于0按0算，大于255按255算</p></li><li><p>截断操作合适吗？</p><p>不合适，效果与实际差很大（eg.-200-1 &lt; 0，结果取0）</p></li><li><p>应该如何操作？</p><p>对于小于0的取绝对值，大于255的可按255算（最大的极差了）</p></li></ol></li></ul></li><li><p><strong>y 方向</strong>上的梯度计算</p><ul><li><p>卷积核进行转置（3 * 3）</p></li><li><p>计算结果相当于<code>下边的 * 对应权值 - 上边的 * 对应权值</code></p><p><img src="image-20250813141954017.png" alt="image-20250813141954017"></p></li></ul></li><li><p>总梯度 及 简化梯度</p><p><img src="image-20250813142101411.png" alt="image-20250813142101411"></p></li></ul></li></ol><h2 id="二、x和y方向梯度计算及融合"><a href="#二、x和y方向梯度计算及融合" class="headerlink" title="二、x和y方向梯度计算及融合"></a>二、x和y方向梯度计算及融合</h2><h3 id="（一）sobel-函数"><a href="#（一）sobel-函数" class="headerlink" title="（一）sobel 函数"></a>（一）sobel 函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv2.Sobel(src,depth,dx,du,ksize)</span><br></pre></td></tr></table></figure><ul><li>src: 源图像</li><li>depth: 图像的深度【-1表示与源图像深度一致[表示截断]】[0, 255]</li><li>[cv2.CV_64F: 保留负数部分]</li><li>dx\du: x 和 y 方向的梯度 </li><li>ksize: 卷积核的大小【3, 5】</li></ul><h3 id="（二）depth-1"><a href="#（二）depth-1" class="headerlink" title="（二）depth = -1"></a>（二）depth = -1</h3><ul><li><p>源码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sobelx = cv2.Sobel(img,-1,1,0,ksize=3)</span><br><span class="line">sobely = cv2.Sobel(img,-1,0,1,ksize=3)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line">cv2.imshow(&#x27;sobelx&#x27;, sobelx)</span><br><span class="line">cv2.imshow(&#x27;sobely&#x27;, sobely)</span><br></pre></td></tr></table></figure></li><li><p>效果图（边界）</p><p><img src="image-20250814171814827.png" alt="image-20250814171814827"></p><p>sobelx 的结果为<code>右 - 左</code>，即255 - 0 = 255（左边边界部分为白色，但是右边边界为0 - 255 &lt; 0，根据深度设定为-1自动截断变为0，即黑色），同理，sobely为<code>下 - 上</code>，结果显示上半边界圆</p></li></ul><h3 id="（三）depth-cv2-CV-64F"><a href="#（三）depth-cv2-CV-64F" class="headerlink" title="（三）depth = cv2.CV_64F"></a>（三）depth = cv2.CV_64F</h3><ul><li><p>源码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)</span><br><span class="line"># 将负数转化为整数【绝对值函数】</span><br><span class="line">sobelx = cv2.convertScaleAbs(sobelx)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line">cv2.imshow(&#x27;sobelx&#x27;, sobelx)</span><br></pre></td></tr></table></figure></li><li><p>效果</p><p><img src="%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-08-14%20173217.png" alt="屏幕截图 2025-08-14 173217"></p></li><li><p>注意：如果没有将负数转化为整数【绝对值函数】（即代码中没有<code>sobelx = cv2.convertScaleAbs(sobelx)</code>)，会造成以下<strong>后果</strong></p><ol><li><p><strong>毛刺</strong>：错误的数值映射会导致某些边缘区域出现随机亮斑或暗斑（看起来像噪声）。</p></li><li><p><strong>边缘断裂</strong>：负梯度信息丢失，导致边缘不连续。</p></li></ol><ul><li><p><strong>表现</strong>如下：</p><p><img src="image-20250814200003511.png" alt="image-20250814200003511"></p></li><li><p><strong>原因</strong></p><ol><li><p>Sobel 计算的是图像的梯度（导数），结果可能是 <strong>正数或负数</strong>：</p><ul><li><p><strong>正梯度</strong>：像素从左到右由暗变亮（如 <code>[0, 0, 255]</code>）。</p></li><li><p><strong>负梯度</strong>：像素从左到右由亮变暗（如 <code>[255, 0, 0]</code>）。</p></li></ul></li><li><p>如果直接显示包含负数的 <code>sobelx</code>（<code>cv2.CV_64F</code> 类型），OpenCV 的 <code>imshow()</code> 会尝试将数据强制转换为 <code>uint8</code>（0-255），但负数会被错误处理：</p><ul><li><strong>负值被截断为 0 或溢出</strong>（例如 <code>-100</code> 可能变成 <code>156</code>），导致像素值异常。</li></ul></li></ol></li></ul></li></ul><h3 id="（四）梯度融合"><a href="#（四）梯度融合" class="headerlink" title="（四）梯度融合"></a>（四）梯度融合</h3><ul><li><p>源码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)</span><br><span class="line"># 将负数转化为整数【绝对值函数】</span><br><span class="line">sobelx = cv2.convertScaleAbs(sobelx)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line">cv2.imshow(&#x27;sobelx&#x27;, sobelx)</span><br><span class="line"></span><br><span class="line"># 计算y方向的梯度</span><br><span class="line">sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)</span><br><span class="line"># 将负数转化为整数【绝对值函数】</span><br><span class="line">sobely = cv2.convertScaleAbs(sobely)</span><br><span class="line">cv2.imshow(&#x27;sobely&#x27;, sobely)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># addWeighted()</span><br><span class="line">new_img = cv2.addWeighted(sobelx,0.5,sobely,0.5,0)</span><br><span class="line">cv2.imshow(&#x27;new_img&#x27;, new_img)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>效果</p><blockquote><p>最接近原图的边界</p></blockquote><p><img src="image-20250814201243648.png" alt="image-20250814201243648"></p></li></ul><h2 id="三、Sobel使用建议及实例"><a href="#三、Sobel使用建议及实例" class="headerlink" title="三、Sobel使用建议及实例"></a>三、Sobel使用建议及实例</h2><h3 id="（一）建议"><a href="#（一）建议" class="headerlink" title="（一）建议"></a>（一）建议</h3><ul><li><p>源码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/梯度运算/1.png&quot;, 0)</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">cv2.Sobel(src,depth,dx,du,ksize)</span><br><span class="line">src: 源图像</span><br><span class="line">depth: 图像的深度【-1表示与源图像深度一致[表示截断]】[0, 255]</span><br><span class="line">[cv2.CV_64F: 保留负数部分]</span><br><span class="line">dx\du: x 和 y 方向的梯度 </span><br><span class="line">ksize: 卷积核的大小【3, 5】</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">sobelx = cv2.Sobel(img,-1,1,0,ksize=3)</span><br><span class="line">sobely = cv2.Sobel(img,-1,0,1,ksize=3)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line">cv2.imshow(&#x27;sobelx&#x27;, sobelx)</span><br><span class="line">cv2.imshow(&#x27;sobely&#x27;, sobely)</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 计算x方向的梯度</span><br><span class="line">sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)</span><br><span class="line"># 将负数转化为整数【绝对值函数】</span><br><span class="line">sobelx = cv2.convertScaleAbs(sobelx)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line">cv2.imshow(&#x27;sobelx&#x27;, sobelx)</span><br><span class="line"></span><br><span class="line"># 计算y方向的梯度</span><br><span class="line">sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)</span><br><span class="line"># 将负数转化为整数【绝对值函数】</span><br><span class="line">sobely = cv2.convertScaleAbs(sobely)</span><br><span class="line">cv2.imshow(&#x27;sobely&#x27;, sobely)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># addWeighted()</span><br><span class="line">new_img = cv2.addWeighted(sobelx,0.5,sobely,0.5,0)</span><br><span class="line">cv2.imshow(&#x27;new_img&#x27;, new_img)</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">直接计算融合的x和y的梯度</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">sobelxy = cv2.Sobel(img, cv2.CV_64F,1,1,ksize=3)</span><br><span class="line">sobelxy = cv2.convertScaleAbs(sobelxy)</span><br><span class="line">cv2.imshow(&#x27;sobelxy&#x27;,sobelxy)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.waitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>效果（直接计算融合的x和y的梯度，但是效果不如分开计算后再融合）</p><ol><li><p><strong>没取</strong>绝对值</p><p><img src="image-20250814201953431.png" alt="image-20250814201953431"></p></li><li><p><strong>取</strong>绝对值</p><p><img src="image-20250814201906062.png" alt="image-20250814201906062"></p></li></ol></li></ul><h3 id="（二）实例——轮廓检测"><a href="#（二）实例——轮廓检测" class="headerlink" title="（二）实例——轮廓检测"></a>（二）实例——轮廓检测</h3><ul><li><p>代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 0)</span><br><span class="line"></span><br><span class="line"># 计算x方向的梯度</span><br><span class="line">sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)</span><br><span class="line">sobelx = cv2.convertScaleAbs(sobelx)</span><br><span class="line"># 计算y方向的梯度</span><br><span class="line">sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)</span><br><span class="line">sobely = cv2.convertScaleAbs(sobely)</span><br><span class="line"># addWeighted()</span><br><span class="line">new_img = cv2.addWeighted(sobelx,0.5,sobely,0.5,0)</span><br><span class="line">cv2.imshow(&#x27;new_img&#x27;, new_img)</span><br></pre></td></tr></table></figure></li><li><p>效果</p><p><img src="317cfa878911bf8442642b3300dcb13e.png" alt="317cfa878911bf8442642b3300dcb13e"></p></li></ul><h2 id="四、拉普拉斯算子（Laplacian算子）"><a href="#四、拉普拉斯算子（Laplacian算子）" class="headerlink" title="四、拉普拉斯算子（Laplacian算子）"></a>四、拉普拉斯算子（Laplacian算子）</h2><h3 id="（一）拉普拉斯算子原理"><a href="#（一）拉普拉斯算子原理" class="headerlink" title="（一）拉普拉斯算子原理"></a>（一）拉普拉斯算子原理</h3><ul><li><p>是轮廓检测，也是梯度运算的算子之一</p></li><li><p>是 Sobel 算子的<strong>二阶导</strong>，卷积核和Sobel 算子不一样</p></li><li><p>能够检测 Sobel 算子无法检测到的非常细节的轮廓</p></li><li><p>但是同样能够检测噪声，即对噪声比较敏感，所以一般不会单独使用Laplacian算子</p></li><li><p>直接计算P5点（核心点）的梯度，没必要再计算x方向和y方向的梯度再进行融合</p><p><img src="image-20250815155924679.png" alt="image-20250815155924679"></p></li></ul><h3 id="（二）代码演示"><a href="#（二）代码演示" class="headerlink" title="（二）代码演示"></a>（二）代码演示</h3><ul><li><p>源码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;&quot;</span><br><span class="line">拉普拉斯算子:</span><br><span class="line">问题: 对噪音比较敏感, 一般不单独使用</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line"># img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/梯度运算/1.png&quot;, 0)</span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 0)</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">cv2.Laplacian(src,depth):</span><br><span class="line">src: 源图像</span><br><span class="line">depth:图像深度【-1表示与源图像深度一致】</span><br><span class="line">cv2.CV_64F: 表示保留负值部分</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">new_img = cv2.Laplacian(img,cv2.CV_64F)</span><br><span class="line">new_img = cv2.convertScaleAbs(new_img)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line">cv2.imshow(&#x27;new_img&#x27;, new_img)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.waitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>效果</p><p><img src="image-20250815161126620.png" alt="image-20250815161126620"></p><p><img src="image-20250815161454855.png" alt="image-20250815161454855"></p><ul><li>像素点对于噪音非常敏感，故而得到的结果整体上来看缺失很多</li></ul></li></ul><h2 id="五、算子总结"><a href="#五、算子总结" class="headerlink" title="五、算子总结"></a>五、算子总结</h2><ul><li><p>Sobel 算子和 Scharr 算子需要算分别 x 和 y ，它们的本质差别在于中心像素点附近的权值不一样，导致Scarr算子能够得到细微的轮廓</p></li><li><p>拉普拉斯算子不需要算 x 和 y 因为太精细了，甚至于会将噪声当作轮廓提前，所以一般不使用它</p></li><li><p>三个算子的本质区别就是卷积核不一样</p><p><img src="image-20250815162626923-1755246387930-2.png" alt="image-20250815162626923"></p></li></ul><h2 id="六、Canny边缘检测原理"><a href="#六、Canny边缘检测原理" class="headerlink" title="六、Canny边缘检测原理"></a>六、Canny边缘检测原理</h2><h3 id="（一）边缘检测步骤"><a href="#（一）边缘检测步骤" class="headerlink" title="（一）边缘检测步骤"></a>（一）边缘检测步骤</h3><ol><li><p>应用<strong>高斯滤波器</strong>，以平滑图像，滤除噪声。【降噪】</p><p><img src="image-20250816200502523.png" alt="image-20250816200502523"></p></li><li><p>计算图像中每个像素点的<strong>梯度</strong>大小（各种算子）和方向。【梯度】</p><p><img src="image-20250816200605157.png" alt="image-20250816200605157"></p><p><img src="image-20250816200743108.png" alt="image-20250816200743108"></p></li><li><p>使用非极大值抑制，消除和边缘检测带来的不利影响（滤除干扰）。【非极大值检测】</p><p><img src="image-20250816201545678.png" alt="image-20250816201545678"></p></li><li><p>应用双阈值检测确定真实和潜在的边缘（消除假边缘）。【双阈值检测】</p><p><img src="image-20250816201907951.png" alt="image-20250816201907951"></p></li><li><p>通过抑制孤立的弱边缘（假边缘）完成边缘检测。【完成检测】</p><p><img src="image-20250816201959960.png" alt="image-20250816201959960"></p></li></ol><h3 id="（二）完成Canny边缘检测"><a href="#（二）完成Canny边缘检测" class="headerlink" title="（二）完成Canny边缘检测"></a>（二）完成Canny边缘检测</h3><ul><li><p>代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(r&#x27;/home/jiax/workspace/Python Learning/Opencv-course/gray.jpg&#x27;, 0)</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">cv.Canny(src,min,max) 双阈值检测</span><br><span class="line">src: 源图像</span><br><span class="line">min: 最小阈值</span><br><span class="line">max: 最大阈值</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">new_img = cv2.Canny(img,100,200)</span><br><span class="line">new_img1 = cv2.Canny(img,80,200)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line">cv2.imshow(&#x27;new_img&#x27;, new_img)</span><br><span class="line">cv2.imshow(&#x27;new_img1&#x27;, new_img1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.waitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>效果</p><p><img src="image-20250816195146823.png" alt="image-20250816195146823"></p></li><li><p>关键在于阈值的确定，可以根据阈值的确定来指定需要的边界</p></li></ul><h2 id="七、图像金字塔原理解析"><a href="#七、图像金字塔原理解析" class="headerlink" title="七、图像金字塔原理解析"></a>七、图像金字塔原理解析</h2><h3 id="（一）什么是图像金字塔"><a href="#（一）什么是图像金字塔" class="headerlink" title="（一）什么是图像金字塔"></a>（一）什么是图像金字塔</h3><p><img src="image-20250816203016996.png" alt="image-20250816203016996"></p><ul><li>level0：原始图片</li></ul><h3 id="（二）图像金字塔的目的"><a href="#（二）图像金字塔的目的" class="headerlink" title="（二）图像金字塔的目的"></a>（二）图像金字塔的目的</h3><p><img src="image-20250816203110845.png" alt="image-20250816203110845"></p><h3 id="（三）高斯金字塔"><a href="#（三）高斯金字塔" class="headerlink" title="（三）高斯金字塔"></a>（三）高斯金字塔</h3><ul><li><p>沿着箭头方向图像做如下操作，依次得到每层图像</p></li><li><p>向下采样（必然有信息的丢失）</p><p><img src="image-20250816204829487.png" alt="image-20250816204829487"></p><p><img src="image-20250816205438313.png" alt="image-20250816205438313"></p></li><li><p>向上采样</p><p><img src="image-20250816205303298.png" alt="image-20250816205303298"></p><p><img src="image-20250816205455408.png" alt="image-20250816205455408"></p></li></ul><h2 id="八、拉普拉斯金字塔"><a href="#八、拉普拉斯金字塔" class="headerlink" title="八、拉普拉斯金字塔"></a>八、拉普拉斯金字塔</h2><ul><li><p>由高斯金字塔变换得到的</p></li><li><p>图像先缩小，再放大，再相减，循环操作一次得到各个层图像</p><p><img src="image-20250816210330080.png" alt="image-20250816210330080"></p></li></ul><h2 id="九、图像轮廓检测"><a href="#九、图像轮廓检测" class="headerlink" title="九、图像轮廓检测"></a>九、图像轮廓检测</h2><h3 id="（一）边缘和轮廓辨析"><a href="#（一）边缘和轮廓辨析" class="headerlink" title="（一）边缘和轮廓辨析"></a>（一）边缘和轮廓辨析</h3><ol><li>边缘检测能够检测出边缘，但是<strong>边缘是不连续</strong>的。</li><li>将边缘连接成一个整体，构成轮廓。</li></ol><h3 id="（二）图像轮廓检测中注意的问题"><a href="#（二）图像轮廓检测中注意的问题" class="headerlink" title="（二）图像轮廓检测中注意的问题"></a>（二）图像轮廓检测中注意的问题</h3><ol><li><p>对象是<strong>二值图像</strong>，所以需要进行<strong>阈值分割</strong>。</p></li><li><p>在Opencv中，<strong>背景必须是黑色的</strong>，对象必须是白色的。</p><p>因为自动从黑色背景中找白色的轮廓。</p></li></ol><h3 id="（三）查找图像轮廓函数"><a href="#（三）查找图像轮廓函数" class="headerlink" title="（三）查找图像轮廓函数"></a>（三）查找图像轮廓函数</h3><ol><li><p>函数主体</p><p><img src="image-20250817210830663.png" alt="image-20250817210830663"></p><p><img src="image-20250817211655029.png" alt="image-20250817211655029"></p></li><li><p>函数返回值（三个）</p><p><img src="image-20250817211953894.png" alt="image-20250817211953894"></p></li></ol><h3 id="（四）轮廓绘制函数"><a href="#（四）轮廓绘制函数" class="headerlink" title="（四）轮廓绘制函数"></a>（四）轮廓绘制函数</h3><p><img src="image-20250817211942081.png" alt="image-20250817211942081"></p><h2 id="十、使用Python完成轮廓检测"><a href="#十、使用Python完成轮廓检测" class="headerlink" title="十、使用Python完成轮廓检测"></a>十、使用Python完成轮廓检测</h2><ul><li><p>代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line"></span><br><span class="line"># 读取彩色图片</span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/梯度运算/color.png&quot;,1)</span><br><span class="line"># 将彩色图片转化为灰度图</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"># 将灰度图转化为二值图</span><br><span class="line">ret,binary = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)</span><br><span class="line"></span><br><span class="line"># 寻找图像的轮廓</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">由于opencv版本的原因:</span><br><span class="line">2 -&gt; cv2.findContours 两个返回值(contours,hie)</span><br><span class="line">3 -&gt; cv2.findContours 三个返回值(img,contours,hie)</span><br><span class="line">4 -&gt; cv2.findContours 两个返回值(contours,hie)</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">contours,hie = \</span><br><span class="line">cv2.findContours(binary,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)</span><br><span class="line"></span><br><span class="line"># 对原始图像进行复制</span><br><span class="line">draw_img = img.copy()</span><br><span class="line"># 绘制轮廓</span><br><span class="line">new_img = cv2.drawContours(draw_img, contours, -1, (0,0,255), 2)</span><br><span class="line"></span><br><span class="line">cv2.imshow(&quot;img&quot;, img)</span><br><span class="line">cv2.imshow(&quot;new_img&quot;, new_img)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.waitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>效果</p><p><img src="image-20250817221548172.png" alt="image-20250817221548172"></p></li><li><p>注意点：</p><ol><li><p>为什么要将彩色图片先转化成灰度图，如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 读取彩色图片</span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/梯度运算/color.png&quot;,1)</span><br><span class="line"># 将彩色图片转化为灰度图</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"># 将灰度图转化为二值图</span><br><span class="line">ret,binary = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)</span><br></pre></td></tr></table></figure><p>答：在二维的灰度图（new_img 是 灰度图 img 的副本）上绘制BGR三通道的彩色轮廓是不可能的。如果是灰度图的话需要用彩色图片的读取方式（1）读取，然后依次转化</p></li><li><p>由于opencv版本的原因:</p><p><code>2</code> -&gt; <code>cv2.findContours</code> 两个返回值(contours,hie)</p><p><code>3</code> -&gt;<code>cv2.findContours</code> 三个返回值(img,contours,hie)</p><p><code>4</code>-&gt; <code>cv2.findContours</code> 两个返回值(contours,hie)</p></li><li><p>为什么要对 img 进行复制</p><p><code>new_img = cv2.drawContours(draw_img, contours, -1, (0,0,255), 2)</code>会对传入的 <code>src</code> 同时进行修改，改变原始图像，而此刻的img需要呈现出来与结果对比，不可改变</p></li></ol></li></ul><h2 id="十一、图像均衡化原理"><a href="#十一、图像均衡化原理" class="headerlink" title="十一、图像均衡化原理"></a>十一、图像均衡化原理</h2><h3 id="（一）直方图"><a href="#（一）直方图" class="headerlink" title="（一）直方图"></a>（一）直方图</h3><ol><li><p>直方图做了什么事情 ？</p><p>直方图进行了像素点个数的统计</p></li><li><p>绘制直方图的目的是什么？</p><p><strong>图像的均衡化处理</strong></p><p><img src="image-20250822113352136.png" alt="image-20250822113352136"></p></li></ol><h3 id="（二）什么是均衡化？"><a href="#（二）什么是均衡化？" class="headerlink" title="（二）什么是均衡化？"></a>（二）什么是均衡化？</h3><ul><li>将尖瘦的直方图平均一些，变为宽胖的直方图</li><li><strong>本质</strong>：平衡图像矩阵内的元素</li></ul><h3 id="（三）如何均衡化？"><a href="#（三）如何均衡化？" class="headerlink" title="（三）如何均衡化？"></a>（三）如何均衡化？</h3><ol><li>统计灰度图原始像素点各灰度值个数并分别计算比例</li><li>根据<strong>累计</strong>比例（从前往后加）调整灰度值（累计比例 * 255 并取整）</li><li>最后将处理后的灰度值回填到相应像素点</li></ol><p><img src="image-20250822114143384.png" alt="image-20250822114143384"></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;图像处理方法&quot;&gt;&lt;a href=&quot;#图像处理方法&quot; class=&quot;headerlink&quot; title=&quot;图像处理方法&quot;&gt;&lt;/a&gt;图像处理方法&lt;/h1&gt;</summary>
    
    
    
    <category term="504医学AI" scheme="http://example.com/categories/504%E5%8C%BB%E5%AD%A6AI/"/>
    
    
    <category term="504医学AI入门" scheme="http://example.com/tags/504%E5%8C%BB%E5%AD%A6AI%E5%85%A5%E9%97%A8/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV 图像处理之膨胀与腐蚀</title>
    <link href="http://example.com/2025/08/17/BasicKnowledge/%E8%86%A8%E8%83%80%E4%B8%8E%E8%85%90%E8%9A%80/"/>
    <id>http://example.com/2025/08/17/BasicKnowledge/%E8%86%A8%E8%83%80%E4%B8%8E%E8%85%90%E8%9A%80/</id>
    <published>2025-08-16T16:00:00.000Z</published>
    <updated>2025-09-16T08:44:39.493Z</updated>
    
    <content type="html"><![CDATA[<h1 id="OpenCV-图像处理之膨胀与腐蚀"><a href="#OpenCV-图像处理之膨胀与腐蚀" class="headerlink" title="OpenCV 图像处理之膨胀与腐蚀"></a>OpenCV 图像处理之膨胀与腐蚀</h1><blockquote><p>参考文献：<a href="https://zhuanlan.zhihu.com/p/110330329#:~:text=膨胀与腐蚀属于形态学范围，具体的含义根据字面意思来理解即可。但是更形象的话就是“增肥”与“减肥”。">OpenCV 图像处理之膨胀与腐蚀 - 知乎</a></p></blockquote><h2 id="1、什么是膨胀与腐蚀"><a href="#1、什么是膨胀与腐蚀" class="headerlink" title="1、什么是膨胀与腐蚀"></a>1、什么是膨胀与腐蚀</h2><p>膨胀与腐蚀属于形态学范围，具体的含义根据字面意思来理解即可。但是更形象的话就是“增肥”与“减肥”。</p><p>它们的用途就是用来处理图形问题上。总结性的来说：膨胀用来<strong>处理缺陷</strong>问题；腐蚀用来<strong>处理毛刺</strong>问题。</p><p>膨胀就是把缺陷给填补了，腐蚀就是把毛刺给腐蚀掉了。这里其实说的并不严谨，也是为了大家理解方便。下面我们就用实例来进行演示。</p><h2 id="2、形态学处理——膨胀"><a href="#2、形态学处理——膨胀" class="headerlink" title="2、形态学处理——膨胀"></a>2、形态学处理——膨胀</h2><p>我们先引入一张图片进行分析。 <strong>程序实现：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">&#x27;Pic/corrode.png&#x27;</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cv_show</span>(<span class="params">img</span>):</span><br><span class="line">    cv2.imshow(<span class="string">&#x27;&#x27;</span>, img)</span><br><span class="line">    cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line">cv_show(img)</span><br></pre></td></tr></table></figure><p><img src="v2-8441976eeed9d6e731620cbe2d7400a9_1440w.jpg" alt="img"></p><p>图中我们可以看到，这张图片是一个二值图片（只有黑白），而且还增加了一些<strong>毛刺</strong>。而且还包含字体中还包含一些小的<strong>间隙</strong>（缺陷）。</p><p>下面我们对这张图片进行膨胀处理。膨胀是如何处理的呢？对于一个像素点，我们需要先指定对每个像素点膨胀的范围。</p><p><img src="v2-e5428bbb4a1a35009b7bbd297373996d_1440w.png" alt="img"></p><p>这里我们指定范围为3 <em> 3的矩阵，kernel（卷积核核）指定为全为1的3 </em> 3矩阵，卷积计算后，该像素点的值等于以该像素点为中心的3 * 3范围内的最大值。由于我们是二值图像，所以只要包含周围白的部分，就变为白的。</p><p><strong>总结：</strong> 只要原图片3 <em> 3范围内有白的，该像素点就是白的。 <em>*程序实现：</em></em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kernel = np.ones((<span class="number">3</span>, <span class="number">3</span>), dtype=np.uint8)</span><br><span class="line">dilate = cv2.dilate(img, kernel, <span class="number">1</span>) <span class="comment"># 1:迭代次数，也就是执行几次膨胀操作</span></span><br><span class="line">cv_show(dilate)</span><br></pre></td></tr></table></figure><p><img src="v2-50b146692ac76bf6543086a544b7d231_1440w.jpg" alt="img"></p><p><strong>分析：</strong> 上图我们可以看出毛刺部分变粗，与此同时字体中的间隙也变小，补了缺陷部分。</p><h3 id="2-1-更改卷积核大小"><a href="#2-1-更改卷积核大小" class="headerlink" title="2.1 更改卷积核大小"></a>2.1 更改卷积核大小</h3><p>如果我们<strong>更改核的大小</strong>（4 <em> 4），也就改变了膨胀的程度。 只要4 </em> 4范围内有白的就变成白的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kernel_2 = np.ones((<span class="number">4</span>, <span class="number">4</span>), dtype=np.uint8) <span class="comment"># 卷积核变为4*4</span></span><br><span class="line">dilate = cv2.dilate(img, kernel_2, <span class="number">1</span>)</span><br><span class="line">cv_show(dilate)</span><br></pre></td></tr></table></figure><p><img src="v2-56322fcf1eaf37473273ac595d0d444d_1440w.jpg" alt="img"></p><h3 id="2-2、更改迭代次数"><a href="#2-2、更改迭代次数" class="headerlink" title="2.2、更改迭代次数"></a>2.2、更改迭代次数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kernel = np.ones((<span class="number">3</span>, <span class="number">3</span>), dtype=np.uint8)</span><br><span class="line">dilate = cv2.dilate(img, kernel, <span class="number">2</span>) <span class="comment"># 更改迭代次数为2</span></span><br><span class="line">ss = np.hstack((img, dilate))</span><br><span class="line">cv_show(ss)</span><br></pre></td></tr></table></figure><p><img src="v2-ba19339b6368d200959f2929518c864a_1440w.jpg" alt="img"></p><p><strong>分析：</strong> 更改迭代次数将为2，将对图片进行2次的膨胀操作</p><h2 id="3、形态学处理——腐蚀操作"><a href="#3、形态学处理——腐蚀操作" class="headerlink" title="3、形态学处理——腐蚀操作"></a>3、形态学处理——腐蚀操作</h2><p>腐蚀操作和膨胀操作相反，也就是将毛刺消除，判断方法为：在卷积核大小中对图片进行卷积。取图像中（3 <em> 3）区域内的最小值。由于我们是二值图像，也就是取0（黑色）。 <strong>总结：</strong> 只要原图片3 </em> 3范围内有黑的，该像素点就是黑的。</p><p><strong>程序实现：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kernel = np.ones((<span class="number">3</span>, <span class="number">3</span>), dtype=np.uint8)</span><br><span class="line">erosion = cv2.erode(img, kernel, iterations=<span class="number">1</span>)</span><br><span class="line">ss = np.hstack((img, erosion))</span><br><span class="line">cv_show(ss)</span><br></pre></td></tr></table></figure><p><img src="v2-1be5ef6d3ce04c2d15d70cd47c41913c_1440w.jpg" alt="img"></p><p><strong>分析：</strong> 可以看出来，毛刺部分被清除掉，但与此同时，字体边缘部分也向里凹陷了一部分。</p><h3 id="3-1、更改卷积核大小"><a href="#3-1、更改卷积核大小" class="headerlink" title="3.1、更改卷积核大小"></a>3.1、更改卷积核大小</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kernel_2 = np.ones((<span class="number">4</span>, <span class="number">4</span>), dtype=np.uint8)</span><br><span class="line">erosion = cv2.erode(img, kernel_2, iterations=<span class="number">1</span>)</span><br><span class="line">ss = np.hstack((img, erosion))</span><br><span class="line">cv_show(ss)</span><br></pre></td></tr></table></figure><p><img src="v2-31befc3f8eeaafdaac01e6d2a5057fa1_1440w.jpg" alt="img"></p><p><strong>分析：</strong> 卷积核变大后，我们发现他已经腐蚀的部分有点多了，字体原来的部分也被清除。</p><h3 id="3-2、更改迭代次数"><a href="#3-2、更改迭代次数" class="headerlink" title="3.2、更改迭代次数"></a>3.2、更改迭代次数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kernel = np.ones((<span class="number">3</span>, <span class="number">3</span>), dtype=np.uint8)</span><br><span class="line">erosion = cv2.erode(img, kernel, iterations=<span class="number">2</span>)</span><br><span class="line">ss = np.hstack((img, erosion))</span><br><span class="line">cv_show(ss)</span><br></pre></td></tr></table></figure><p><img src="v2-25cd42fc1dd475828244718b776bf384_1440w.jpg" alt="img"></p><p><strong>分析：</strong> 增加迭代次数后，腐蚀变得更加厉害，所以应该选择合适的迭代次数。</p><h2 id="4、开运算和并运算"><a href="#4、开运算和并运算" class="headerlink" title="4、开运算和并运算"></a>4、开运算和并运算</h2><blockquote><p>开运算：先腐蚀，在膨胀 闭运算：先膨胀，在腐蚀</p></blockquote><p>我们在上面的膨胀和腐蚀的图片中可以看到，图片大小程度上都受到了损失，字体信息缺失或者变粗等等。如果我们不想更改原有信息，即字体粗细。那么我们可以使用上面的两种运算。例如开运算，先对字体进行变细，在对字体进行变粗，整体上字体粗细不会发生变化。毛刺信息在腐蚀的时候就已经消除了，膨胀也不会膨胀出多余信息。</p><h3 id="4-1、开运算"><a href="#4-1、开运算" class="headerlink" title="4.1、开运算"></a>4.1、开运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, <span class="number">1</span>)</span><br><span class="line">ss = np.hstack((img, opening))</span><br><span class="line">cv_show(ss)</span><br></pre></td></tr></table></figure><p><img src="v2-5dba8d78ff5de91c24f5a3bcf5d8bcd2_1440w.jpg" alt="img"></p><p><strong>分析：</strong> 我们发现大部分毛刺已经消除，而且字体信息也没有发生变化，这也就是我们想要的效果。虽然仍然有一部信息没有被清除，我们只需要调整卷积核的大小就可以实现。</p><h3 id="4-2、闭运算"><a href="#4-2、闭运算" class="headerlink" title="4.2、闭运算"></a>4.2、闭运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)  <span class="comment">## 有缺陷，填补缺陷</span></span><br><span class="line">ss = np.hstack((img, closing))</span><br><span class="line">cv_show(ss)</span><br></pre></td></tr></table></figure><p><img src="v2-9731e001feabeb34f519fe37a134cc8f_1440w.jpg" alt="img"></p><p><strong>分析：</strong> 字体不改变的前提下，我们把字体缺陷信息补全。</p><h2 id="5、梯度计算"><a href="#5、梯度计算" class="headerlink" title="5、梯度计算"></a>5、<a href="https://zhida.zhihu.com/search?content_id=112648299&amp;content_type=Article&amp;match_order=1&amp;q=梯度计算&amp;zhida_source=entity">梯度计算</a></h2><p>梯度计算主要显示的是边缘信息。计算的方法：</p><blockquote><p>膨胀的图像 - 腐蚀的图像</p></blockquote><p>我们明显的看出，用大一圈的图像减去小一圈的图像正好就是边缘的信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)</span><br><span class="line">cv_show(gradient)</span><br></pre></td></tr></table></figure><p><img src="v2-cd3d9881414f19c0ae5555ddc28791b6_1440w.jpg" alt="img"></p><p><strong>分析：</strong> 我们可以看出来，我们形成了一个空心的字体样式</p><h2 id="6、高帽和黑帽"><a href="#6、高帽和黑帽" class="headerlink" title="6、高帽和黑帽"></a>6、高帽和黑帽</h2><blockquote><p>高帽计算：原始图像 - 开运算结果 黑帽计算：闭运算结果 - 原始图像</p></blockquote><h3 id="6-1、高帽计算"><a href="#6-1、高帽计算" class="headerlink" title="6.1、高帽计算"></a>6.1、高帽计算</h3><p>我们知道开运算的结果就是去除毛刺，我们原始图像减去开运算结果就是我们要消除的毛刺信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">top_hat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)</span><br><span class="line">ss = np.hstack((img, top_hat))</span><br><span class="line">cv_show(ss)</span><br></pre></td></tr></table></figure><p><img src="v2-49f926bc181d7c73fa6bf96fc384b20a_1440w.jpg" alt="img"></p><p><strong>分析：</strong> 可以看出来，所有的毛刺信息我们全部提取了出来。</p><h3 id="6-2、黑帽操作"><a href="#6-2、黑帽操作" class="headerlink" title="6.2、黑帽操作"></a>6.2、黑帽操作</h3><p>高帽操作<strong>显示毛刺</strong>，那么黑帽就是<strong>显示缺陷</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">black_hat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)</span><br><span class="line">ss = np.hstack((img, black_hat))</span><br><span class="line">cv_show(ss)</span><br></pre></td></tr></table></figure><p><img src="v2-98040e57b398cf5903ae52b77891bb74_1440w.jpg" alt="img"></p><p><strong>分析：</strong> 这里我们看的不是很明显，我们只需要只要黑帽所处理的问题是什么。针对不同的场景应用不用的方法。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;OpenCV-图像处理之膨胀与腐蚀&quot;&gt;&lt;a href=&quot;#OpenCV-图像处理之膨胀与腐蚀&quot; class=&quot;headerlink&quot; title=&quot;OpenCV 图像处理之膨胀与腐蚀&quot;&gt;&lt;/a&gt;OpenCV 图像处理之膨胀与腐蚀&lt;/h1&gt;</summary>
    
    
    
    <category term="基础知识" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
    <category term="OepnCV" scheme="http://example.com/tags/OepnCV/"/>
    
  </entry>
  
  <entry>
    <title>Week4</title>
    <link href="http://example.com/2025/08/10/LearningSchedule/Week4/"/>
    <id>http://example.com/2025/08/10/LearningSchedule/Week4/</id>
    <published>2025-08-09T16:00:00.000Z</published>
    <updated>2025-08-10T12:54:22.233Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Opencv（二）"><a href="#Opencv（二）" class="headerlink" title="Opencv（二）"></a>Opencv（二）</h1><h2 id="一、图像基础知识复习"><a href="#一、图像基础知识复习" class="headerlink" title="一、图像基础知识复习"></a>一、图像基础知识复习</h2><ol><li><p>图像是由像素构成的</p><p>像素点的多少决定了图片的质量（相同图片大小，像素点越多，单个像素点越小，图片质量越好）</p><p><img src="image-20250810124134321.png" alt="image-20250810124134321"></p></li><li><p>图像的分类</p><p><img src="image-20250810124203155.png" alt="image-20250810124203155"></p><ul><li><p>二值图像：像素点非0即1</p><p><img src="image-20250810124322219.png" alt="image-20250810124322219"></p></li><li><p>灰度图像：像素点有256个结果</p><p><img src="image-20250810124332896.png" alt="image-20250810124332896"></p></li><li><p>彩色图像：由三通道（三原色RGB）进行叠加的图像</p><p><img src="image-20250810124404611.png" alt="image-20250810124404611"></p></li></ul></li><li><p>Opencv读取彩色图像的特点</p><ul><li><p>读取结果：BGR（注意顺序）</p></li><li><p>每个像素点由BGR三个分量构成</p><p>例：（245，168，200）-&gt; B：245 、G：168、R：200</p></li></ul></li></ol><h2 id="二、灰度图片像素的选取与修改"><a href="#二、灰度图片像素的选取与修改" class="headerlink" title="二、灰度图片像素的选取与修改"></a>二、灰度图片像素的选取与修改</h2><ul><li><p>源码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">gray_img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg&quot;, 0)</span><br><span class="line">cv2.imshow(&#x27;gray_img&#x27;, gray_img)</span><br><span class="line"></span><br><span class="line"># 选取灰度图像的某个像素点【矩阵-numpy中的数组】</span><br><span class="line">gray_img[100,100]</span><br><span class="line">gray_img[100,200]</span><br><span class="line"></span><br><span class="line"># 选取某些像素点</span><br><span class="line">gray_img[100:200,100:200]</span><br><span class="line"></span><br><span class="line"># 修改像素点[0~255]</span><br><span class="line">gray_img1 = gray_img.copy() # 拷贝</span><br><span class="line">gray_img1[100:200,100:200] = 0</span><br><span class="line"># gray_img1[100:200,100:200] = 100</span><br><span class="line"># gray_img1[100:200,100:200] = 255</span><br><span class="line">cv2.imshow(&#x27;gray_img1&#x27;, gray_img1)</span><br><span class="line"></span><br><span class="line"># 0：表示任意键关闭; 具体数字，表示毫秒</span><br><span class="line">cv2.waitKey() </span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>效果</p><p><img src="%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-08-10%20130828.png" alt="屏幕截图 2025-08-10 130828"></p></li></ul><h2 id="三、显示图片的一些问题"><a href="#三、显示图片的一些问题" class="headerlink" title="三、显示图片的一些问题"></a>三、显示图片的一些问题</h2><ol><li>显示图片时候的“备注“（即<code>cv2.imshow(&#39;gray_img1&#39;, gray_img1</code>中‘ ’内部的内容)作为图片的区分不一致时才可以同时显示多张图片</li><li><code>cv2.waitKey()</code>和<code>cv2.destroyAllWindows()</code>必须同时存在</li></ol><h2 id="四、彩色图片像素的选取与修改"><a href="#四、彩色图片像素的选取与修改" class="headerlink" title="四、彩色图片像素的选取与修改"></a>四、彩色图片像素的选取与修改</h2><ul><li><p>源码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 1)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line"></span><br><span class="line"># 选取彩色图片某个像素点</span><br><span class="line"># BGR -&gt; 指对应的(100,100)的坐标</span><br><span class="line">print(img[100, 100])</span><br><span class="line">print(img[100, 100, 0])</span><br><span class="line">print(img[100, 100, 1])</span><br><span class="line">print(img[100, 100, 2])</span><br><span class="line"></span><br><span class="line"># 选择某些像素点</span><br><span class="line">print(img[100:200,100:200,0])</span><br><span class="line">print(img[100:200,100:200,1])</span><br><span class="line">print(img[100:200,100:200])</span><br><span class="line"></span><br><span class="line"># 修改某个像素点</span><br><span class="line">img1 = img.copy()</span><br><span class="line">img1[100,100,0] = 0</span><br><span class="line">print(img[100,100])</span><br><span class="line">print(img1[100,100])</span><br><span class="line"></span><br><span class="line"># 修改某些像素点</span><br><span class="line">img1[100:200, 100:200,0] = 0</span><br><span class="line">print(img[100:200, 100:200])</span><br><span class="line">print(img1[100:200, 100:200])</span><br><span class="line">img1[100:200, 100:200,1] = 0</span><br><span class="line">print(img[100:200, 100:200])</span><br><span class="line">print(img1[100:200, 100:200])</span><br><span class="line">cv2.imshow(&#x27;img1&#x27;, img1)</span><br><span class="line"></span><br><span class="line">cv2.waitKey() </span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>效果</p><p><img src="image-20250810132859092.png" alt="image-20250810132859092"></p></li></ul><h2 id="五、获取图像的基本属性"><a href="#五、获取图像的基本属性" class="headerlink" title="五、获取图像的基本属性"></a>五、获取图像的基本属性</h2><ul><li><p>源码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line"></span><br><span class="line"># 灰度图像</span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg&quot;, 0)</span><br><span class="line"># cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line"></span><br><span class="line"># 获取灰度图像的形状[二维的元组]</span><br><span class="line">print(img.shape)</span><br><span class="line"># 获取灰度图像的大小[指行*列(像素点的个数)]</span><br><span class="line">print(img.size)</span><br><span class="line"># 图像的数据类型&lt;class &#x27;numpy.ndarray&#x27;&gt;</span><br><span class="line">print(type(img))</span><br><span class="line"># 获取像素点的数据类型 uint8</span><br><span class="line">print(img.dtype)</span><br><span class="line"></span><br><span class="line"># 彩色图片</span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 1)</span><br><span class="line"># cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line"></span><br><span class="line"># 获取彩色图像的形状[三维的元组]</span><br><span class="line">print(img.shape)</span><br><span class="line"># 获取彩色图像的大小[指行*列*通道数(3)]</span><br><span class="line">print(img.size)</span><br><span class="line"># 图像的数据类型&lt;class &#x27;numpy.ndarray&#x27;&gt;</span><br><span class="line">print(type(img))</span><br><span class="line"># 获取像素点的数据类型 uint8</span><br><span class="line">print(img.dtype)</span><br></pre></td></tr></table></figure></li></ul><h2 id="六、提取感兴趣的ROI区域"><a href="#六、提取感兴趣的ROI区域" class="headerlink" title="六、提取感兴趣的ROI区域"></a>六、提取感兴趣的ROI区域</h2><ul><li><p>源码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># ROI区域</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 1)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;,img)</span><br><span class="line"></span><br><span class="line"># 知道图片的shape[(1333, 750, 3)]</span><br><span class="line">print(img.shape)</span><br><span class="line"></span><br><span class="line"># new_img = img[300:800, 100:360]</span><br><span class="line">new_img = img[415:525, 200:300]</span><br><span class="line">cv2.imshow(&#x27;after&#x27;,new_img)</span><br><span class="line"></span><br><span class="line"># 写出新图片</span><br><span class="line">cv2.imwrite(r&#x27;/home/jiax/workspace/Python Learning/Opencv-course/after.jpg&#x27;, new_img)</span><br><span class="line"></span><br><span class="line">img[:110,:100] = new_img</span><br><span class="line">cv2.imshow(&#x27;new_img&#x27;, img)</span><br><span class="line"></span><br><span class="line">img1 = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg&quot;, 1)</span><br><span class="line">img1[:110,:100] = new_img</span><br><span class="line">cv2.imshow(&#x27;new_img1&#x27;, img1)</span><br><span class="line"></span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>ROI区域效果图：</p><p><img src="image-20250810135256764.png" alt="image-20250810135256764"></p><p><img src="image-20250810135806330.png" alt="image-20250810135806330"></p></li></ul><h2 id="七、图像的加法"><a href="#七、图像的加法" class="headerlink" title="七、图像的加法"></a>七、图像的加法</h2><ul><li><p>源码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 图像的加法 -&gt;矩阵</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 1)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line">img1 = img.copy()</span><br><span class="line"></span><br><span class="line"># 加法【前提：必须是一样大的矩阵；对应元素求和】</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">像素点：[0,255]超过255怎么办【取余】</span><br><span class="line">150 + 150 = 300</span><br><span class="line">300 % 255 = 45</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">result1 = img + img1</span><br><span class="line">cv2.imshow(&#x27;result1&#x27;, result1)</span><br><span class="line"></span><br><span class="line"># opencv 提供给了add()函数</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">像素点：[0,255]超过255怎么办【按255算】</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">result2 = cv2.add(img, img1)</span><br><span class="line">cv2.imshow(&#x27;result2&#x27;, result2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>演示效果</p><p><img src="image-20250810193716787.png" alt="image-20250810193716787"></p></li></ul><h2 id="八、图片融合"><a href="#八、图片融合" class="headerlink" title="八、图片融合"></a>八、图片融合</h2><blockquote><p>注意：图片相加不是图片融合</p></blockquote><ul><li><p>源码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># 图片融合：将两张图片放在一张上</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">前提：图片的shape一样</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">img1 = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/1.jpg&quot;, 1)</span><br><span class="line">img2 = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/2.jpg&quot;, 1)</span><br><span class="line"></span><br><span class="line"># 前提：图片的shape一样</span><br><span class="line">print(img1.shape)</span><br><span class="line">print(img2.shape)</span><br><span class="line"></span><br><span class="line"># 图片融合</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">addWeighted(src1, alpha,src2,beta,gamma)</span><br><span class="line">src1\src2：第一张和第二张图片</span><br><span class="line">alpha\beta：第一张图片的权重、第二张图片的权重</span><br><span class="line">gamma：亮度的调节</span><br><span class="line"># </span><br><span class="line">0.8*img1 + 0.2*img2 + gamma</span><br><span class="line">[0, 255]：超过255仍按照255算，即亮度非常大时，图片所有像素点权全为255（全白）</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">result = cv2.addWeighted(img1, 0.8, img2, 0.2, 100)</span><br><span class="line">cv2.imshow(&#x27;img1&#x27;, img1)</span><br><span class="line">cv2.imshow(&#x27;img2&#x27;, img2)</span><br><span class="line">cv2.imshow(&#x27;result&#x27;, result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.waitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>效果：</p><p><img src="image-20250810195225642.png" alt="image-20250810195225642"></p><p><img src="image-20250810195658468.png" alt="image-20250810195658468"></p></li></ul><h2 id="九、-图像的类型转换"><a href="#九、-图像的类型转换" class="headerlink" title="九、 图像的类型转换"></a>九、 图像的类型转换</h2><ul><li><p>源码:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"># 图像的类型转换</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">cv2里面的图像类型转换远远不止介绍的这些，共由两百多个</span><br><span class="line">需要学会自己去查自己想要的转化方式</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 1)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line"></span><br><span class="line"># 原始图片：BGR-&gt;RGB (本质即为0和2列进行了对调)</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">cvtColor(img,way)</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line">cv2.imshow(&#x27;img_rgb&#x27;, img_rgb)</span><br><span class="line"></span><br><span class="line">img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">cv2.imshow(&#x27;img_gray&#x27;, img_gray)</span><br><span class="line"></span><br><span class="line"># 读取灰度图片</span><br><span class="line">img1 = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg&quot;, 1)</span><br><span class="line">cv2.imshow(&#x27;img1&#x27;, img1)</span><br><span class="line">img_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">b, g, r = cv2.split(img1)</span><br><span class="line">cv2.imshow(&#x27;img1&#x27;, img1)</span><br><span class="line">cv2.imshow(&#x27;b&#x27;,b)</span><br><span class="line">cv2.imshow(&#x27;g&#x27;,g)</span><br><span class="line">cv2.imshow(&#x27;r&#x27;,r)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.waitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>效果：</p><p><img src="image-20250810201809881.png" alt="image-20250810201809881"></p><p><img src="image-20250810201859638.png" alt="image-20250810201859638"></p></li></ul><h2 id="十、图像的缩放"><a href="#十、图像的缩放" class="headerlink" title="十、图像的缩放"></a>十、图像的缩放</h2><ul><li><p>源码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># 图像的缩放</span><br><span class="line"># 本质：矩阵的变换</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 1)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">cv2.resize(src, dsize, fx, fy)</span><br><span class="line">src：源图片【需要被缩放的照片img(100*100)】</span><br><span class="line">dsize：缩放到的大小(200*200)[列(W) * 行(H)]</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">size = (1000,500)</span><br><span class="line">new_img = cv2.resize(img, size)</span><br><span class="line">cv2.imshow(&#x27;new_img&#x27;, new_img)</span><br><span class="line"></span><br><span class="line"># 指定列、行的缩放大小</span><br><span class="line">h, w, ch = img.shape</span><br><span class="line">size = (int(0.5*w), int(1.5*h))</span><br><span class="line">new_img1 = cv2.resize(img, size)</span><br><span class="line">cv2.imshow(&#x27;new_img1&#x27;, new_img1)</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">cv2.resize(src, dsize, fx, fy)</span><br><span class="line">src：原图片【需要被缩放的照片img(100*100)】</span><br><span class="line">dsize：None</span><br><span class="line">fx：x方向上的比例</span><br><span class="line">fy：y方向上的比例</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">new_img2 = cv2.resize(img, None, fx=0.5, fy=0.5)</span><br><span class="line">cv2.imshow(&#x27;new_img2&#x27;, new_img2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.waitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>效果：</p><p><img src="image-20250810203427079.png" alt="image-20250810203427079"></p></li></ul><h2 id="十一、图像的翻转"><a href="#十一、图像的翻转" class="headerlink" title="十一、图像的翻转"></a>十一、图像的翻转</h2><ul><li><p>源码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># 图像的翻转</span><br><span class="line"># 本质：矩阵的翻转</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">1. 沿着x轴进行翻转</span><br><span class="line">2. 沿着y轴进行翻转</span><br><span class="line">3. 同时沿着x轴和y轴进行翻转</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/1.jpg&quot;, 1)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">cv2.flip(src, flipCode)</span><br><span class="line">src：源图像</span><br><span class="line">flipCode：翻转形式</span><br><span class="line">    0：沿着x轴进行翻转</span><br><span class="line">    1(大于等于1)：沿着y轴进行翻转</span><br><span class="line">    -1(小于等于-1)：同时沿着x轴和y轴进行翻转</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">new_img1 = cv2.flip(img, 0)</span><br><span class="line">cv2.imshow(&#x27;new_img1&#x27;, new_img1)</span><br><span class="line">new_img2= cv2.flip(img, 1)</span><br><span class="line"># new_img2= cv2.flip(img, 10)</span><br><span class="line">cv2.imshow(&#x27;new_img2&#x27;, new_img2)</span><br><span class="line">new_img3 = cv2.flip(img, -1)</span><br><span class="line"># new_img3 = cv2.flip(img, -10)</span><br><span class="line">cv2.imshow(&#x27;new_img3&#x27;, new_img3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.waitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>效果：</p><p><img src="image-20250810205116045.png" alt="image-20250810205116045"></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Opencv（二）&quot;&gt;&lt;a href=&quot;#Opencv（二）&quot; class=&quot;headerlink&quot; title=&quot;Opencv（二）&quot;&gt;&lt;/a&gt;Opencv（二）&lt;/h1&gt;</summary>
    
    
    
    <category term="504医学AI" scheme="http://example.com/categories/504%E5%8C%BB%E5%AD%A6AI/"/>
    
    
    <category term="504医学AI入门" scheme="http://example.com/tags/504%E5%8C%BB%E5%AD%A6AI%E5%85%A5%E9%97%A8/"/>
    
  </entry>
  
  <entry>
    <title>Week3</title>
    <link href="http://example.com/2025/08/03/LearningSchedule/Week3/"/>
    <id>http://example.com/2025/08/03/LearningSchedule/Week3/</id>
    <published>2025-08-02T16:00:00.000Z</published>
    <updated>2025-08-10T12:54:22.235Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Opencv（二）"><a href="#Opencv（二）" class="headerlink" title="Opencv（二）"></a>Opencv（二）</h1><ul><li><p>上一周学到彩色图片像素点的统计，这一周就从纯黑纯白图片像素点统计开始</p></li><li><p>代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line"></span><br><span class="line"># 读取图片（默认以BGR格式加载）</span><br><span class="line">image = cv2.imread(&#x27;image.jpg&#x27;)</span><br><span class="line"></span><br><span class="line"># 查看矩阵内容</span><br><span class="line">print(image)  # 直接打印整个矩阵</span><br><span class="line">print(image.shape)  # 打印矩阵形状：(高度, 宽度, 通道数)</span><br><span class="line"></span><br><span class="line"># 查看特定像素值（例如第10行第20列的BGR值）</span><br><span class="line">print(image[10, 20])  # 输出格式：[B, G, R]</span><br><span class="line"></span><br><span class="line"># 查看部分矩阵（例如前10行前10列）</span><br><span class="line">print(image[:10, :10])</span><br></pre></td></tr></table></figure></li></ul><h2 id="一、纯黑纯白图片像素点统计"><a href="#一、纯黑纯白图片像素点统计" class="headerlink" title="一、纯黑纯白图片像素点统计"></a>一、纯黑纯白图片像素点统计</h2><ul><li><p>以下为纯白图片(1080, 2298, 3)的像素点统计结果，可与纯黑图片做比对</p><p><img src="image-20250730233541830.png" alt="image-20250730233541830"></p></li><li><p>不存在纯黑的图片（或者计算机很难实现），以下图片是(650, 650, 3)的纯黑图片像素点统计结果，可以看出黑色图片的像素点并不如纯白图片集中，即不如白色纯</p><p><img src="image-20250730233223690.png" alt="image-20250730233223690"></p></li></ul><h2 id="二、随机生成彩色图片"><a href="#二、随机生成彩色图片" class="headerlink" title="二、随机生成彩色图片"></a>二、随机生成彩色图片</h2><ul><li><p>代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">array1 = np.random.randint(0,255,(700,400,3),dtype=np.uint8)</span><br><span class="line"># print(array1)</span><br><span class="line"># cv2.imshow(&#x27;random_pic&#x27;, array1)</span><br><span class="line"># cv2.waitKey()</span><br><span class="line"># cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">array2 = np.random.randint(200,255,(700,400,3),dtype=np.uint8)</span><br><span class="line"># cv2.imshow(&#x27;random_pic&#x27;, array2)</span><br><span class="line"># cv2.waitKey()</span><br><span class="line"># cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">new_array = np.hstack((array1, array2))</span><br><span class="line">cv2.imshow(&#x27;random_pic&#x27;, new_array)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>代码演示效果</p><p><img src="image-20250730234813380.png" alt="image-20250730234813380"></p></li></ul><h2 id="三、彩色图片颜色通道拾遗"><a href="#三、彩色图片颜色通道拾遗" class="headerlink" title="三、彩色图片颜色通道拾遗"></a>三、彩色图片颜色通道拾遗</h2><h3 id="1-查看B-蓝色"><a href="#1-查看B-蓝色" class="headerlink" title="1. 查看B[蓝色]"></a>1. 查看B[蓝色]</h3><ul><li><p>代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 查看B[蓝色]</span><br><span class="line">img_B = img.copy()</span><br><span class="line">img_B[:,:,1] = 0</span><br><span class="line">img_B[:,:,2] = 0</span><br><span class="line">cv2.imshow(&quot;img_B&quot;, img_B)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>代码演示效果</p><p><img src="image-20250731180734098.png" alt="image-20250731180734098"></p></li></ul><h3 id="2-查看G-绿色"><a href="#2-查看G-绿色" class="headerlink" title="2. 查看G[绿色]"></a>2. 查看G[绿色]</h3><ul><li><p>代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 查看G[绿色]</span><br><span class="line">img_G = img.copy()</span><br><span class="line">img_G[:,:,0] = 0</span><br><span class="line">img_G[:,:,2] = 0</span><br><span class="line">cv2.imshow(&quot;img_R&quot;, img_R)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>代码演示效果</p><p><img src="image-20250731180824164.png" alt="image-20250731180824164"></p></li></ul><h3 id="3-查看R-红色"><a href="#3-查看R-红色" class="headerlink" title="3. 查看R[红色]"></a>3. 查看R[红色]</h3><ul><li><p>代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 查看R[红色]</span><br><span class="line">img_R = img.copy()</span><br><span class="line">img_R[:,:,0] = 0</span><br><span class="line">img_R[:,:,1] = 0</span><br><span class="line">cv2.imshow(&quot;img_R&quot;, img_R)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>代码演示效果</p><p><img src="image-20250731180936286.png" alt="image-20250731180936286"></p></li></ul><h3 id="另：有一个需要注意的，和以下代码的效果进行区分"><a href="#另：有一个需要注意的，和以下代码的效果进行区分" class="headerlink" title="另：有一个需要注意的，和以下代码的效果进行区分"></a>另：有一个需要注意的，和以下代码的效果进行区分</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">b,g,r = cv2.split(img)</span><br><span class="line">cv2.imshow(&quot;img_B&quot;, b)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><ul><li><p>采用图像通道分割的结果和置零后分别显示图片的效果不同，<strong>结果并非蓝色</strong></p></li><li><p>效果如下</p><p><img src="image-20250731181742812.png" alt="image-20250731181742812"></p></li></ul><h2 id="四、深入研究图片的读取"><a href="#四、深入研究图片的读取" class="headerlink" title="四、深入研究图片的读取"></a>四、深入研究图片的读取</h2><ul><li><p>cv2.imread(path, way)</p><ul><li><p>0: 读取灰度图片</p></li><li><p>1: 读取彩色图片[默认读取方式]</p></li><li><p>-1: 读取图片，加载Alpha通道</p></li><li>Alpha通道: 指一张图片的透明与不透明度。</li></ul></li><li><p>带有透明度的图片有Alpha通道</p><p><img src="image-20250731182341061.png" alt="image-20250731182341061"></p></li><li><p>代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">img_color = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;)</span><br><span class="line">print(np.shape(img_color))</span><br><span class="line"></span><br><span class="line">img_gray = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg&quot;)</span><br><span class="line">print(np.shape(img_gray))</span><br><span class="line"></span><br><span class="line">img_gray = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg&quot;, -1)</span><br><span class="line">print(np.shape(img_gray))</span><br><span class="line">cv2.imshow(&quot;img_gray&quot;, img_gray)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li></ul><h2 id="五、以灰度方式打开彩色图像原理剖析"><a href="#五、以灰度方式打开彩色图像原理剖析" class="headerlink" title="五、以灰度方式打开彩色图像原理剖析"></a>五、以灰度方式打开彩色图像原理剖析</h2><ul><li><p>如果以0的方式读取彩色图片</p></li><li><p>把三维的图片（BGR三张图片）相同位置的像素点糅合在一起，形成一张新的图片</p></li><li><p>不同形式的图片</p><ol><li><p>原图</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 1)</span><br><span class="line">print(np.shape(img))</span><br><span class="line">cv2.imshow(&quot;img&quot;, img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><p><img src="image-20250802112423865.png" alt="image-20250802112423865"></p></li><li><p>灰度图</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 0)</span><br><span class="line">print(np.shape(img))</span><br><span class="line">cv2.imshow(&quot;img&quot;, img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><p><img src="image-20250802112502848.png" alt="image-20250802112502848"></p></li><li><p>普通的均分叠加（不是图） </p><blockquote><p>推断出来的公式: Y = (B+G+R)/3</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 三通道分离</span><br><span class="line">b,g,r = cv2.split(img)</span><br><span class="line">new_img = (b+g+r)/3</span><br><span class="line">cv2.imshow(&quot;new_img&quot;, new_img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><p><img src="image-20250802112341404.png" alt="image-20250802112341404"></p><p><strong>cv2.imshow()中的参数要求不仅仅是array()，而且数组元素必须是uint8类型的，表示八位深度（0，1），而三通道分离的结果是float类型的</strong></p><p>修改如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">b,g,r = cv2.split(img)</span><br><span class="line">new_img = (b+g+r)/3</span><br><span class="line">new_img = new_img.astype(&#x27;uint8&#x27;)</span><br><span class="line">cv2.imshow(&quot;new_img&quot;, new_img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><p><img src="image-20250802114219650.png" alt="image-20250802114219650"></p></li><li><p>官方公式的三维叠加</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 官方给出的公式: Y = 0.299R + 0.587G + 0.114B</span><br><span class="line">new_img1 =  0.299*r + 0.587*g + 0.114*b</span><br><span class="line">new_img1 = new_img1.astype(&#x27;uint8&#x27;)</span><br><span class="line">cv2.imshow(&quot;new_img1&quot;, new_img1)</span><br><span class="line"></span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><p><img src="image-20250809211133519.png" alt="image-20250809211133519"></p></li></ol></li></ul><blockquote><p>最终得知，灰度图片（即0读取图片的方式）是原彩色图片三通道通过公式Y = 0.299R + 0.587G + 0.114B拟合得出的结果</p></blockquote><h2 id="六、以彩色方式打开灰度图像原理剖析"><a href="#六、以彩色方式打开灰度图像原理剖析" class="headerlink" title="六、以彩色方式打开灰度图像原理剖析"></a>六、以彩色方式打开灰度图像原理剖析</h2><ul><li><p>源码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 以1（彩色图像）的方式打开灰度图像</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">img_color = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg&quot;, 1)</span><br><span class="line">print(img_color.shape)</span><br><span class="line"># cv2.imshow(&#x27;img_color&#x27;, img_color)</span><br><span class="line"></span><br><span class="line"># Opencv 内部如何将灰度图像转化为彩色图像？</span><br><span class="line">&quot;&quot;&quot;&quot;</span><br><span class="line">官方的填充方式：以初始的灰度二维矩阵进行RGB通道的填充</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">img_gray = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg&quot;, 0)</span><br><span class="line">print(img_gray.shape)</span><br><span class="line"></span><br><span class="line">new_img = cv2.merge([img_gray, img_gray, img_gray])</span><br><span class="line">print(new_img.shape)</span><br><span class="line"></span><br><span class="line"># 一定要检查这个新图像的dtype (uint8)</span><br><span class="line">print(new_img.dtype)</span><br><span class="line"># cv2.imshow(&#x27;img_color&#x27;, img_color)</span><br><span class="line"></span><br><span class="line"># 选取部分元素-&gt;验证官方填充方式对于灰度图像转化为彩色图像的正确性</span><br><span class="line">img_color[100,200]</span><br><span class="line">new_img[100,200]</span><br><span class="line"></span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Opencv（二）&quot;&gt;&lt;a href=&quot;#Opencv（二）&quot; class=&quot;headerlink&quot; title=&quot;Opencv（二）&quot;&gt;&lt;/a&gt;Opencv（二）&lt;/h1&gt;</summary>
    
    
    
    <category term="504医学AI" scheme="http://example.com/categories/504%E5%8C%BB%E5%AD%A6AI/"/>
    
    
    <category term="504医学AI入门" scheme="http://example.com/tags/504%E5%8C%BB%E5%AD%A6AI%E5%85%A5%E9%97%A8/"/>
    
  </entry>
  
  <entry>
    <title>Week2</title>
    <link href="http://example.com/2025/07/27/LearningSchedule/Week2/"/>
    <id>http://example.com/2025/07/27/LearningSchedule/Week2/</id>
    <published>2025-07-26T16:00:00.000Z</published>
    <updated>2025-07-27T12:09:50.482Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Opencv"><a href="#Opencv" class="headerlink" title="Opencv"></a>Opencv</h1><h3 id="一、常见的图片格式及图片类型"><a href="#一、常见的图片格式及图片类型" class="headerlink" title="一、常见的图片格式及图片类型"></a>一、常见的图片格式及图片类型</h3><ul><li><p>图片格式</p><ol><li><p>bmp：比较老的格式|不常见|无损-&gt;基本上无压缩|体积大|被淘汰</p></li><li><p>jpg（jpeg）：用<strong>最少的磁盘空间</strong>得到<strong>较好的图片质量</strong></p></li><li><p>png：无损压缩的位图片形格式（首选）</p></li></ol></li><li><p>图片类型：[ 黑白 ]  [ 彩色 ]</p></li></ul><p>​    【gif(动图) -&gt; 一帧一帧拿出来】</p><ul><li>图片的本质：由像素点组成的一个矩阵，每个元素（像素点）都是在 [0,255] 之间</li></ul><h3 id="二、读取第一张黑白图片"><a href="#二、读取第一张黑白图片" class="headerlink" title="二、读取第一张黑白图片"></a>二、读取第一张黑白图片</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br></pre></td></tr></table></figure><ol><li><p>读取和展示</p><ul><li>path：路径 0：代表灰度图 1：彩色图</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">path = r&quot;./R-C.jpg&quot;</span><br><span class="line">img = cv2.imread(path,0)</span><br><span class="line">print(type(img))</span><br><span class="line">print(img.shape)</span><br><span class="line">print(img)</span><br><span class="line">cv2.imshow(&#x27;image&#x27;, img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><ul><li>需要注意的是这里的<code>cv2.imshow(&#39;image&#39;, img)</code>因为我这次编写代码是在实验的服务器上运行的，远程连接ssh服务器需要额外使用X - Service（这个玩意浪费了我四天的时间，不过解决了这个问题后面的学习就流畅多了） ——附教程</li></ul></li><li><p>图片的裁剪</p><ul><li>简单图片的裁剪和展示</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">path = r&quot;/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg&quot;</span><br><span class="line"># path:路径 0：代表灰度图 1：彩色图</span><br><span class="line">img = cv2.imread(path,0)</span><br><span class="line"># 本质：数组、矩阵</span><br><span class="line">img1 = img[:500, :500]</span><br><span class="line">cv2.imshow(&#x27;img1&#x27;, img1)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><ul><li>Numpy 黑白颜色图片的叠加，即拼接</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">path = r&quot;/home/jiax/workspace/Python Learning/Opencv-course/black.jpg&quot;</span><br><span class="line">img1 = cv2.imread(path,0)</span><br><span class="line">print(img1.shape)</span><br><span class="line"></span><br><span class="line">path = r&quot;/home/jiax/workspace/Python Learning/Opencv-course/white.jpg&quot;</span><br><span class="line">img2 = cv2.imread(path,0)</span><br><span class="line">print(img2.shape)</span><br><span class="line"></span><br><span class="line">new_img1 = img1[:100,:300]</span><br><span class="line">new_img2 = img2[:100,:300]</span><br><span class="line"></span><br><span class="line"># 垂直拼接 列数相等</span><br><span class="line">new_img = np.vstack((new_img1, new_img2))</span><br><span class="line">cv2.imshow(&#x27;new_img&#x27;, new_img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"># 水平拼接 行数相等</span><br><span class="line">new_img = np.hstack((new_img1, new_img2))</span><br><span class="line">cv2.imshow(&#x27;new_img&#x27;, new_img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>图片的保存（<code>imwrite(path, target)</code>）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">path = r&quot;/home/jiax/workspace/Python Learning/Opencv-course/black.jpg&quot;</span><br><span class="line">img1 = cv2.imread(path,0)</span><br><span class="line">print(img1.shape)</span><br><span class="line"></span><br><span class="line">path = r&quot;/home/jiax/workspace/Python Learning/Opencv-course/white.jpg&quot;</span><br><span class="line">img2 = cv2.imread(path,0)</span><br><span class="line">print(img2.shape)</span><br><span class="line"></span><br><span class="line">new_img1 = img1[:100,:300]</span><br><span class="line">new_img2 = img2[:100,:300]</span><br><span class="line"></span><br><span class="line">new_img = np.vstack((new_img1, new_img2))</span><br><span class="line"></span><br><span class="line"># png 类型所占的空间更大</span><br><span class="line">cv2.imwrite(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/new_img.jpg&quot;, new_img)</span><br><span class="line">cv2.imwrite(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/new_img.png&quot;, new_img)</span><br></pre></td></tr></table></figure></li><li><p>将numpy所生成的图片转换为cv所能识别的矩阵形式=&gt;将生成的数组转为图片</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 图像一定是三维的，黑白图片(h,w,1)，彩色(h,w,3)</span><br><span class="line">array1 = np.random.randint(0,255,(700,500,1), dtype=&#x27;uint8&#x27;) # 将numpy所生成的图片转换为cv所能识别的矩阵形式=&gt;将生成的数组转为图片</span><br><span class="line">print(type(array1))</span><br><span class="line">array2 = np.random.randint(0,255,(700,500,1))</span><br><span class="line">print(type(array2))</span><br><span class="line"></span><br><span class="line">cv2.imshow(&#x27;new_img&#x27;, array2)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li></ol><h3 id="三、读取第一张彩色图片"><a href="#三、读取第一张彩色图片" class="headerlink" title="三、读取第一张彩色图片"></a>三、读取第一张彩色图片</h3>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br></pre></td></tr></table></figure><ol><li><p>彩色图片的读取</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 彩色图片读取方式为1</span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 1)</span><br><span class="line"></span><br><span class="line"># 检查彩色图片是否array形式[&lt;class &#x27;numpy.ndarray&#x27;&gt;]</span><br><span class="line">print(type(img))</span><br><span class="line"></span><br><span class="line"># 注意需要传递图片名以及图片矩阵</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"># 彩色图片的形状 [(1333, 750, 3)]</span><br><span class="line">print(img.shape)</span><br></pre></td></tr></table></figure></li><li><p>研究三通道：[Opencv中以三个二维矩阵进行存储，即三维矩阵：[H-W*3] ]</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个二维数组</span><br><span class="line">print(np.array([[1,2]]).shape)</span><br><span class="line">print(np.array([[1,2],[1,2]]).shape)</span><br><span class="line"># 创建一个三维数组</span><br><span class="line">print(np.array([[[1,2],[1,2]]]).shape)</span><br><span class="line">print(np.array([ [[1,2],[1,2]],</span><br><span class="line">                [[1,2],[1,2]] ]).shape)</span><br><span class="line">print(np.array([ [[1,2],[1,2]],</span><br><span class="line">                [[1,2],[1,2]],</span><br><span class="line">                [[1,2],[1,2]] ]).shape)</span><br><span class="line"></span><br><span class="line">彩色图片 -&gt; 三张图片(RGB) Opencv 中以BGR形式存储</span><br><span class="line">尝试拆分一张彩色图片</span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 1)</span><br><span class="line">img0 = img[:,:,0] #B</span><br><span class="line">cv2.imshow(&#x27;img0&#x27;, img0)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line">cv2.imwrite(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/2_b.jpg&quot;,img0)</span><br><span class="line">img1 = img[:,:,1] #G</span><br><span class="line">cv2.imwrite(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/2_g.jpg&quot;,img1)</span><br><span class="line">img2 = img[:,:,2] #R</span><br><span class="line">cv2.imwrite(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/2_r.jpg&quot;,img2)</span><br><span class="line"></span><br><span class="line"># split() 拆分，类似以上效果</span><br><span class="line">b,g,r = cv2.split(img)</span><br><span class="line"></span><br><span class="line"># 合并拆分结果</span><br><span class="line"># img = cv2.merge([b,g,r]) 正常显示</span><br><span class="line"># img = cv2.merge([b,g]) 无法显示</span><br><span class="line">img = cv2.merge([r,g,b]) # 可进行图片的重生成</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>剪裁</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 1)</span><br><span class="line">img0 = img[:,:,0] #B</span><br><span class="line">img1 = img[:,:,0] #B</span><br><span class="line">img2 = img[:,:,0] #B</span><br><span class="line">print(img.shape)</span><br><span class="line">new_img0 = img0[:100,:100]</span><br><span class="line">new_img1 = img1[:100,100:200]</span><br><span class="line">new_img2 = img2[:100,200:300]</span><br><span class="line">new_img = np.hstack((new_img0, new_img1, new_img2))</span><br><span class="line">cv2.imshow(&#x27;new_img&#x27;, new_img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p>使用opencv转换图片的色彩空间</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 1. 色彩空间：[BGR]</span><br><span class="line"># (1) HSV：更类似于人类感觉颜色的方式。H：色相(Hue) S：饱和度(Saturation) V：亮度(Value)</span><br><span class="line"># (2) YUV：Y：亮度信号 U\V：两个色彩信号-&gt;色彩的饱和度</span><br><span class="line"># (3) Lab：由国际照明委员会建立。L：整张图的明亮度 a\b：负责颜色的多少</span><br><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 1)</span><br><span class="line">cv2.imshow(&#x27;img&#x27;, img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"># HSV</span><br><span class="line">hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)</span><br><span class="line">cv2.imshow(&#x27;hsv&#x27;, hsv)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"># YUV</span><br><span class="line">yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)</span><br><span class="line">cv2.imshow(&#x27;yuv&#x27;, yuv)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"># Lab</span><br><span class="line">lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)</span><br><span class="line">cv2.imshow(&#x27;lab&#x27;, lab)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"># 还有其他的色彩空间</span><br></pre></td></tr></table></figure></li></ol><h3 id="四、统计一张图片的像素点个数"><a href="#四、统计一张图片的像素点个数" class="headerlink" title="四、统计一张图片的像素点个数"></a>四、统计一张图片的像素点个数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import cv2</span><br></pre></td></tr></table></figure><ol><li>图片的读取</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg&quot;, 0)</span><br><span class="line"></span><br><span class="line">h,w = np.shape(img)</span><br><span class="line">hest = np.zeros([256], dtype=np.int32) # 创建256个全为0零的一维矩阵</span><br></pre></td></tr></table></figure><ol><li>遍历图片矩阵</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for row in range(h):</span><br><span class="line">    for col in range(w):</span><br><span class="line">        pv = img[row,col]</span><br><span class="line">        hest[pv] += 1</span><br></pre></td></tr></table></figure><ol><li>绘图的操作</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(hest, color=&#x27;r&#x27;)</span><br><span class="line">plt.xlim([0,256])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="image-20250727200339645.png" alt="image-20250727200339645"></p><h3 id="五、彩色图片像素点的统计"><a href="#五、彩色图片像素点的统计" class="headerlink" title="五、彩色图片像素点的统计"></a>五、彩色图片像素点的统计</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import cv2</span><br></pre></td></tr></table></figure><ol><li>图片的读取</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(r&quot;/home/jiax/workspace/Python Learning/Opencv-course/color.jpg&quot;, 1)</span><br></pre></td></tr></table></figure><ol><li>分离颜色通道</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b,g,r = cv2.split(img)</span><br></pre></td></tr></table></figure><ol><li>行列遍历</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h, w = np.shape(b)</span><br></pre></td></tr></table></figure><ol><li>建立空白数组</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hest = np.zeros([256],dtype=np.int32)</span><br></pre></td></tr></table></figure><ol><li>遍历图片</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">for i in [b,g,r]:</span><br><span class="line">    for row in range(h):</span><br><span class="line">        for col in range(w):</span><br><span class="line">            pv = i[row,col]</span><br><span class="line">            hest[pv] += 1</span><br><span class="line"></span><br><span class="line">plt.plot(hest, color=&#x27;r&#x27;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="image-20250727200527018.png" alt="image-20250727200527018"></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Opencv&quot;&gt;&lt;a href=&quot;#Opencv&quot; class=&quot;headerlink&quot; title=&quot;Opencv&quot;&gt;&lt;/a&gt;Opencv&lt;/h1&gt;</summary>
    
    
    
    <category term="504医学AI" scheme="http://example.com/categories/504%E5%8C%BB%E5%AD%A6AI/"/>
    
    
    <category term="504医学AI入门" scheme="http://example.com/tags/504%E5%8C%BB%E5%AD%A6AI%E5%85%A5%E9%97%A8/"/>
    
  </entry>
  
  <entry>
    <title>Week1</title>
    <link href="http://example.com/2025/07/20/LearningSchedule/Week1/"/>
    <id>http://example.com/2025/07/20/LearningSchedule/Week1/</id>
    <published>2025-07-19T16:00:00.000Z</published>
    <updated>2025-07-27T12:09:50.480Z</updated>
    
    <content type="html"><![CDATA[<h1 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h1><blockquote><p>学习视频</p><p><a href="https://www.bilibili.com/video/BV1ev411P7dR/?spm_id_from=333.1391.0.0&amp;vd_source=f087eabd3aa1e0f48fafe303a9a3a49b">语义分割前言_哔哩哔哩_bilibili</a></p></blockquote><h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p><strong>目标：</strong></p><ul><li>[x] 什么是语义分割</li><li>[x] 暂定的学习规划</li><li>[x] 语义分割任务常见数据集格式</li><li>[x] 语义分割得到结果的具体形式</li><li>[x] 语义分割常见评价标准</li><li>[x] 语义分割标注工具</li></ul><h3 id="1-常见分割任务"><a href="#1-常见分割任务" class="headerlink" title="1. 常见分割任务"></a>1. 常见分割任务</h3><ol><li><p>语义分割（FCN）：对每一个像素进行分类</p></li><li><p>实例分割（Mask R-CNN）：针对同一个类别的不同目标也采用不同颜色进行分类，结果更精细，只关注目标背景</p></li><li><p>全景分割（Panoptic FPN）语义 + 实例 + 背景划分</p></li></ol><blockquote><p>精细程度逐级递增</p></blockquote><p><img src="d4feeb82775c742b95f2bca8aa9444954dd05abe.jpg@682w_!web-note.webp" alt="img"></p><h3 id="2-pytorch-官方提供的语义分割网络"><a href="#2-pytorch-官方提供的语义分割网络" class="headerlink" title="2. pytorch 官方提供的语义分割网络"></a>2. pytorch 官方提供的语义分割网络</h3><p><img src="460884667254062d83d862562f79021274b71feb.jpg@682w_!web-note.webp" alt="img"></p><h3 id="3-语义分割任务常见数据集格式"><a href="#3-语义分割任务常见数据集格式" class="headerlink" title="3. 语义分割任务常见数据集格式"></a>3. 语义分割任务常见数据集格式</h3><ol><li><p><strong>Pascal VOC</strong></p><blockquote><p><a href="https://blog.csdn.net/qq_37541097/article/details/115787033">PASCAL VOC2012数据集介绍_pascal voc 2012-CSDN博客</a></p></blockquote><p>语义分割中提供的是png图片（记录每个像素所属的一个类别信息），这个png图片使用调色板的模式进行存储。</p><p>图片（第二张图片）实际是一个一通道的图片（黑白图片），但看到的确实彩色的。</p><p>用 python 的 Pillow 去读取 png 图片的话，默认读取的是调色板的模式（P模式），通道数为1（单通道）。</p><p>但是读取图片进行训练的时候只需要关注每个像素所属的类别索引即可</p><p>目标的边缘都会有一个特殊的颜色进行分割，或者图片中的一些特殊去也会用这个颜色进行填充，而这些位置对应的像素值是255万。在训练过程中，会抛弃像素值为255万的地方，因为这些地方并不好严格确定其所属类型。</p><p>除此之外，有一些不好区分类别的地方，也可用这个颜色进行填充。例如图中的长方形区域，在原图中是有一个飞机的尾翼部分的，但是并不好进行分割，故直接使用了像素值为255的数值进行填充，填充遮蔽之后再训练网络的时候就不会去计算这部分的损失。</p></li></ol><p><img src="image-20250208151458501.png" alt="image-20250208151458501"></p><blockquote><p>像素值指的是数字图像的基本单位像素所具有的数值信息。它是用来定义图像的亮度或颜色等级的，对彩色图像而言，每个像素通常包含了红、绿、蓝三个颜色通道的数值信息，这三个颜色通道的数值组合决定了该像素呈现的颜色。</p><p>像素值是三维数值</p></blockquote><p><img src="image-20250208152753100.png" alt="image-20250208152753100"></p><ol><li><p><strong>MS COCO</strong></p><blockquote><p><a href="https://blog.csdn.net/qq_37541097/article/details/113247318">MS COCO数据集介绍以及pycocotools简单使用_coco数据集最多一张图有多少个instance-CSDN博客</a></p><p>这篇论文是关于读取每张图片的分割信息的部分，如何读取并得到每个图像所对应的标签图片</p></blockquote><p>针对图像中的每一个目标都给出了一个<strong>多边形</strong>的一个<strong>坐标形式</strong>（x坐标.y坐标，两个一组一个坐标点，点连成线，得到目标），将图像中的所有目标绘制出来，即可得到右下角抽离出来的训练图案。</p><p>这个结果图片与 Pascal 的 png 图片结果是一样的，不过并没有标注边缘信息，因此使用MS COCO数据集就需要自己将多边形信息解码成png图片（期望的标签图片）。计算损失时，就是拿预测的每个像素对应的类别与真实标签的每个类型进行对比计算。</p><p>另外，记录的多边形信息除可用于语义分割外，还可以用于进行实例分割，因这样已经记录了每个目标的，是能够将每个目标都区分出来的</p></li></ol><p><img src="image-20250208152939744.png" alt="image-20250208152939744"></p><h3 id="4-语义分割得到结果的具体形式"><a href="#4-语义分割得到结果的具体形式" class="headerlink" title="4. 语义分割得到结果的具体形式"></a>4. 语义分割得到结果的具体形式</h3><blockquote><p>单通道图片</p></blockquote><ul><li>以下是单通道 + 调色板，利用 PyTorch 官方的 FCN 网络预测的结果（背景位置像素值为0， 飞机位置像素值为1，人位置的像素值为15）。</li></ul><p>如果直接以灰度图片显示的话，看到的图片是一幅黑色的（因为不同目标的像素值实际都很小—-1和15），肉眼根本看不出区别，加上调色板，可以让每个像素对应一个彩色，方便可视化我们的预测结果。</p><ul><li>每个像素的数值对应类别索引</li></ul><p><img src="image-20250208154730540.png" alt="image-20250208154730540"></p><h3 id="5-常见语义分割评价指标"><a href="#5-常见语义分割评价指标" class="headerlink" title="5. 常见语义分割评价指标"></a>5. 常见语义分割评价指标</h3><ol><li><p><strong>Pixel Accuracy（Global Acc）</strong></p><ul><li>分子是预测标签图像中所有预测正确的像素个数的总和</li><li>分母是图片的总像素个数</li></ul></li><li><p><strong>mean Acc</strong></p><p>将每个类别的 Acc 计算出来，然后再进行一个求和，然后再取平均</p></li><li><p><strong>mean IoU</strong></p><p>计算每一个类别的 IoU，然后再对每个类别 IoU 的累和求平均</p><p>其实和目标检测 IoU 理论上是一样的，都是两个目标面积的交集比上他们面积的并集 </p><ul><li>假设绿色的圆圈对应的是真实的标签，蓝色的圆圈对应的是预测的标签，那么n~ii~ 对应的是这两个圈重合的部分，即预测正确的部分</li><li>t~i~ 对应的是类别 i 的总个数，即绿色圆圈部分的面积，而<img src="image-20250208162640581.png" alt="image-20250208162640581">对应的是预测标签中所有预测为类别 i 一个像素总个数，即蓝色圆圈部分的面积，由于计算的时候中间部分计算了两次，所以还需要减去一次中间部分 n~ii~</li></ul><p>论文中最常见的是 mean IoU</p></li></ol><blockquote><p>n~ii~ ：针对类别i，预测正确的总像素个数</p></blockquote><p><img src="image-20250208160252213.png" alt="image-20250208160252213"></p><h4 id="Pytorch-官方的一个计算方法——通过构建一个混淆矩阵来进行计算"><a href="#Pytorch-官方的一个计算方法——通过构建一个混淆矩阵来进行计算" class="headerlink" title="Pytorch 官方的一个计算方法——通过构建一个混淆矩阵来进行计算"></a>Pytorch 官方的一个计算方法——通过构建一个混淆矩阵来进行计算</h4><p><img src="image-20250208163130675.png" alt="image-20250208163130675"></p><ol><li><strong>Global ACC</strong></li></ol><ul><li>为了方便理解，现将所有标注为0的位置设置为白色，非0标注的位置全部设置为灰色，这样把所有预测标签为0的结果全部提取出来了，</li><li>然后预测正确的位置用绿色进行表示，预测错误的位置用红色表示</li><li>右图中16是预测为0的正确像素总是（即绿色像素总个数），2为预测为0的预测错误的像素总个数（即红色像素总个数），错误像素原本对应的索引是3</li></ul><p><img src="image-20250208163420330.png" alt="image-20250208163420330"></p><ul><li>同样在预测标签当中，将所有预测为1的结果全部提取出来，预测正确的用绿色表示，预测错误的用红色表示</li></ul><p><img src="image-20250208163907857.png" alt="image-20250208163907857"></p><ul><li>以此类推，可以分别预测出类别2，类别3，类别4对应的参数</li><li>最终得到一个混淆矩阵<ul><li>分子是预测标签图像中所有预测正确的像素个数的总和</li><li>分母是图片的总像素个数</li><li>对角线对应的全部是预测正确的像素个数，即分子是混淆矩阵对角线上的数字之和</li><li>可以将混淆矩阵的所有个数相加得到分母，或者直接使用标签（8行8列8*8=64）得到像素值</li></ul></li></ul><p><img src="image-20250208165128870.png" alt="image-20250208165128870"></p><ol><li><strong>mean ACC</strong></li></ol><p><img src="image-20250208165950994.png" alt="image-20250208165950994"></p><ol><li><strong>mean IoU</strong></li></ol><p><img src="image-20250208170239310.png" alt="image-20250208170239310"></p><p><img src="image-20250208170304472.png" alt="image-20250208170304472"></p><h3 id="6-标注工具"><a href="#6-标注工具" class="headerlink" title="6. 标注工具"></a>6. 标注工具</h3><ol><li><strong>Labelme</strong></li></ol><blockquote><p><a href="https://blog.csdn.net/qq_37541097/article/details/120162702">Labelme分割标注软件使用_labelme2voc.py-CSDN博客</a></p></blockquote><p><img src="image-20250208170416293.png" alt="image-20250208170416293"></p><ol><li><strong>EISeg</strong> —- 百度开源的深度学习框架</li></ol><blockquote><p><a href="https://blog.csdn.net/qq_37541097/article/details/120154543">EISeg分割标注软件使用_eiseg使用-CSDN博客</a></p></blockquote><p><img src="image-20250208170854204.png" alt="image-20250208170854204"></p><p>开源仓库：<a href="https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.10/EISeg">PaddleSeg/EISeg at release/2.10 · PaddlePaddle/PaddleSeg</a></p><h2 id="二、转置卷积（Transposed-Convolution）"><a href="#二、转置卷积（Transposed-Convolution）" class="headerlink" title="二、转置卷积（Transposed Convolution）"></a>二、转置卷积（Transposed Convolution）</h2><blockquote><p><a href="https://arxiv.org/abs/1603.07285">[1603.07285] A guide to convolution arithmetic for deep learning</a></p></blockquote><p> <a href="卷积.md">卷积.md</a> </p><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h3><ul><li><p>在语义分割和对抗神经网络 gan 当中的作用：<strong>采样</strong>（upsampling）</p></li><li><p>左侧的图是一个传统的卷积，输入的是高宽为 4 <em> 4 的特征层，克隆大小是 3 </em> 3的，padding = 0， strides = 1，通过卷积之后，得到的输出特征层的高宽是 2 * 2 的</p></li><li><p>右边的图是转置卷积，对于输入的是 2 <em> 2 的特征层，同时在四周填充一些零元素，填充之后同样使用 3 </em> 3 的卷积核来进行卷积处理，通过转置卷积之后，发现输入特征层大小是 2 <em> 2，输出特征层大小变成了 4 </em> 4，输出变大了，这也是转置卷积最常用的一种情况，就是<strong>伤采样</strong>。</p><ol><li><p>转置卷积不是卷积的逆运算</p><ul><li><p>deconvolution卷积逆运算的名称，但同时在某些地方也被认为是转置卷积，这很容易混淆，所以一般不用这个做称呼</p></li><li><p>转置卷积只是将特征层的大小还原回卷积之前的大小，但其数值是和输入特征层的数值不一样，所以转置卷积并不算一个卷积逆运算的过程</p></li></ul></li><li><p>转置卷积也是卷积</p></li></ol></li></ul><p><img src="image-20250209142613047.png" alt="image-20250209142613047"></p><video src="/../../../../../AppData/Local/Packages/Microsoft.ScreenSketch_8wekyb3d8bbwe/TempState/Recordings/20250209-0636-50.4310252.mp4"></video><blockquote><p>第一次听到转置卷积是在李宏毅老师课上，印象深刻的一句话：转置卷积就是卷积。对了，补充一下，把卷积核矩阵转置乘原图矩阵就是转置卷积，因此卷积运算的反向传播就是通过转置卷积实现的。以及转置卷积在生成任务中如果卷积核大小为3，步长为2，会有非常明显的棋盘效应，因此更推荐使用最临近插值或双线性插值后再接一个卷积来取代转置卷积。</p></blockquote><h3 id="2-转置卷积运算步骤"><a href="#2-转置卷积运算步骤" class="headerlink" title="2. 转置卷积运算步骤"></a>2. 转置卷积运算步骤</h3><p><img src="image-20250209161051085-1753011630523-19.png" alt="image-20250209161051085"></p><h2 id="基本环境配置"><a href="#基本环境配置" class="headerlink" title="基本环境配置"></a>基本环境配置</h2><h3 id="一、实验室Linux系统连接"><a href="#一、实验室Linux系统连接" class="headerlink" title="一、实验室Linux系统连接"></a>一、实验室Linux系统连接</h3><h3 id="二、Anaconda-安装和路径设置"><a href="#二、Anaconda-安装和路径设置" class="headerlink" title="二、Anaconda 安装和路径设置"></a>二、Anaconda 安装和路径设置</h3><h3 id="三、Pytorch-和-Opencv-依赖库的安装"><a href="#三、Pytorch-和-Opencv-依赖库的安装" class="headerlink" title="三、Pytorch 和 Opencv 依赖库的安装"></a>三、Pytorch 和 Opencv 依赖库的安装</h3><ol><li>Pytorch（GPU）(conda) </li><li>和 Opencv-Python（4.1.0.25） (pip) </li></ol><h3 id="四、Pycharm-与-实验室服务器直连（可直接编辑文件和可视化编辑代码）"><a href="#四、Pycharm-与-实验室服务器直连（可直接编辑文件和可视化编辑代码）" class="headerlink" title="四、Pycharm 与 实验室服务器直连（可直接编辑文件和可视化编辑代码）"></a>四、Pycharm 与 实验室服务器直连（可直接编辑文件和可视化编辑代码）</h3><blockquote><p><a href="https://zhuanlan.zhihu.com/p/680151749">Pycharm连接linux服务器远程开发 2023 直连 - 知乎</a></p><p><a href="https://blog.csdn.net/weixin_43486940/article/details/123229290">如何在pycharm中使用anaconda的虚拟环境_pycharm使用anaconda环境-CSDN博客</a></p></blockquote><h2 id="Opencv图像处理—python版"><a href="#Opencv图像处理—python版" class="headerlink" title="Opencv图像处理—python版"></a>Opencv图像处理—python版</h2><p>——专门做图像处理的库</p><p>（1）缩放（）裁剪（）</p><h3 id="一、常见的图片格式及图片类型"><a href="#一、常见的图片格式及图片类型" class="headerlink" title="一、常见的图片格式及图片类型"></a>一、常见的图片格式及图片类型</h3><blockquote><p>图片格式</p></blockquote><ol><li>bmp：比较老的格式|不常见|无损-&gt;基本上无压缩|体积大|被淘汰</li><li>jpg（jpeg）：用<strong>最少的磁盘空间</strong>得到<strong>较好的图片质量</strong></li><li>png：无损压缩的位图片形格式（首选）</li></ol><blockquote><p>图片类型</p></blockquote><p>[ 黑白 ]  [ 彩色 ]</p><p>【gif(动图) -&gt; 一帧一帧拿出来】</p><p>图片的本质：由像素点组成的一个矩阵，每个元素（像素点）都是在 [0,255] 之间</p><h3 id="二、读取第一张黑白照片"><a href="#二、读取第一张黑白照片" class="headerlink" title="二、读取第一张黑白照片"></a>二、读取第一张黑白照片</h3><blockquote><p>遇到的问题</p><ol><li>pycharm 的dataview 以及 variable变量的跟踪</li><li>使用实验室服务器时使用cv2.imshow(‘image’, img) 出现: cannot connect to X server 错误提示</li></ol><p>问题原因及解决情况</p><ol><li>解决</li><li>为解决。目前知道的原因是实验室Linux服务器上无图形界面，运行cv2.imshow需要图形显示(GUI)的程序无法正常进程。现解决方向：配置X11转发，但一直卡在服务器无法ping通本地，无法转发到本地ip：0.0</li></ol></blockquote>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;语义分割&quot;&gt;&lt;a href=&quot;#语义分割&quot; class=&quot;headerlink&quot; title=&quot;语义分割&quot;&gt;&lt;/a&gt;语义分割&lt;/h1&gt;</summary>
    
    
    
    <category term="504医学AI" scheme="http://example.com/categories/504%E5%8C%BB%E5%AD%A6AI/"/>
    
    
    <category term="504医学AI入门" scheme="http://example.com/tags/504%E5%8C%BB%E5%AD%A6AI%E5%85%A5%E9%97%A8/"/>
    
  </entry>
  
</feed>
