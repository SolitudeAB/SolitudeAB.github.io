<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>/2025/07/16/DeepSeek/</url>
    <content><![CDATA[<p>技术突破和市场营销兼而有之，说白了就是：<strong>技术牛 + 会搞事 + 赶上了好时候</strong>。</p>
<h2 id="一、为什么是DeepSeek爆发？"><a href="#一、为什么是DeepSeek爆发？" class="headerlink" title="一、为什么是DeepSeek爆发？"></a>一、为什么是DeepSeek爆发？</h2><h3 id="1、技术确实能打"><a href="#1、技术确实能打" class="headerlink" title="1、技术确实能打"></a>1、技术确实能打</h3><p>比如它可能搞了个“更聪明还更便宜”的<a href="https://zhida.zhihu.com/search?content_id=711650522&amp;content_type=Answer&amp;match_order=1&amp;q=AI模型&amp;zhida_source=entity">AI模型</a>：</p>
<p>1）做题（数学、编程）比<a href="https://zhida.zhihu.com/search?content_id=711650522&amp;content_type=Answer&amp;match_order=1&amp;q=ChatGPT&amp;zhida_source=entity">ChatGPT</a>还猛，但用起来省电省钱。</p>
<p>2）直接开源代码，让程序员白嫖，口碑一下就炸了。</p>
<p>3）国产模型对于汉字理解和输出能力更好</p>
<p>4）机器逻辑转化为自然语言逻辑推理</p>
<p>5）仅此 openAI （ close 源）第二模型</p>
<h3 id="2、正好踩中风口"><a href="#2、正好踩中风口" class="headerlink" title="2、正好踩中风口"></a>2、正好踩中风口</h3><p>1）企业现在都想用AI省钱（比如用AI客服裁掉真人），它价格便宜，老板们心动。</p>
<p>2）国内政策推国产AI（怕被国外卡脖子），它刚好是“自家孩子”。</p>
<p>3）普通人被ChatGPT搞出好奇心，但用不了<a href="https://zhida.zhihu.com/search?content_id=711650522&amp;content_type=Answer&amp;match_order=1&amp;q=GPT-4&amp;zhida_source=entity">GPT-4</a>，转头就试它。</p>
<h3 id="3、特别会“刷存在感”"><a href="#3、特别会“刷存在感”" class="headerlink" title="3、特别会“刷存在感”"></a>3、特别会“刷存在感”</h3><p>1）和阿里、腾讯这些大厂合作，贴牌“国家队”标签。</p>
<p>2）在<a href="https://zhida.zhihu.com/search?content_id=711650522&amp;content_type=Answer&amp;match_order=1&amp;q=程序员论坛&amp;zhida_source=entity">程序员论坛</a>（<a href="https://zhida.zhihu.com/search?content_id=711650522&amp;content_type=Answer&amp;match_order=1&amp;q=GitHub&amp;zhida_source=entity">GitHub</a>）、抖音、B站疯狂推教程，让小白也能玩起来。</p>
<p><strong>举个栗子</strong></p>
<p>就像突然有个新奶茶店，奶茶比别人好喝还半价（技术强），同时找网红直播带货（市场会玩），再加上最近全网流行喝奶茶（行业风口），不火才怪。</p>
<h3 id="4-创新处"><a href="#4-创新处" class="headerlink" title="4. 创新处"></a>4. 创新处</h3><p><strong>1）MoE（混合专家模式）：</strong></p>
<p>这种模式可以在遇到用户提出的问题时，先拆解、分类，再由相应相应领域的专家来解答，各司其职，而不需要所有专家集体会诊，从而极大降低计算量。与 OpenAI o1 所采用的稠密（Dense）架构相比，DeepSeek 使用的 MoE 可以在模型总参数高达 6710 亿的情况下，在实际推理时每次只调用其中的 370 亿个参数。</p>
<p>这个技术并非 DeepSeek 发明，其历史可以追溯到1991年，当时Michael Jordan和Geoffrey Hinton（去年诺贝尔物理学奖得主）共同发表了开创性论文《Adaptive Mixtures of Local Experts》，首次提出了MoE的概念，旨在通过门控网络（gating network）动态分配输入数据到不同的专家网络，从而实现模型性能的提升。实际上，OpenAI的 GPT4 也采用了这种模式。</p>
<p><strong>2）多头潜注意力机制（MLA）：</strong></p>
<p>本技术为 DeepSeek 团队独创，针对传统 Transformer模型的“多头注意力机制”在处理长文本时容易“分心”的问题。MLA可以通过压缩关键信息，让模型更聚焦核心内容。比如阅读一篇长篇小说时，MLA能自动提取人物关系、关键情节等核心线索，减少无效信息的处理，提高推理速度，同时显存占用更低。</p>
<p><img src="https://pic3.zhimg.com/v2-391350614bf7bb90ea3e45726e16f9c2_1440w.jpg" alt="img"></p>
<p>DeepSeek-V3 技术报告中详细介绍了 MLA 和 MoE 的组合方法，来源：DeepSeek</p>
<p><strong>3）利用群体相对策略优化（GPRO），减少有监督微调（SFT）步骤：</strong></p>
<p>传统的大模型开发流程，都是先通过大量标注数据进行 SFT（有监督微调），让模型具备基础能力，之后才使用强化学习（RL）进行能力提升，这是由GPT 系列开创并一直所遵循的范式。然而 DeepSeek 团队发现，大模型可以完全依靠强化学习获得强大的推理能力，无需任何监督式微调，这无疑可以极大提高训练速度，减少对于标注数据的需求。团队直接在 DeepSeek-V3-base 模型上应用强化学习，完全抛开SFT环节，开发了实验性的 R1-Zero 版本。</p>
<p>R1-Zero 采用的是<strong>纯强化学习（pure RL）</strong>，而不是 GPT 所采用的“人类反馈强化学习”（RLHF）。它用 DeepSeek-V3 作为基础模型，只提供算数、代码、逻辑等题目的奖励函数（解答正确、思考过程符合某种链式推理结构）。没有人类在环（HF），纯粹让模型在奖励指引下自我演化，也就是说，完全不需要人类参与。不过在从 R1-Zero 到 R1 的过程中，团队加入了一些少量的监督数据（cold start），然后再做强化学习，生成了完整的 R1。</p>
<p>在这个过程中采用了团队还采用了独创的 <a href="https://zhida.zhihu.com/search?content_id=253440283&amp;content_type=Article&amp;match_order=1&amp;q=GRPO&amp;zhida_source=entity">GRPO</a> 算法，进一步优化强化学习的效果。传统方法通常需要维护一个与主模型规模相当的评价网络来估计状态值，这不仅增加了计算开销，还容易导致训练不稳定。而 <strong>GRPO 则另辟蹊径，移除了规模庞大的 Critic 网络，通过群组相对优势估计来优化策略网络</strong>。这个大胆的尝试产生了惊人的效果：在完全没有人工标注数据的情况下，模型展现出了持续的自我进化能力，出现了所谓的<strong>“Aha moment”（顿悟时刻）</strong>。</p>
<p>这一点其实是非常具有重要的突破（很多媒体或者文章对这点表达得不够清晰）：过去限制大模型发展、升级的一个重要瓶颈，就是需要人类的参与，包括数据标注和奖励，现在 DeepSeek 摆脱了这个“镣铐”，让大模型可以通过自我推理持续进化，那么剩下的就完全是机器效率问题了。这就仿佛是，从过去弯弯曲曲的羊肠小道，走上了一马平川的高速公路。</p>
<p><img src="https://pic4.zhimg.com/v2-b35af1999d87d911d40634a11cb5174d_1440w.jpg" alt="img"></p>
<p>以 AIME 2024 数据考试为例，R1-zero 模型经过经过多轮强化学习之后（红色实线），超过了 OpenAI o1 的水平（图中紫色虚线），来源：DeepSeek</p>
<p><strong>4）蒸馏（Distilling）:</strong></p>
<p>“蒸馏”这个概念是 Geoffrey Hinton 等在其论文《Distilling the Knowledge in a Neural Network》（2015）提出，DeepSeek 在 R1 技术报告中，专门介绍了自己在蒸馏方面的成果，标题为“小模型也可以干大事”（Smaller Models Can Be Powerful Too），即用 R1 模型生成的数据，对业界一些主流的开源模型（主要是 QWen 和 Llama）进行调优，获得体积较小的模型。</p>
<p>其中，最小的 Qwen-1.5B 模型在 AIME 上达到了 28.9% 的准确率，这个成绩已经超过了一些大得多的基础模型。中等规模的 Qwen-7B 达到了 55.5% 的准确率，这意味着一个仅有 70 亿参数的模型就能解决相当复杂的数学问题。而 Qwen-32B 在 AIME 上更是达到了 72.6% 的准确率，在 MATH-500 上达到了 94.3%，这些成绩都接近于原始的 R1 模型。</p>
<p>这一发现具有重要的实践意义：它证明了我们可以<strong>通过知识蒸馏的方式，将大模型的高级能力有效地转移到更小的模型中</strong>，这为 AI 技术的实际应用提供了一条可行的路径。</p>
<p>不过，这也是目前引起争议比较大的一个领域：有一些观点认为，DeepSeek 在训练中也使用了 OpenAI 生成的数据，换句话说，DeepSeek 对 ChatGPT 进行了蒸馏。但是这种观点目前主要是一些揣测，并没有明确的证据。</p>
<p>除此以外，还有FP8混合精度训练、语言一致性奖励、四阶段训练流程等多项技术创新，在此不一一赘述。</p>
<p><strong>更普惠</strong></p>
<p>在春节期间，为数众多的自媒体、公众号都在用 DeepSeek 加工各种创意，有用来编辑过年短信的，有用来制作贺岁图片的（生成提示词），更多是用它来解答各式各样的问题：这一幕在前几年 ChatGPT 刚刚出现和 Kimi 等产品上线时也曾经出现，但是最大的区别在于，因为 DeepSeek-R1 在对话中可以方便地启动“深度思考”功能，用户既可以看到它的思考过程，又能够获得更加全面、深入的对话结果，甚至有人提出：所有之前曾经和其他大模型对话过的内容，都值得用 R1 重新问一遍。</p>
<p><img src="https://pic4.zhimg.com/v2-85985671be7dd4609afec1b8c04093e7_1440w.jpg" alt="img"></p>
<p>当然，更重要的原因是，<strong>这一切都是免费的。</strong></p>
<p>然而，要在 ChatGPT 这样的闭源产品上获得类似的效果，不仅要克服重重障碍才能访问，而且还需要成为付费会员，高价才能使用深度推理功能（o1）。</p>
<p>对于开发者而言，如果是用 API 形式调用 R1，那么其价格：输入 token，每百万个输入 token 0.55 美元（缓存如果命中则只有 0.14 美元），每百万个输出 token 2.19 美元，相比之下，o1 的收费为 15 美元和 60 美元，价格相差接近 30 倍，R1 的优势不言而喻。</p>
<blockquote>
<p><strong>API方式</strong>是指用户可以通过程序，直接访问大模型企业的对外服务接口，按照输入和输出的字数（准确来说是 token，即字元的数量，一个汉字大约 0.5-1个 token，一个英文字母大约 1-3 个 token）。</p>
</blockquote>
<p>低价的原因之一，是在大模型 API 的使用场景中，用户输入有相当比例是重复的。例如或在多轮对话中，每一轮都要将前几轮的内容重复输入。因此，<strong>DeepSeek独创了上下文硬盘缓存技术</strong>，把预计未来会重复使用的内容，缓存在分布式的硬盘阵列中。如果输入存在重复，则重复的部分只需要从缓存读取，无需计算，从而大幅降低成本和计算时间。</p>
<p><img src="https://pic2.zhimg.com/v2-854bdd3cfd106104e8f984fada456b03_1440w.jpg" alt="img"></p>
<p>DeepSeek 对于上下文硬盘缓存技术的说明</p>
<p>总而言之，通过各种技术手段，DeepSeek 成功地将大模型的训练成本降低了数十倍，这使得更多企业和个人能够承担得起 AI 技术的使用成本。再通过“开源”这种方式，推动了 AI 技术的普及和应用，为全世界的广大用户提供了高性价比的选择</p>
<h2 id="二、启示"><a href="#二、启示" class="headerlink" title="二、启示"></a>二、启示</h2><ol>
<li><strong>技术能力的重要性</strong>：需要掌握人工智能、大数据等前沿技术，以适应未来的就业市场。</li>
<li><strong>持续学习与自我提升</strong>：保持对新技术的敏感度，不断更新自己的知识储备。</li>
<li><strong>团队合作与创新精神</strong>：在项目中积极参与，培养协作能力和创新的思维方式。</li>
<li><strong>商业化应用的理解</strong>：明白技术如何转化为实际价值，关注技术与商业的结合。</li>
</ol>
<h2 id="三、如何用DeepSeek做科研"><a href="#三、如何用DeepSeek做科研" class="headerlink" title="三、如何用DeepSeek做科研"></a>三、如何用DeepSeek做科研</h2><p>指令一般包含三部分：<strong>背景与问题</strong>、<strong>自身需求</strong>，<strong>还有精细要求</strong>。下面给大家分享 6个 DeepSeek 指令，助你更好地使用它。</p>
<h3 id="No-1-明确方向"><a href="#No-1-明确方向" class="headerlink" title="No.1 明确方向"></a>No.1 明确方向</h3><p>作为一名专注于[XX]的[XXX专家]，我目前正着手撰写一篇关于[XXX]的学术论文。希望你能对这一主题的研究背景进行详细阐述，并推荐一些相关文献，以便进一步明确研究重点和思路。</p>
<p><strong>1、背景梳理指令</strong></p>
<p>在DeepSeek对话框中输入“梳理[XXX]主题的研究背景，包括发展历程、重要节点和当前趋势”。它会为你提供一个清晰的背景框架，帮助你快速了解该领域的全貌。</p>
<p><strong>2、文献推荐指令</strong></p>
<p>输入“推荐[XXX]主题的高影响力文献，重点关注近5年的研究成果”。DeepSeek会根据你的需求，筛选出最相关的文献，让你直接获取高质量的参考资料。</p>
<p><strong>3、研究重点聚焦指令</strong></p>
<p>输入“分析[XXX]主题的研究热点和未来发展方向”。DeepSeek会结合最新的研究动态，为你指出值得深入探索的领域，帮助你明确研究方向。</p>
<h3 id="No-2-论文选题"><a href="#No-2-论文选题" class="headerlink" title="No.2 论文选题"></a>No.2 论文选题</h3><p>我目前是一名[XXX专家]，主要研究领域包括[XXX等方向]。我正在准备撰写一篇关于[XXX]的学术论文，能否帮我构思5个相关的论文选题方向？</p>
<p><strong>1、选题拓展指令</strong></p>
<p>输入“基于[XXX]主题，生成5个具有创新性的论文选题方向”。DeepSeek会结合当前的研究趋势和未被充分探索的领域，为你提供独特的选题思路。</p>
<p><strong>2、选题优化指令</strong></p>
<p>输入“评估[XXX]主题的论文选题可行性，考虑研究难度和实际意义”。它会从多个角度分析选题的可行性，帮助你选择最适合自己的研究方向。</p>
<p><strong>3、选题对比指令</strong></p>
<p>输入“对比[XXX]主题的多个选题方向，分析其研究价值和创新点”。DeepSeek会为你提供详细的对比分析，让你清晰地看到每个选题的优势和不足。</p>
<h3 id="No-3-搜集文献"><a href="#No-3-搜集文献" class="headerlink" title="No.3 搜集文献"></a>No.3 搜集文献</h3><p>我的研究主题为“XXX”，请梳理XXX的现有研究进展与技术发展动态。同时，总结当前研究中存在的不足之处或尚未填补的研究空白，并协助我查找2020年之后的相关文献资料。</p>
<p><strong>1、研究进展梳理指令</strong></p>
<p>输入“梳理[XXX]主题的现有研究进展，按时间顺序总结关键成果”。DeepSeek会为你提供一个清晰的研究进展脉络，让你快速了解该领域的最新动态。</p>
<p><strong>2、研究空白分析指令</strong></p>
<p>输入“分析[XXX]主题当前研究中存在的不足和研究空白”。它会结合最新的研究文献，指出尚未解决的问题，为你的研究提供切入点。</p>
<p><strong>3、文献查找指令</strong></p>
<p>输入“查找2020年之后关于[XXX]主题的高被引文献”。DeepSeek会直接为你提供最新的文献资源，节省你大量的查找时间。</p>
<h3 id="No-4-撰写摘要"><a href="#No-4-撰写摘要" class="headerlink" title="No.4 撰写摘要"></a>No.4 撰写摘要</h3><p>我的研究主题为“XXX”，请为我撰写一篇约300字的摘要。</p>
<p><strong>1、摘要生成指令</strong></p>
<p>输入“为[XXX]主题撰写一篇300字的学术摘要，突出研究目的方法、和结论”。DeepSeek会根据你的主题，生成一个简洁明了的摘要，帮助你快速完成摘要部分。</p>
<p><strong>2、摘要优化指令</strong></p>
<p>输入“优化[XXX]主题的摘要，使其更具逻辑性和吸引力”。它会对生成的摘要进行润色，确保语言流畅、逻辑清晰。</p>
<p><strong>3、摘要校对指令</strong></p>
<p>输入“校对[XXX]主题的摘要，检查语法和拼写错误”。DeepSeek会仔细检查摘要中的每一个细节，确保其完美无误。</p>
<h3 id="No-5-筛选关键词"><a href="#No-5-筛选关键词" class="headerlink" title="No.5 筛选关键词"></a>No.5 筛选关键词</h3><p>依据摘要的核心内容，帮我筛选出3-5个精准的高频关键词，确保它们能够准确反映论文的主题和研究重点，并附上简要说明。</p>
<p><strong>1、关键词提取指令</strong></p>
<p>输入“从[XXX]主题的摘要中提取3-5个核心关键词”。DeepSeek会根据摘要内容，精准提取最能反映主题的关键词。</p>
<p><strong>2、关键词说明指令</strong></p>
<p>输入“为[XXX]主题的关键词提供简要说明，解释其在研究中的重要性”。它会为每个关键词提供详细的解释，帮助你更好地理解其意义。</p>
<p><strong>3、关键词优化指令</strong></p>
<p>输入“优化[XXX]主题的关键词，确保其准确性和专业性”。DeepSeek会根据最新的学术规范和研究趋势，调整关键词，使其更具专业性。</p>
<h3 id="No-6-拟定大纲"><a href="#No-6-拟定大纲" class="headerlink" title="No.6 拟定大纲"></a>No.6 拟定大纲</h3><p>作为一名[XXX领域专家]，请根据摘要、引言、关键词等信息，为“XXX”这篇论文拟定一份大纲。</p>
<p><strong>1、大纲生成指令</strong></p>
<p>输入“根据[XXX]主题的摘要和关键词，生成一份详细的论文大纲”。DeepSeek会为你生成一个结构清晰、内容完整的论文大纲，帮助你规划写作进度。</p>
<p><strong>2、大纲细化指令</strong></p>
<p>输入“细化[XXX]主题的论文大纲，增加每个章节的子标题和主要内容”。它会进一步完善大纲，让你在写作时更有方向感。</p>
<p><strong>3、大纲调整指令</strong></p>
<p>输入“根据最新研究动态，调整[XXX]主题的论文大纲”。DeepSeek会结合最新的研究进展，优化大纲内容，确保其时效性和科学性。</p>
<p>通过以上6个核心指令，DeepSeek不仅能帮你节省大量时间，还能提升你的科研效率和论文质量。希望这些技巧能成为你在科研路上的得力助手！</p>
<p>研究方向：</p>
<ol>
<li>脑机接口——植物人、抑郁症</li>
<li>程序</li>
<li>教育</li>
</ol>
<p>使用：</p>
<ol>
<li>根据要求创新点写代码</li>
<li>写论文（文献）</li>
<li>结合画图工具生成图片</li>
<li></li>
</ol>
<p>prompt</p>
<ul>
<li>个人知识库<ul>
<li>相关文献、代码（ github ）</li>
<li>数字真人，多模态（ 语音和文字的转化 ），卡顿可利用工作流转化</li>
<li>ai 助手（ 面试官 ）</li>
</ul>
</li>
<li>工作流</li>
<li>写论文<ul>
<li>文献</li>
<li>看论文找方向</li>
<li>写代码</li>
<li>画图建模</li>
<li>写证明</li>
<li>实现算法</li>
<li>纠错</li>
</ul>
</li>
<li></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2025/07/16/z.nn.Embedding/</url>
    <content><![CDATA[<h3 id="什么是-nn-Embedding？"><a href="#什么是-nn-Embedding？" class="headerlink" title="什么是 nn.Embedding？"></a>什么是 <code>nn.Embedding</code>？</h3><p><code>nn.Embedding</code> 就像一个“词典”或者“查找表”，它把一些数字（比如，单词的编号）转换成一个个有意义的“向量”（向量就是一串数字，代表某个东西的特征）。</p>
<h3 id="为什么要用它？"><a href="#为什么要用它？" class="headerlink" title="为什么要用它？"></a>为什么要用它？</h3><p>假设你有一个句子，比如：“我 喜欢 学习”。在计算机的眼里，计算机并不理解“我”这个字，或者“喜欢”这个字，它只能看到数字。为了让计算机能够理解这些词语，我们需要把每个词语转换成一个“数字编号”。但是，单纯的数字编号其实并不能告诉计算机这些词语的意思。</p>
<p>这时候，<code>nn.Embedding</code> 就来了。它会把每个编号的单词转换成一个“有意义”的数字序列（这个序列我们叫它“向量”）。这些“向量”能够包含关于这个词的更多信息，比如它和其他词的关系。</p>
<h3 id="举个简单的例子"><a href="#举个简单的例子" class="headerlink" title="举个简单的例子"></a>举个简单的例子</h3><p>假设我们有三个单词：<strong>“苹果”</strong>, <strong>“香蕉”</strong>, <strong>“橙子”</strong>，我们给每个词一个编号：</p>
<ul>
<li>苹果：0</li>
<li>香蕉：1</li>
<li>橙子：2</li>
</ul>
<p>我们用 <code>nn.Embedding</code> 创建一个“查找表”，它把这些数字编号转换成一组数字。比如：</p>
<ul>
<li>苹果（编号 0）变成 [0.2, 0.5, -0.3]</li>
<li>香蕉（编号 1）变成 [0.1, -0.4, 0.7]</li>
<li>橙子（编号 2）变成 [-0.2, 0.6, 0.9]</li>
</ul>
<p>这些数字就是“向量”，它们能帮助计算机更好地理解这些单词。虽然我们现在看的这些向量数字看起来有点复杂，但它们可以让计算机知道“苹果”和“香蕉”之间有什么关系，或者“苹果”和“橙子”有什么相似之处。</p>
<h3 id="什么时候用到？"><a href="#什么时候用到？" class="headerlink" title="什么时候用到？"></a>什么时候用到？</h3><p>比如，在做 <strong>自然语言处理</strong>（NLP）时，计算机要处理文本、分析句子里的单词、理解意思。这时候就可以用 <code>nn.Embedding</code> 来把单词转换成向量。这样，计算机就可以通过这些向量“比较”单词之间的关系，做一些像翻译、语法分析、情感分析等任务。</p>
<h3 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h3><p><code>nn.Embedding</code> 就是一个帮助计算机把离散的东西（比如单词的编号）转换成一个“向量”的工具，这样计算机就能更好地理解这些东西之间的关系。简单来说，它就是把“编号”变成了“有意思的数字”，让计算机能够做更多的聪明的事情。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2025/07/16/z.nn.linear/</url>
    <content><![CDATA[<h3 id="类比："><a href="#类比：" class="headerlink" title="类比："></a>类比：</h3><p>想象你有一台咖啡机，它有一个输入口和一个输出口。输入口可以放入咖啡豆和水，这些输入会经过咖啡机的处理，最终变成一杯咖啡。<code>nn.Linear</code> 就像这台咖啡机，它有输入和输出，它的作用是将输入“转换”成输出。</p>
<h3 id="什么是-nn-Linear？"><a href="#什么是-nn-Linear？" class="headerlink" title="什么是 nn.Linear？"></a>什么是 <code>nn.Linear</code>？</h3><p>在神经网络中，<code>nn.Linear</code> 是一个线性层，它的作用是接收一个输入向量，通过一定的“加权”和“偏移”处理，输出一个新的向量。简单来说，<code>nn.Linear</code> 会根据一定的规则将输入数据转化为输出数据。</p>
<h3 id="数学解释："><a href="#数学解释：" class="headerlink" title="数学解释："></a>数学解释：</h3><p><code>nn.Linear</code> 可以看作是一个矩阵乘法操作。它接受一个输入向量 <code>x</code>，然后用一个权重矩阵 <code>W</code> 进行乘法操作，再加上一个偏置项 <code>b</code>。公式是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">复制代码y = W * x + b</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li><code>x</code> 是输入向量。</li>
<li><code>W</code> 是权重矩阵，它控制每个输入特征对输出的影响。</li>
<li><code>b</code> 是偏置项，它帮助调整输出的结果。</li>
<li><code>y</code> 是输出向量。</li>
</ul>
<h3 id="举个例子："><a href="#举个例子：" class="headerlink" title="举个例子："></a>举个例子：</h3><p>假设我们有一个非常简单的神经网络，它的输入是一个 2 维向量 <code>[x1, x2]</code>。如果我们使用一个 <code>nn.Linear</code> 层，它的输出是一个 3 维的向量 <code>[y1, y2, y3]</code>。</p>
<ul>
<li>输入向量是 <code>[x1, x2]</code>，也就是咖啡机放入的原料。</li>
<li>权重矩阵 <code>W</code> 是一个 3x2 的矩阵（因为我们要从 2 维的输入转到 3 维的输出）。</li>
<li>偏置项 <code>b</code> 是一个 3 维的向量，用来调整输出。</li>
</ul>
<p>在这个 <code>nn.Linear</code> 层中，输入 <code>[x1, x2]</code> 会与 <code>W</code> 矩阵相乘，然后加上偏置 <code>b</code>，最终输出 3 维向量 <code>[y1, y2, y3]</code>。</p>
<h3 id="直观理解："><a href="#直观理解：" class="headerlink" title="直观理解："></a>直观理解：</h3><ol>
<li><strong>输入</strong>：你传入的数据（例如，学生的数学成绩和英语成绩）。</li>
<li><strong>加权计算</strong>：<code>nn.Linear</code> 会给每个输入数据分配不同的权重，就像老师给每个学科的成绩打分一样。</li>
<li><strong>输出</strong>：通过加权计算后，你得到一个新的输出（例如，学生的总成绩或一个预测值）。</li>
</ol>
<h3 id="作用："><a href="#作用：" class="headerlink" title="作用："></a>作用：</h3><ol>
<li><strong>信息传递</strong>：<code>nn.Linear</code> 层是神经网络中信息传递的关键，它将输入的数据转化成模型能理解的输出。</li>
<li><strong>学习规则</strong>：在训练过程中，神经网络会不断调整这些权重和偏置，让输出更接近正确答案，从而完成任务，比如分类或预测。</li>
</ol>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p><code>nn.Linear</code> 就是神经网络中的一个“转换器”，它通过矩阵乘法和加偏置的方式，将输入数据转化成输出数据。它的作用就像是将原始数据加上权重和调整，帮助神经网络理解并做出预测。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2025/07/16/z.softmax%20%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<p>Softmax 是一种数学函数，通常用于机器学习和深度学习中，特别是在分类问题里。它的作用是将一组数转换成一个概率分布，简单来说，Softmax 会把输入的数值（通常是网络的输出）转换成一个范围在 0 到 1 之间的概率，并且这些概率的总和为 1。</p>
<h3 id="怎么理解-Softmax？"><a href="#怎么理解-Softmax？" class="headerlink" title="怎么理解 Softmax？"></a>怎么理解 Softmax？</h3><p>假设你有几个分类结果的得分，比如在一个三分类问题中，你得到了以下三个得分：</p>
<ul>
<li>类别 1 得分：2.0</li>
<li>类别 2 得分：1.0</li>
<li>类别 3 得分：0.1</li>
</ul>
<p>这些得分并不能直接告诉我们哪个类别是最有可能的，Softmax 就是用来将这些得分转换成概率的。</p>
<h3 id="Softmax-的计算过程"><a href="#Softmax-的计算过程" class="headerlink" title="Softmax 的计算过程"></a>Softmax 的计算过程</h3><p>Softmax 的公式大致如下：</p>
<p>P(y=i)=ezi∑jezj<em>P</em>(<em>y</em>=<em>i</em>)=∑<em>j<strong>e</strong>z<strong>j</strong>e<strong>z</strong>i</em></p>
<ul>
<li>zi<em>z**i</em> 是每个类别的得分（比如 2.0, 1.0, 0.1）。</li>
<li>ezi<em>e<strong>z</strong>i</em> 是对每个得分取指数（exponential），这个步骤让更高的得分变得更明显。</li>
<li>然后，把每个类别的指数结果除以所有类别的指数结果之和，这样所有类别的概率加起来就等于 1。</li>
</ul>
<h3 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h3><p>我们拿上面的得分举个例子：</p>
<ol>
<li>计算每个得分的指数（e的幂）：<ul>
<li>类别 1: e2.0≈7.39<em>e</em>2.0≈7.39</li>
<li>类别 2: e1.0≈2.72<em>e</em>1.0≈2.72</li>
<li>类别 3: e0.1≈1.11<em>e</em>0.1≈1.11</li>
</ul>
</li>
<li>计算指数结果的总和：<ul>
<li>总和 = 7.39+2.72+1.11=11.227.39+2.72+1.11=11.22</li>
</ul>
</li>
<li>计算每个类别的概率：<ul>
<li>类别 1: 7.3911.22≈0.6611.227.39≈0.66</li>
<li>类别 2: 2.7211.22≈0.2411.222.72≈0.24</li>
<li>类别 3: 1.1111.22≈0.1011.221.11≈0.10</li>
</ul>
</li>
</ol>
<p>最终，我们得到了每个类别的概率。类别 1 的概率最大，所以 Softmax 告诉我们，类别 1 是最有可能的分类结果。</p>
<h3 id="为什么使用-Softmax？"><a href="#为什么使用-Softmax？" class="headerlink" title="为什么使用 Softmax？"></a>为什么使用 Softmax？</h3><ol>
<li><strong>输出概率</strong>：Softmax 可以把任何得分（无论它们的值是多少）转换成概率，这对于分类任务很重要。</li>
<li><strong>总和为 1</strong>：Softmax 确保所有类别的概率加起来等于 1，使得模型的输出是一个有效的概率分布。</li>
<li><strong>提高区分度</strong>：它通过指数函数放大高得分和低得分之间的差异，这让高分的类别更明显，低分的类别被抑制。</li>
</ol>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p>Softmax 就是一个将得分转换为概率的函数，它帮助我们做出更准确的分类判断，特别是在多类别分类任务中。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2025/07/16/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%94%A8Python%E6%90%AD%E5%BB%BALLMCreate%20a%20LLM%20/</url>
    <content><![CDATA[<h1 id="从零开始用Python搭建LLM-Create-a-LLM"><a href="#从零开始用Python搭建LLM-Create-a-LLM" class="headerlink" title="从零开始用Python搭建LLM|Create a LLM"></a>从零开始用Python搭建LLM|Create a LLM</h1><h2 id="一、配置anaconda"><a href="#一、配置anaconda" class="headerlink" title="一、配置anaconda"></a>一、配置anaconda</h2><p><a href="https://blog.csdn.net/qq_44000789/article/details/142214660">最新版最详细Anaconda新手安装+配置+环境创建教程-CSDN博客</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 添加清华源</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line"> </span><br><span class="line"># 添加阿里云镜像源</span><br><span class="line">conda config --add channels https://mirrors.aliyun.com/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.aliyun.com/anaconda/pkgs/main/</span><br><span class="line"> </span><br><span class="line"># 添加中科大源</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"># （可选）设置搜索时显示通道地址</span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - defaults</span><br><span class="line">  - https://repo.anaconda.com/pkgs/main</span><br><span class="line">  - https://repo.anaconda.com/pkgs/r</span><br><span class="line">  - https://repo.anaconda.com/pkgs/msys2</span><br><span class="line">show_channel_urls: true</span><br></pre></td></tr></table></figure>
<h2 id="二、环境"><a href="#二、环境" class="headerlink" title="二、环境"></a>二、环境</h2><ol>
<li><p>安装库</p>
<ul>
<li>matplotlib</li>
<li>numpy</li>
<li>jupyter</li>
<li>pylzma</li>
<li>ipykernel：将实际的jupyternotebooke能够和虚拟环境引入笔记本</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">记一次报错：下载时出现ModuleNotFoundError: No module named &#x27;distutils.msvccompiler</span><br><span class="line">解决方案：pip install setuptools==58.0.0 wheel==0.36.2（降级建造工具即可）</span><br></pre></td></tr></table></figure>
</li>
<li><p>Pylzma 构造工具</p>
</li>
<li><p>Jupyter Notebook</p>
</li>
</ol>
<h2 id="三、学会使用Pytorch"><a href="#三、学会使用Pytorch" class="headerlink" title="三、学会使用Pytorch"></a>三、学会使用Pytorch</h2><ol>
<li><p>使用GTP学习</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.询问特定名字含义（如nn.Embedding是什么意思）</span><br><span class="line">2.限定讲解对象（如向初二同学解释）</span><br></pre></td></tr></table></figure>
<p>eg.  <a href="nn.Embedding.md">nn.Embedding.md</a> </p>
</li>
<li><p>学习知识点</p>
<ul>
<li>software</li>
<li>点积</li>
<li>神经学网络</li>
<li>优化器</li>
<li>标准差</li>
</ul>
</li>
</ol>
<h2 id="四、self-attention"><a href="#四、self-attention" class="headerlink" title="四、self-attention"></a>四、self-attention</h2><ol>
<li><p>令牌</p>
<ul>
<li><p>K（key）：为每个单词生成一个不同的小张量，表示包含的内容</p>
</li>
<li><p>Q（query）：表示所在寻找的东西</p>
</li>
<li><p>V：</p>
</li>
</ul>
</li>
<li><p><strong>Dot Product(K, Q)</strong></p>
</li>
<li>Sac</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2025/07/16/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/</url>
    <content><![CDATA[<h1 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h1><blockquote>
<p>学习视频</p>
<p><a href="https://www.bilibili.com/video/BV1ev411P7dR/?spm_id_from=333.1391.0.0&amp;vd_source=f087eabd3aa1e0f48fafe303a9a3a49b">语义分割前言_哔哩哔哩_bilibili</a></p>
</blockquote>
<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p><strong>目标：</strong></p>
<ul>
<li>[x] 什么是语义分割</li>
<li>[x] 暂定的学习规划</li>
<li>[x] 语义分割任务常见数据集格式</li>
<li>[x] 语义分割得到结果的具体形式</li>
<li>[x] 语义分割常见评价标准</li>
<li>[x] 语义分割标注工具</li>
</ul>
<h3 id="1-常见分割任务"><a href="#1-常见分割任务" class="headerlink" title="1. 常见分割任务"></a>1. 常见分割任务</h3><ol>
<li><p>语义分割（FCN）：对每一个像素进行分类</p>
</li>
<li><p>实例分割（Mask R-CNN）：针对同一个类别的不同目标也采用不同颜色进行分类，结果更精细，只关注目标背景</p>
</li>
<li><p>全景分割（Panoptic FPN）语义 + 实例 + 背景划分</p>
</li>
</ol>
<blockquote>
<p>精细程度逐级递增</p>
</blockquote>
<p><img src="d4feeb82775c742b95f2bca8aa9444954dd05abe.jpg@682w_!web-note.webp" alt="img"></p>
<h3 id="2-pytorch-官方提供的语义分割网络"><a href="#2-pytorch-官方提供的语义分割网络" class="headerlink" title="2. pytorch 官方提供的语义分割网络"></a>2. pytorch 官方提供的语义分割网络</h3><p><img src="460884667254062d83d862562f79021274b71feb.jpg@682w_!web-note.webp" alt="img"></p>
<h3 id="3-语义分割任务常见数据集格式"><a href="#3-语义分割任务常见数据集格式" class="headerlink" title="3. 语义分割任务常见数据集格式"></a>3. 语义分割任务常见数据集格式</h3><ol>
<li><p><strong>Pascal VOC</strong></p>
<blockquote>
<p><a href="https://blog.csdn.net/qq_37541097/article/details/115787033">PASCAL VOC2012数据集介绍_pascal voc 2012-CSDN博客</a></p>
</blockquote>
<p>语义分割中提供的是png图片（记录每个像素所属的一个类别信息），这个png图片使用调色板的模式进行存储。</p>
<p>图片（第二张图片）实际是一个一通道的图片（黑白图片），但看到的确实彩色的。</p>
<p>用 python 的 Pillow 去读取 png 图片的话，默认读取的是调色板的模式（P模式），通道数为1（单通道）。</p>
<p>但是读取图片进行训练的时候只需要关注每个像素所属的类别索引即可</p>
<p>目标的边缘都会有一个特殊的颜色进行分割，或者图片中的一些特殊去也会用这个颜色进行填充，而这些位置对应的像素值是255万。在训练过程中，会抛弃像素值为255万的地方，因为这些地方并不好严格确定其所属类型。</p>
<p>除此之外，有一些不好区分类别的地方，也可用这个颜色进行填充。例如图中的长方形区域，在原图中是有一个飞机的尾翼部分的，但是并不好进行分割，故直接使用了像素值为255的数值进行填充，填充遮蔽之后再训练网络的时候就不会去计算这部分的损失。</p>
</li>
</ol>
<p><img src="image-20250208151458501.png" alt="image-20250208151458501"></p>
<blockquote>
<p>像素值指的是数字图像的基本单位像素所具有的数值信息。它是用来定义图像的亮度或颜色等级的，对彩色图像而言，每个像素通常包含了红、绿、蓝三个颜色通道的数值信息，这三个颜色通道的数值组合决定了该像素呈现的颜色。</p>
<p>像素值是三维数值</p>
</blockquote>
<p><img src="image-20250208152753100.png" alt="image-20250208152753100"></p>
<ol>
<li><p><strong>MS COCO</strong></p>
<blockquote>
<p><a href="https://blog.csdn.net/qq_37541097/article/details/113247318">MS COCO数据集介绍以及pycocotools简单使用_coco数据集最多一张图有多少个instance-CSDN博客</a></p>
<p>这篇论文是关于读取每张图片的分割信息的部分，如何读取并得到每个图像所对应的标签图片</p>
</blockquote>
<p>针对图像中的每一个目标都给出了一个<strong>多边形</strong>的一个<strong>坐标形式</strong>（x坐标.y坐标，两个一组一个坐标点，点连成线，得到目标），将图像中的所有目标绘制出来，即可得到右下角抽离出来的训练图案。</p>
<p>这个结果图片与 Pascal 的 png 图片结果是一样的，不过并没有标注边缘信息，因此使用MS COCO数据集就需要自己将多边形信息解码成png图片（期望的标签图片）。计算损失时，就是拿预测的每个像素对应的类别与真实标签的每个类型进行对比计算。</p>
<p>另外，记录的多边形信息除可用于语义分割外，还可以用于进行实例分割，因这样已经记录了每个目标的，是能够将每个目标都区分出来的</p>
</li>
</ol>
<p><img src="image-20250208152939744.png" alt="image-20250208152939744"></p>
<h3 id="4-语义分割得到结果的具体形式"><a href="#4-语义分割得到结果的具体形式" class="headerlink" title="4. 语义分割得到结果的具体形式"></a>4. 语义分割得到结果的具体形式</h3><blockquote>
<p>单通道图片</p>
</blockquote>
<ul>
<li>以下是单通道 + 调色板，利用 PyTorch 官方的 FCN 网络预测的结果（背景位置像素值为0， 飞机位置像素值为1，人位置的像素值为15）。</li>
</ul>
<p>如果直接以灰度图片显示的话，看到的图片是一幅黑色的（因为不同目标的像素值实际都很小—-1和15），肉眼根本看不出区别，加上调色板，可以让每个像素对应一个彩色，方便可视化我们的预测结果。</p>
<ul>
<li>每个像素的数值对应类别索引</li>
</ul>
<p><img src="image-20250208154730540.png" alt="image-20250208154730540"></p>
<h3 id="5-常见语义分割评价指标"><a href="#5-常见语义分割评价指标" class="headerlink" title="5. 常见语义分割评价指标"></a>5. 常见语义分割评价指标</h3><ol>
<li><p><strong>Pixel Accuracy（Global Acc）</strong></p>
<ul>
<li>分子是预测标签图像中所有预测正确的像素个数的总和</li>
<li>分母是图片的总像素个数</li>
</ul>
</li>
<li><p><strong>mean Acc</strong></p>
<p>将每个类别的 Acc 计算出来，然后再进行一个求和，然后再取平均</p>
</li>
<li><p><strong>mean IoU</strong></p>
<p>计算每一个类别的 IoU，然后再对每个类别 IoU 的累和求平均</p>
<p>其实和目标检测 IoU 理论上是一样的，都是两个目标面积的交集比上他们面积的并集 </p>
<ul>
<li>假设绿色的圆圈对应的是真实的标签，蓝色的圆圈对应的是预测的标签，那么n~ii~ 对应的是这两个圈重合的部分，即预测正确的部分</li>
<li>t~i~ 对应的是类别 i 的总个数，即绿色圆圈部分的面积，而<img src="image-20250208162640581.png" alt="image-20250208162640581">对应的是预测标签中所有预测为类别 i 一个像素总个数，即蓝色圆圈部分的面积，由于计算的时候中间部分计算了两次，所以还需要减去一次中间部分 n~ii~</li>
</ul>
<p>论文中最常见的是 mean IoU</p>
</li>
</ol>
<blockquote>
<p>n~ii~ ：针对类别i，预测正确的总像素个数</p>
</blockquote>
<p><img src="image-20250208160252213.png" alt="image-20250208160252213"></p>
<h4 id="Pytorch-官方的一个计算方法——通过构建一个混淆矩阵来进行计算"><a href="#Pytorch-官方的一个计算方法——通过构建一个混淆矩阵来进行计算" class="headerlink" title="Pytorch 官方的一个计算方法——通过构建一个混淆矩阵来进行计算"></a>Pytorch 官方的一个计算方法——通过构建一个混淆矩阵来进行计算</h4><p><img src="image-20250208163130675.png" alt="image-20250208163130675"></p>
<ol>
<li><strong>Global ACC</strong></li>
</ol>
<ul>
<li>为了方便理解，现将所有标注为0的位置设置为白色，非0标注的位置全部设置为灰色，这样把所有预测标签为0的结果全部提取出来了，</li>
<li>然后预测正确的位置用绿色进行表示，预测错误的位置用红色表示</li>
<li>右图中16是预测为0的正确像素总是（即绿色像素总个数），2为预测为0的预测错误的像素总个数（即红色像素总个数），错误像素原本对应的索引是3</li>
</ul>
<p><img src="image-20250208163420330.png" alt="image-20250208163420330"></p>
<ul>
<li>同样在预测标签当中，将所有预测为1的结果全部提取出来，预测正确的用绿色表示，预测错误的用红色表示</li>
</ul>
<p><img src="image-20250208163907857.png" alt="image-20250208163907857"></p>
<ul>
<li>以此类推，可以分别预测出类别2，类别3，类别4对应的参数</li>
<li>最终得到一个混淆矩阵<ul>
<li>分子是预测标签图像中所有预测正确的像素个数的总和</li>
<li>分母是图片的总像素个数</li>
<li>对角线对应的全部是预测正确的像素个数，即分子是混淆矩阵对角线上的数字之和</li>
<li>可以将混淆矩阵的所有个数相加得到分母，或者直接使用标签（8行8列8*8=64）得到像素值</li>
</ul>
</li>
</ul>
<p><img src="image-20250208165128870.png" alt="image-20250208165128870"></p>
<ol>
<li><strong>mean ACC</strong></li>
</ol>
<p><img src="image-20250208165950994.png" alt="image-20250208165950994"></p>
<ol>
<li><strong>mean IoU</strong></li>
</ol>
<p><img src="image-20250208170239310.png" alt="image-20250208170239310"></p>
<p><img src="image-20250208170304472.png" alt="image-20250208170304472"></p>
<h3 id="6-标注工具"><a href="#6-标注工具" class="headerlink" title="6. 标注工具"></a>6. 标注工具</h3><ol>
<li><strong>Labelme</strong></li>
</ol>
<blockquote>
<p><a href="https://blog.csdn.net/qq_37541097/article/details/120162702">Labelme分割标注软件使用_labelme2voc.py-CSDN博客</a></p>
</blockquote>
<p><img src="image-20250208170416293.png" alt="image-20250208170416293"></p>
<ol>
<li><strong>EISeg</strong> —- 百度开源的深度学习框架</li>
</ol>
<blockquote>
<p><a href="https://blog.csdn.net/qq_37541097/article/details/120154543">EISeg分割标注软件使用_eiseg使用-CSDN博客</a></p>
</blockquote>
<p><img src="image-20250208170854204.png" alt="image-20250208170854204"></p>
<p>开源仓库：<a href="https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.10/EISeg">PaddleSeg/EISeg at release/2.10 · PaddlePaddle/PaddleSeg</a></p>
<h2 id="二、转置卷积（Transposed-Convolution）"><a href="#二、转置卷积（Transposed-Convolution）" class="headerlink" title="二、转置卷积（Transposed Convolution）"></a>二、转置卷积（Transposed Convolution）</h2><blockquote>
<p><a href="https://arxiv.org/abs/1603.07285">[1603.07285] A guide to convolution arithmetic for deep learning</a></p>
</blockquote>
<p> <a href="卷积.md">卷积.md</a> </p>
<h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h3><ul>
<li><p>在语义分割和对抗神经网络 gan 当中的作用：<strong>采样</strong>（upsampling）</p>
</li>
<li><p>左侧的图是一个传统的卷积，输入的是高宽为 4 <em> 4 的特征层，克隆大小是 3 </em> 3的，padding = 0， strides = 1，通过卷积之后，得到的输出特征层的高宽是 2 * 2 的</p>
</li>
<li><p>右边的图是转置卷积，对于输入的是 2 <em> 2 的特征层，同时在四周填充一些零元素，填充之后同样使用 3 </em> 3 的卷积核来进行卷积处理，通过转置卷积之后，发现输入特征层大小是 2 <em> 2，输出特征层大小变成了 4 </em> 4，输出变大了，这也是转置卷积最常用的一种情况，就是<strong>伤采样</strong>。</p>
<ol>
<li><p>转置卷积不是卷积的逆运算</p>
<ul>
<li><p>deconvolution卷积逆运算的名称，但同时在某些地方也被认为是转置卷积，这很容易混淆，所以一般不用这个做称呼</p>
</li>
<li><p>转置卷积只是将特征层的大小还原回卷积之前的大小，但其数值是和输入特征层的数值不一样，所以转置卷积并不算一个卷积逆运算的过程</p>
</li>
</ul>
</li>
<li><p>转置卷积也是卷积</p>
</li>
</ol>
</li>
</ul>
<p><img src="image-20250209142613047.png" alt="image-20250209142613047"></p>
<video src="/../../../../../AppData/Local/Packages/Microsoft.ScreenSketch_8wekyb3d8bbwe/TempState/Recordings/20250209-0636-50.4310252.mp4"></video>

<blockquote>
<p>第一次听到转置卷积是在李宏毅老师课上，印象深刻的一句话：转置卷积就是卷积。对了，补充一下，把卷积核矩阵转置乘原图矩阵就是转置卷积，因此卷积运算的反向传播就是通过转置卷积实现的。以及转置卷积在生成任务中如果卷积核大小为3，步长为2，会有非常明显的棋盘效应，因此更推荐使用最临近插值或双线性插值后再接一个卷积来取代转置卷积。</p>
</blockquote>
<h3 id="2-转置卷积运算步骤"><a href="#2-转置卷积运算步骤" class="headerlink" title="2. 转置卷积运算步骤"></a>2. 转置卷积运算步骤</h3><p><img src="image-20250209161051085.png" alt="image-20250209161051085"></p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2025/07/16/%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93/</url>
    <content><![CDATA[<ul>
<li>[ ] 网页版DeepSeek的缺点</li>
<li>[ ] RAG技术和模型微调的区别</li>
<li>[ ] Embedding 模型</li>
<li>[ ] 本地部署流程</li>
</ul>
<h2 id="一、网页版DeepSeek的缺点"><a href="#一、网页版DeepSeek的缺点" class="headerlink" title="一、网页版DeepSeek的缺点"></a>一、网页版DeepSeek的缺点</h2><ul>
<li>需求：绝对的 <strong>隐私保护</strong> 和 <strong>个性化</strong> 知识库的构建</li>
<li>缺点：<ul>
<li>隐私安全</li>
<li>上传文件的限制</li>
<li>附件扩展上下文功能有限</li>
</ul>
</li>
</ul>
<h2 id="二、RAG技术和模型微调的区别"><a href="#二、RAG技术和模型微调的区别" class="headerlink" title="二、RAG技术和模型微调的区别"></a>二、RAG技术和模型微调的区别</h2><p>目的：解决大模型的<strong>幻觉</strong>问题</p>
<ul>
<li><strong>微调</strong>：在已有的预训练模型基础上，再结合特定任务的数据集进一步对其进行训练，使得模型在这一领域中表现得更好</li>
<li><strong>RAG</strong>：在生成回答之前，通过信息检索从外部知识库中查找与问题相关的知识，增强生成过程中的信息来源，从而提升生成的质量和准确性<ul>
<li>检索</li>
<li>增强</li>
<li>生成</li>
</ul>
</li>
</ul>
<h3 id="三、-Embedding-模型"><a href="#三、-Embedding-模型" class="headerlink" title="三、 Embedding 模型"></a>三、 Embedding 模型</h3><ul>
<li><strong>Embedding（嵌入）</strong> ：将自然语言转化为机器可以直接理解的高维向量，并且同这一构成捕获到文本背后的语言信息（ 比如不同文本之间的相似度关系 ） ——《数学之美》</li>
</ul>
<blockquote>
<p>简而言之，Embedding 就是为了解析上传的附件</p>
</blockquote>
<ul>
<li>模型分类：<ul>
<li>chat 模型</li>
<li>Embedding 模型</li>
</ul>
</li>
</ul>
<h3 id="四、本地部署流程"><a href="#四、本地部署流程" class="headerlink" title="四、本地部署流程"></a>四、本地部署流程</h3><ol>
<li><p>下载 ollama ， 通过ollma 将DeepSeek 模型下载到本地运行</p>
<ul>
<li><p>下载 ollama 平台</p>
</li>
<li><p>配置环境变量</p>
<ul>
<li><p>OLLAMA_HOST - 0.0.0.0:11434</p>
<p>让虚拟机里的RAGFlow能够访问到本机上的 Ollama</p>
</li>
<li><p>OLLAMA_MODELS - 自定义位置</p>
<p>ollama 默认会把模型下载到 C 盘，自定义修改模型下载位置</p>
</li>
</ul>
</li>
<li><p>下载模型</p>
</li>
</ul>
</li>
<li><p>下载 RAGflow 源代码和 Docker，通过 Docker 来本地部署 RAGflow</p>
<ul>
<li>下载 RAGFlow 源代码</li>
<li>下载 Docker（ 包含运行 RAGFlow 所需的依赖、库和配置 ）</li>
</ul>
</li>
<li><p>在 RAGflow 中构建个人知识库并实现基于个人知识库的对话问答</p>
</li>
</ol>
<ul>
<li>docker 成功启动以后，浏览器输入 localhost:80 来访问RAGFlow</li>
<li>在“模型提供商”中添加我们本地部署的 deepseek-r1模型</li>
<li>在“系统模型设置”中配置 chat 模型（ deepseek-r1:1.5b ) 和 Embedding 模型，散光  （RAGFlow 自带的即可）</li>
<li>创建知识库，上传文件，解析文件</li>
<li>创建聊天助手（注意prompt 和 tokens 的配置）</li>
<li>开始对话</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2025/07/16/%E5%8D%B7%E7%A7%AF/</url>
    <content><![CDATA[<h1 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h1><p><a href="https://www.zhihu.com/question/22298352">如何通俗易懂地解释卷积？ - 知乎</a></p>
<p>从数学上讲，卷积就是一种运算。</p>
<p>某种运算，能被定义出来，至少有以下特征：</p>
<ul>
<li>首先是抽象的、符号化的</li>
<li>其次，在生活、科研中，有着广泛的作用</li>
</ul>
<p>比如加法：</p>
<ul>
<li>a+b ，是抽象的，本身只是一个数学符号</li>
<li>在现实中，有非常多的意义，比如增加、合成、旋转等等</li>
</ul>
<p>卷积，是我们学习高等数学之后，新接触的一种运算，因为涉及到积分、级数，所以看起来觉得很复杂。</p>
<p><strong>1 卷积的定义</strong></p>
<p>我们称 (f∗g)(n) 为 f,g 的卷积</p>
<p>其连续的定义为：</p>
<p><img src="image-20250209160306870.png" alt="image-20250209160306870"></p>
<p>其离散的定义为：</p>
<p><img src="image-20250209160324392.png" alt="image-20250209160324392"></p>
<p>这两个式子有一个共同的特征：</p>
<p><img src="v2-d3df01f12b869d431c65f97ad307508f_720w.webp" alt="img"></p>
<p>这个特征有什么意义？</p>
<p>我们令 x=τ,y=n−τ ，那么 x+y=n 就是下面这些直线：</p>
<p><img src="v2-8be52f6bada3f7a21cebfc210d2e7ea0_720w.webp" alt="动图"></p>
<p>如果遍历这些直线，就好比，把毛巾沿着角卷起来：</p>
<video src="%E5%8D%B7%E7%A7%AF/87ec7ad8-2328-11eb-a2f4-5af206f672cd.mp4"></video>

<p>此处受到 <a href="https://zhihu.com/question/54677157/answer/141245297">荆哲：卷积为什么叫「卷」积？</a> 答案的启发。</p>
<p>只看数学符号，卷积是抽象的，不好理解的，但是，我们可以通过现实中的意义，来<strong>习惯</strong>卷积这种运算，正如我们小学的时候，学习加减乘除需要各种苹果、糖果来帮助我们习惯一样。</p>
<p>我们来看看现实中，这样的定义有什么意义。</p>
<p><strong>2 <a href="https://zhida.zhihu.com/search?content_id=71624064&amp;content_type=Answer&amp;match_order=1&amp;q=离散卷积&amp;zhida_source=entity">离散卷积</a>的例子：丢骰子</strong></p>
<p>我有两枚骰子：</p>
<p><img src="v2-e279045403bb2b0d8de72262f37562cd_720w.webp" alt="img"></p>
<p>把这两枚骰子都抛出去：</p>
<p><img src="v2-53f1a57bc5e9ee0eb6b6f18ab7654337_720w.webp" alt="img"></p>
<p>求：</p>
<p><img src="v2-e8826b4dfaf68b5af638b0c126cb67a7_720w.webp" alt="img"></p>
<p>这里问题的关键是，两个骰子加起来要等于4，这正是卷积的应用场景。</p>
<p>我们把骰子各个点数出现的概率表示出来：</p>
<p><img src="v2-4763fd548536b21640d01d3f8a59c546_720w.webp" alt="img"></p>
<p>那么，两枚骰子点数加起来为4的情况有：</p>
<p><img src="v2-a67a711702ce48cd7632e783ae0a1f42_720w.webp" alt="img"></p>
<p><img src="v2-d6ff10bf39c46397ab2bebb971d4b58c_720w.webp" alt="img"></p>
<p><img src="v2-0cdabcc04398ea723aa6e47e05072e5c_720w-1739085721284-197.webp" alt="img"></p>
<p>因此，两枚骰子点数加起来为4的概率为：</p>
<p><img src="image-20250209160620015.png" alt="image-20250209160620015"></p>
<p>符合卷积的定义，把它写成标准的形式就是：</p>
<p><img src="image-20250209160628280.png" alt="image-20250209160628280"></p>
<p><strong>3 连续卷积的例子：做馒头</strong></p>
<p>楼下早点铺子生意太好了，供不应求，就买了一台机器，不断的生产馒头。</p>
<p>假设馒头的生产速度是 f(t) ，那么一天后生产出来的馒头总量为：</p>
<p><img src="image-20250209160637580.png" alt="image-20250209160637580"></p>
<p>馒头生产出来之后，就会慢慢腐败，假设腐败函数为 g(t) ，比如，10个馒头，24小时会腐败：</p>
<p><img src="image-20250209160644600.png" alt="image-20250209160644600"></p>
<p>想想就知道，第一个小时生产出来的馒头，一天后会经历24小时的腐败，第二个小时生产出来的馒头，一天后会经历23小时的腐败。</p>
<p>如此，我们可以知道，一天后，馒头总共腐败了：</p>
<p><img src="image-20250209160656243.png" alt="image-20250209160656243"></p>
<p>这就是连续的卷积。</p>
<p><strong>4 图像处理</strong></p>
<p><strong>4.1 原理</strong></p>
<p>有这么一副图像，可以看到，图像上有很多噪点：</p>
<p><img src="v2-8d161328acd72d035e461c0b89b753e5_720w.webp" alt="img"></p>
<p>高频信号，就好像平地耸立的山峰：</p>
<p><img src="v2-294698966c5a833cd750df70c0a00c21_720w.webp" alt="img"></p>
<p>看起来很显眼。</p>
<p>平滑这座山峰的办法之一就是，把山峰刨掉一些土，填到山峰周围去。用数学的话来说，就是把山峰周围的高度平均一下。</p>
<p>平滑后得到：</p>
<p><img src="v2-83b24e8ed70f17df6bc3b921ebe6276c_720w.webp" alt="img"></p>
<p><strong>4.2 计算</strong></p>
<p>卷积可以帮助实现这个平滑算法。</p>
<p>有噪点的原图，可以把它转为一个矩阵：</p>
<p><img src="v2-8dd14775ab8c91a09507f52e44f347f3_720w-1739085721284-198.webp" alt="img"></p>
<p>然后用下面这个平均矩阵（说明下，原图的处理实际上用的是<a href="https://zhida.zhihu.com/search?content_id=71624064&amp;content_type=Answer&amp;match_order=1&amp;q=正态分布矩阵&amp;zhida_source=entity">正态分布矩阵</a>，这里为了简单，就用了算术平均矩阵）来平滑图像：</p>
<p>g=[191919191919191919]</p>
<p>记得刚才说过的算法，把高频信号与周围的数值平均一下就可以平滑山峰。</p>
<p>比如我要平滑 a1,1 点，就在矩阵中，取出 a1,1 点附近的点组成矩阵 f ，和 g 进行<a href="https://zhida.zhihu.com/search?content_id=71624064&amp;content_type=Answer&amp;match_order=1&amp;q=卷积计算&amp;zhida_source=entity">卷积计算</a>后，再填回去：</p>
<p><img src="v2-5ee9a99988137a42d1067deab36c4e51_720w.webp" alt="img"></p>
<p>要注意一点，为了运用卷积， g 虽然和 f 同维度，但下标有点不一样：</p>
<p><img src="v2-779d4e972dc557be55e6131edbb8db9f_720w-1739085721284-199.webp" alt="img"></p>
<p>我用一个动图来说明下计算过程：</p>
<p><img src="v2-c658110eafe027eded16864fb6a28f46_720w-1739085721284-200.jpg" alt="动图封面"></p>
<p>写成卷积公式就是：</p>
<p><img src="image-20250209160715355.png" alt="image-20250209160715355"></p>
<p>要求 c~4,5~ ，一样可以套用上面的<a href="https://zhida.zhihu.com/search?content_id=71624064&amp;content_type=Answer&amp;match_order=2&amp;q=卷积公式&amp;zhida_source=entity">卷积公式</a>。</p>
<p>这样相当于实现了 g 这个矩阵在原来图像上的划动（准确来说，下面这幅图把 g 矩阵旋转了 180° ）：</p>
<p><img src="v2-15fea61b768f7561648dbea164fcb75f_720w-1739085721284-201.jpg" alt="动图封面"></p>
<p>此图出处：<a href="https://link.zhihu.com/?target=https%3A//mlnotebook.github.io/post/CNN1/">Convolutional Neural Networks - Basics</a></p>
<p>文章最新版本在（有可能会有后续更新）：<a href="https://link.zhihu.com/?target=https%3A//www.matongxue.com/madocs/32.html">如何通俗地理解卷积？</a></p>
]]></content>
  </entry>
</search>
