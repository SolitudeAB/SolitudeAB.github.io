<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Week1 | SolitudeAB</title><meta name="author" content="SolitudeAB"><meta name="copyright" content="SolitudeAB"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="语义分割">
<meta property="og:type" content="article">
<meta property="og:title" content="Week1">
<meta property="og:url" content="http://example.com/2025/07/20/Week1/index.html">
<meta property="og:site_name" content="SolitudeAB">
<meta property="og:description" content="语义分割">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar.jpg">
<meta property="article:published_time" content="2025-07-19T16:00:00.000Z">
<meta property="article:modified_time" content="2025-07-27T12:09:50.480Z">
<meta property="article:author" content="SolitudeAB">
<meta property="article:tag" content="504医学AI入门">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="http://example.com/2025/07/20/Week1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/seach.xml","preload":false,"top_n_per_article":3,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'medium_zoom',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Week1',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><link rel="stylesheet" href="/css/transpancy.css"><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="SolitudeAB" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="web_bg" style="background:url(/img/background1.jpg);background-attachment: local;background-position: center;background-size: cover;background-repeat: no-repeat;"></div><div id="web_bg" style="background-image: url(url(/img/background1.jpg));"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/avatar.jpg" alt="Logo"><span class="site-name">SolitudeAB</span></a><a class="nav-page-title" href="/"><span class="site-name">Week1</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Week1</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-19T16:00:00.000Z" title="发表于 2025-07-20 00:00:00">2025-07-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-27T12:09:50.480Z" title="更新于 2025-07-27 20:09:50">2025-07-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/504%E5%8C%BB%E5%AD%A6AI/">504医学AI</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h1><blockquote>
<p>学习视频</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1ev411P7dR/?spm_id_from=333.1391.0.0&amp;vd_source=f087eabd3aa1e0f48fafe303a9a3a49b">语义分割前言_哔哩哔哩_bilibili</a></p>
</blockquote>
<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p><strong>目标：</strong></p>
<ul>
<li>[x] 什么是语义分割</li>
<li>[x] 暂定的学习规划</li>
<li>[x] 语义分割任务常见数据集格式</li>
<li>[x] 语义分割得到结果的具体形式</li>
<li>[x] 语义分割常见评价标准</li>
<li>[x] 语义分割标注工具</li>
</ul>
<h3 id="1-常见分割任务"><a href="#1-常见分割任务" class="headerlink" title="1. 常见分割任务"></a>1. 常见分割任务</h3><ol>
<li><p>语义分割（FCN）：对每一个像素进行分类</p>
</li>
<li><p>实例分割（Mask R-CNN）：针对同一个类别的不同目标也采用不同颜色进行分类，结果更精细，只关注目标背景</p>
</li>
<li><p>全景分割（Panoptic FPN）语义 + 实例 + 背景划分</p>
</li>
</ol>
<blockquote>
<p>精细程度逐级递增</p>
</blockquote>
<p><img src="d4feeb82775c742b95f2bca8aa9444954dd05abe.jpg@682w_!web-note.webp" alt="img"></p>
<h3 id="2-pytorch-官方提供的语义分割网络"><a href="#2-pytorch-官方提供的语义分割网络" class="headerlink" title="2. pytorch 官方提供的语义分割网络"></a>2. pytorch 官方提供的语义分割网络</h3><p><img src="460884667254062d83d862562f79021274b71feb.jpg@682w_!web-note.webp" alt="img"></p>
<h3 id="3-语义分割任务常见数据集格式"><a href="#3-语义分割任务常见数据集格式" class="headerlink" title="3. 语义分割任务常见数据集格式"></a>3. 语义分割任务常见数据集格式</h3><ol>
<li><p><strong>Pascal VOC</strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/115787033">PASCAL VOC2012数据集介绍_pascal voc 2012-CSDN博客</a></p>
</blockquote>
<p>语义分割中提供的是png图片（记录每个像素所属的一个类别信息），这个png图片使用调色板的模式进行存储。</p>
<p>图片（第二张图片）实际是一个一通道的图片（黑白图片），但看到的确实彩色的。</p>
<p>用 python 的 Pillow 去读取 png 图片的话，默认读取的是调色板的模式（P模式），通道数为1（单通道）。</p>
<p>但是读取图片进行训练的时候只需要关注每个像素所属的类别索引即可</p>
<p>目标的边缘都会有一个特殊的颜色进行分割，或者图片中的一些特殊去也会用这个颜色进行填充，而这些位置对应的像素值是255万。在训练过程中，会抛弃像素值为255万的地方，因为这些地方并不好严格确定其所属类型。</p>
<p>除此之外，有一些不好区分类别的地方，也可用这个颜色进行填充。例如图中的长方形区域，在原图中是有一个飞机的尾翼部分的，但是并不好进行分割，故直接使用了像素值为255的数值进行填充，填充遮蔽之后再训练网络的时候就不会去计算这部分的损失。</p>
</li>
</ol>
<p><img src="image-20250208151458501.png" alt="image-20250208151458501"></p>
<blockquote>
<p>像素值指的是数字图像的基本单位像素所具有的数值信息。它是用来定义图像的亮度或颜色等级的，对彩色图像而言，每个像素通常包含了红、绿、蓝三个颜色通道的数值信息，这三个颜色通道的数值组合决定了该像素呈现的颜色。</p>
<p>像素值是三维数值</p>
</blockquote>
<p><img src="image-20250208152753100.png" alt="image-20250208152753100"></p>
<ol>
<li><p><strong>MS COCO</strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/113247318">MS COCO数据集介绍以及pycocotools简单使用_coco数据集最多一张图有多少个instance-CSDN博客</a></p>
<p>这篇论文是关于读取每张图片的分割信息的部分，如何读取并得到每个图像所对应的标签图片</p>
</blockquote>
<p>针对图像中的每一个目标都给出了一个<strong>多边形</strong>的一个<strong>坐标形式</strong>（x坐标.y坐标，两个一组一个坐标点，点连成线，得到目标），将图像中的所有目标绘制出来，即可得到右下角抽离出来的训练图案。</p>
<p>这个结果图片与 Pascal 的 png 图片结果是一样的，不过并没有标注边缘信息，因此使用MS COCO数据集就需要自己将多边形信息解码成png图片（期望的标签图片）。计算损失时，就是拿预测的每个像素对应的类别与真实标签的每个类型进行对比计算。</p>
<p>另外，记录的多边形信息除可用于语义分割外，还可以用于进行实例分割，因这样已经记录了每个目标的，是能够将每个目标都区分出来的</p>
</li>
</ol>
<p><img src="image-20250208152939744.png" alt="image-20250208152939744"></p>
<h3 id="4-语义分割得到结果的具体形式"><a href="#4-语义分割得到结果的具体形式" class="headerlink" title="4. 语义分割得到结果的具体形式"></a>4. 语义分割得到结果的具体形式</h3><blockquote>
<p>单通道图片</p>
</blockquote>
<ul>
<li>以下是单通道 + 调色板，利用 PyTorch 官方的 FCN 网络预测的结果（背景位置像素值为0， 飞机位置像素值为1，人位置的像素值为15）。</li>
</ul>
<p>如果直接以灰度图片显示的话，看到的图片是一幅黑色的（因为不同目标的像素值实际都很小—-1和15），肉眼根本看不出区别，加上调色板，可以让每个像素对应一个彩色，方便可视化我们的预测结果。</p>
<ul>
<li>每个像素的数值对应类别索引</li>
</ul>
<p><img src="image-20250208154730540.png" alt="image-20250208154730540"></p>
<h3 id="5-常见语义分割评价指标"><a href="#5-常见语义分割评价指标" class="headerlink" title="5. 常见语义分割评价指标"></a>5. 常见语义分割评价指标</h3><ol>
<li><p><strong>Pixel Accuracy（Global Acc）</strong></p>
<ul>
<li>分子是预测标签图像中所有预测正确的像素个数的总和</li>
<li>分母是图片的总像素个数</li>
</ul>
</li>
<li><p><strong>mean Acc</strong></p>
<p>将每个类别的 Acc 计算出来，然后再进行一个求和，然后再取平均</p>
</li>
<li><p><strong>mean IoU</strong></p>
<p>计算每一个类别的 IoU，然后再对每个类别 IoU 的累和求平均</p>
<p>其实和目标检测 IoU 理论上是一样的，都是两个目标面积的交集比上他们面积的并集 </p>
<ul>
<li>假设绿色的圆圈对应的是真实的标签，蓝色的圆圈对应的是预测的标签，那么n~ii~ 对应的是这两个圈重合的部分，即预测正确的部分</li>
<li>t~i~ 对应的是类别 i 的总个数，即绿色圆圈部分的面积，而<img src="image-20250208162640581.png" alt="image-20250208162640581">对应的是预测标签中所有预测为类别 i 一个像素总个数，即蓝色圆圈部分的面积，由于计算的时候中间部分计算了两次，所以还需要减去一次中间部分 n~ii~</li>
</ul>
<p>论文中最常见的是 mean IoU</p>
</li>
</ol>
<blockquote>
<p>n~ii~ ：针对类别i，预测正确的总像素个数</p>
</blockquote>
<p><img src="image-20250208160252213.png" alt="image-20250208160252213"></p>
<h4 id="Pytorch-官方的一个计算方法——通过构建一个混淆矩阵来进行计算"><a href="#Pytorch-官方的一个计算方法——通过构建一个混淆矩阵来进行计算" class="headerlink" title="Pytorch 官方的一个计算方法——通过构建一个混淆矩阵来进行计算"></a>Pytorch 官方的一个计算方法——通过构建一个混淆矩阵来进行计算</h4><p><img src="image-20250208163130675.png" alt="image-20250208163130675"></p>
<ol>
<li><strong>Global ACC</strong></li>
</ol>
<ul>
<li>为了方便理解，现将所有标注为0的位置设置为白色，非0标注的位置全部设置为灰色，这样把所有预测标签为0的结果全部提取出来了，</li>
<li>然后预测正确的位置用绿色进行表示，预测错误的位置用红色表示</li>
<li>右图中16是预测为0的正确像素总是（即绿色像素总个数），2为预测为0的预测错误的像素总个数（即红色像素总个数），错误像素原本对应的索引是3</li>
</ul>
<p><img src="image-20250208163420330.png" alt="image-20250208163420330"></p>
<ul>
<li>同样在预测标签当中，将所有预测为1的结果全部提取出来，预测正确的用绿色表示，预测错误的用红色表示</li>
</ul>
<p><img src="image-20250208163907857.png" alt="image-20250208163907857"></p>
<ul>
<li>以此类推，可以分别预测出类别2，类别3，类别4对应的参数</li>
<li>最终得到一个混淆矩阵<ul>
<li>分子是预测标签图像中所有预测正确的像素个数的总和</li>
<li>分母是图片的总像素个数</li>
<li>对角线对应的全部是预测正确的像素个数，即分子是混淆矩阵对角线上的数字之和</li>
<li>可以将混淆矩阵的所有个数相加得到分母，或者直接使用标签（8行8列8*8=64）得到像素值</li>
</ul>
</li>
</ul>
<p><img src="image-20250208165128870.png" alt="image-20250208165128870"></p>
<ol>
<li><strong>mean ACC</strong></li>
</ol>
<p><img src="image-20250208165950994.png" alt="image-20250208165950994"></p>
<ol>
<li><strong>mean IoU</strong></li>
</ol>
<p><img src="image-20250208170239310.png" alt="image-20250208170239310"></p>
<p><img src="image-20250208170304472.png" alt="image-20250208170304472"></p>
<h3 id="6-标注工具"><a href="#6-标注工具" class="headerlink" title="6. 标注工具"></a>6. 标注工具</h3><ol>
<li><strong>Labelme</strong></li>
</ol>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/120162702">Labelme分割标注软件使用_labelme2voc.py-CSDN博客</a></p>
</blockquote>
<p><img src="image-20250208170416293.png" alt="image-20250208170416293"></p>
<ol>
<li><strong>EISeg</strong> —- 百度开源的深度学习框架</li>
</ol>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/120154543">EISeg分割标注软件使用_eiseg使用-CSDN博客</a></p>
</blockquote>
<p><img src="image-20250208170854204.png" alt="image-20250208170854204"></p>
<p>开源仓库：<a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.10/EISeg">PaddleSeg/EISeg at release/2.10 · PaddlePaddle/PaddleSeg</a></p>
<h2 id="二、转置卷积（Transposed-Convolution）"><a href="#二、转置卷积（Transposed-Convolution）" class="headerlink" title="二、转置卷积（Transposed Convolution）"></a>二、转置卷积（Transposed Convolution）</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1603.07285">[1603.07285] A guide to convolution arithmetic for deep learning</a></p>
</blockquote>
<p> <a href="卷积.md">卷积.md</a> </p>
<h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h3><ul>
<li><p>在语义分割和对抗神经网络 gan 当中的作用：<strong>采样</strong>（upsampling）</p>
</li>
<li><p>左侧的图是一个传统的卷积，输入的是高宽为 4 <em> 4 的特征层，克隆大小是 3 </em> 3的，padding = 0， strides = 1，通过卷积之后，得到的输出特征层的高宽是 2 * 2 的</p>
</li>
<li><p>右边的图是转置卷积，对于输入的是 2 <em> 2 的特征层，同时在四周填充一些零元素，填充之后同样使用 3 </em> 3 的卷积核来进行卷积处理，通过转置卷积之后，发现输入特征层大小是 2 <em> 2，输出特征层大小变成了 4 </em> 4，输出变大了，这也是转置卷积最常用的一种情况，就是<strong>伤采样</strong>。</p>
<ol>
<li><p>转置卷积不是卷积的逆运算</p>
<ul>
<li><p>deconvolution卷积逆运算的名称，但同时在某些地方也被认为是转置卷积，这很容易混淆，所以一般不用这个做称呼</p>
</li>
<li><p>转置卷积只是将特征层的大小还原回卷积之前的大小，但其数值是和输入特征层的数值不一样，所以转置卷积并不算一个卷积逆运算的过程</p>
</li>
</ul>
</li>
<li><p>转置卷积也是卷积</p>
</li>
</ol>
</li>
</ul>
<p><img src="image-20250209142613047.png" alt="image-20250209142613047"></p>
<video src="/../../../../../AppData/Local/Packages/Microsoft.ScreenSketch_8wekyb3d8bbwe/TempState/Recordings/20250209-0636-50.4310252.mp4"></video>

<blockquote>
<p>第一次听到转置卷积是在李宏毅老师课上，印象深刻的一句话：转置卷积就是卷积。对了，补充一下，把卷积核矩阵转置乘原图矩阵就是转置卷积，因此卷积运算的反向传播就是通过转置卷积实现的。以及转置卷积在生成任务中如果卷积核大小为3，步长为2，会有非常明显的棋盘效应，因此更推荐使用最临近插值或双线性插值后再接一个卷积来取代转置卷积。</p>
</blockquote>
<h3 id="2-转置卷积运算步骤"><a href="#2-转置卷积运算步骤" class="headerlink" title="2. 转置卷积运算步骤"></a>2. 转置卷积运算步骤</h3><p><img src="image-20250209161051085-1753011630523-19.png" alt="image-20250209161051085"></p>
<h2 id="基本环境配置"><a href="#基本环境配置" class="headerlink" title="基本环境配置"></a>基本环境配置</h2><h3 id="一、实验室Linux系统连接"><a href="#一、实验室Linux系统连接" class="headerlink" title="一、实验室Linux系统连接"></a>一、实验室Linux系统连接</h3><h3 id="二、Anaconda-安装和路径设置"><a href="#二、Anaconda-安装和路径设置" class="headerlink" title="二、Anaconda 安装和路径设置"></a>二、Anaconda 安装和路径设置</h3><h3 id="三、Pytorch-和-Opencv-依赖库的安装"><a href="#三、Pytorch-和-Opencv-依赖库的安装" class="headerlink" title="三、Pytorch 和 Opencv 依赖库的安装"></a>三、Pytorch 和 Opencv 依赖库的安装</h3><ol>
<li>Pytorch（GPU）(conda) </li>
<li>和 Opencv-Python（4.1.0.25） (pip) </li>
</ol>
<h3 id="四、Pycharm-与-实验室服务器直连（可直接编辑文件和可视化编辑代码）"><a href="#四、Pycharm-与-实验室服务器直连（可直接编辑文件和可视化编辑代码）" class="headerlink" title="四、Pycharm 与 实验室服务器直连（可直接编辑文件和可视化编辑代码）"></a>四、Pycharm 与 实验室服务器直连（可直接编辑文件和可视化编辑代码）</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/680151749">Pycharm连接linux服务器远程开发 2023 直连 - 知乎</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43486940/article/details/123229290">如何在pycharm中使用anaconda的虚拟环境_pycharm使用anaconda环境-CSDN博客</a></p>
</blockquote>
<h2 id="Opencv图像处理—python版"><a href="#Opencv图像处理—python版" class="headerlink" title="Opencv图像处理—python版"></a>Opencv图像处理—python版</h2><p>——专门做图像处理的库</p>
<p>（1）缩放（）裁剪（）</p>
<h3 id="一、常见的图片格式及图片类型"><a href="#一、常见的图片格式及图片类型" class="headerlink" title="一、常见的图片格式及图片类型"></a>一、常见的图片格式及图片类型</h3><blockquote>
<p>图片格式</p>
</blockquote>
<ol>
<li>bmp：比较老的格式|不常见|无损-&gt;基本上无压缩|体积大|被淘汰</li>
<li>jpg（jpeg）：用<strong>最少的磁盘空间</strong>得到<strong>较好的图片质量</strong></li>
<li>png：无损压缩的位图片形格式（首选）</li>
</ol>
<blockquote>
<p>图片类型</p>
</blockquote>
<p>[ 黑白 ]  [ 彩色 ]</p>
<p>【gif(动图) -&gt; 一帧一帧拿出来】</p>
<p>图片的本质：由像素点组成的一个矩阵，每个元素（像素点）都是在 [0,255] 之间</p>
<h3 id="二、读取第一张黑白照片"><a href="#二、读取第一张黑白照片" class="headerlink" title="二、读取第一张黑白照片"></a>二、读取第一张黑白照片</h3><blockquote>
<p>遇到的问题</p>
<ol>
<li>pycharm 的dataview 以及 variable变量的跟踪</li>
<li>使用实验室服务器时使用cv2.imshow(‘image’, img) 出现: cannot connect to X server 错误提示</li>
</ol>
<p>问题原因及解决情况</p>
<ol>
<li>解决</li>
<li>为解决。目前知道的原因是实验室Linux服务器上无图形界面，运行cv2.imshow需要图形显示(GUI)的程序无法正常进程。现解决方向：配置X11转发，但一直卡在服务器无法ping通本地，无法转发到本地ip：0.0</li>
</ol>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">SolitudeAB</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/07/20/Week1/">http://example.com/2025/07/20/Week1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">SolitudeAB</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/504%E5%8C%BB%E5%AD%A6AI%E5%85%A5%E9%97%A8/">504医学AI入门</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/07/27/Week2/" title="Week2"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Week2</div></div><div class="info-2"><div class="info-item-1">Opencv一、常见的图片格式及图片类型 图片格式  bmp：比较老的格式|不常见|无损-&gt;基本上无压缩|体积大|被淘汰  jpg（jpeg）：用最少的磁盘空间得到较好的图片质量  png：无损压缩的位图片形格式（首选）    图片类型：[ 黑白 ]  [ 彩色 ]   ​    【gif(动图) -&gt; 一帧一帧拿出来】  图片的本质：由像素点组成的一个矩阵，每个元素（像素点）都是在 [0,255] 之间  二、读取第一张黑白图片12import cv2import numpy as np  读取和展示  path：路径 0：代表灰度图 1：彩色图  12345678path = r"./R-C.jpg"img = cv2.imread(path,0)print(type(img))print(img.shape)print(img)cv2.imshow('image', img)cv2.waitKey()cv2.destroyAllWindows()  需要注意的是这里的cv2.imshow('image',...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/08/24/CNN/" title="卷积神经网络（CNN）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-24</div><div class="info-item-2">卷积神经网络（CNN）</div></div><div class="info-2"><div class="info-item-1">卷积神经网络（CNN）的原理引言： 可查看前篇文章——神经网络：构建人工智能的基石  卷积神经网络（Convolutional Neural Network，CNN）是一种在计算机视觉领域取得了巨大成功的深度学习模型。它们的设计灵感来自于生物学中的视觉系统，旨在模拟人类视觉处理的方式。在过去的几年中，CNN已经在图像识别、目标检测、图像生成和许多其他领域取得了显著的进展，成为了计算机视觉和深度学习研究的重要组成部分。 一、图像原理在了解卷积神经网络前，我们先来看看图像的原理： 图像在计算机中是一堆按顺序排列的数字，数值为0到255。0表示最暗，255表示最亮。 如下图：  上图是只有黑白颜色的灰度图，而更普遍的图片表达方式是RGB颜色模型，即红、绿、蓝三原色的色光以不同的比例相加，以产生多种多样的色光。RGB颜色模型中，单个矩阵就扩展成了有序排列的三个矩阵，也可以用三维张量去理解。 其中的每一个矩阵又叫这个图片的一个channel（通道），宽, 高,...</div></div></div></a><a class="pagination-related" href="/2025/08/03/Week3/" title="Week3"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-03</div><div class="info-item-2">Week3</div></div><div class="info-2"><div class="info-item-1">Opencv（二） 上一周学到彩色图片像素点的统计，这一周就从纯黑纯白图片像素点统计开始  代码 1234567891011121314import cv2# 读取图片（默认以BGR格式加载）image = cv2.imread('image.jpg')# 查看矩阵内容print(image)  # 直接打印整个矩阵print(image.shape)  # 打印矩阵形状：(高度, 宽度, 通道数)# 查看特定像素值（例如第10行第20列的BGR值）print(image[10, 20])  # 输出格式：[B, G, R]# 查看部分矩阵（例如前10行前10列）print(image[:10, :10])   一、纯黑纯白图片像素点统计 以下为纯白图片(1080, 2298, 3)的像素点统计结果，可与纯黑图片做比对   不存在纯黑的图片（或者计算机很难实现），以下图片是(650, 650,...</div></div></div></a><a class="pagination-related" href="/2025/08/10/Week4/" title="Week4"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-10</div><div class="info-item-2">Week4</div></div><div class="info-2"><div class="info-item-1">Opencv（二）一、图像基础知识复习 图像是由像素构成的 像素点的多少决定了图片的质量（相同图片大小，像素点越多，单个像素点越小，图片质量越好）   图像的分类   二值图像：像素点非0即1   灰度图像：像素点有256个结果   彩色图像：由三通道（三原色RGB）进行叠加的图像     Opencv读取彩色图像的特点  读取结果：BGR（注意顺序）  每个像素点由BGR三个分量构成 例：（245，168，200）-&gt; B：245 、G：168、R：200     二、灰度图片像素的选取与修改 源码 123456789101112131415161718192021import cv2gray_img = cv2.imread(r"/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg", 0)cv2.imshow('gray_img', gray_img)#...</div></div></div></a><a class="pagination-related" href="/2025/07/27/Week2/" title="Week2"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-27</div><div class="info-item-2">Week2</div></div><div class="info-2"><div class="info-item-1">Opencv一、常见的图片格式及图片类型 图片格式  bmp：比较老的格式|不常见|无损-&gt;基本上无压缩|体积大|被淘汰  jpg（jpeg）：用最少的磁盘空间得到较好的图片质量  png：无损压缩的位图片形格式（首选）    图片类型：[ 黑白 ]  [ 彩色 ]   ​    【gif(动图) -&gt; 一帧一帧拿出来】  图片的本质：由像素点组成的一个矩阵，每个元素（像素点）都是在 [0,255] 之间  二、读取第一张黑白图片12import cv2import numpy as np  读取和展示  path：路径 0：代表灰度图 1：彩色图  12345678path = r"./R-C.jpg"img = cv2.imread(path,0)print(type(img))print(img.shape)print(img)cv2.imshow('image', img)cv2.waitKey()cv2.destroyAllWindows()  需要注意的是这里的cv2.imshow('image',...</div></div></div></a><a class="pagination-related" href="/2025/08/17/Week5/" title="Week5"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-17</div><div class="info-item-2">Week5</div></div><div class="info-2"><div class="info-item-1">图像处理方法一、Sobel算子 OpenCV 图像处理之膨胀与腐蚀 | SolitudeAB  （一）什么是Sobel算子？ Sobel 算子是图像一种图像边缘   图像边缘检测重要算子之一  与梯度密度密不可分 -&gt; 目的：图像边缘检测的方法，本质是==梯度运算==   （二）什么情况下会产生梯度？利用 3 * 3 的卷积核放在二值图像中有三种位置关系，如下   全黑全白的像素值是相同的，只有在边缘部位时会有梯度产生。所有，梯度是进行边缘你检测的一个核心(边缘的梯度：255 - 0 = 255)    （三）Sobel 算子原理 遍历过程  卷积核顺序放到原图上    卷积核固定（中间列都是0）  卷积核中心位置在中间4x3区域内（对于边缘位置，卷积核暂时无法顾及到）  但是卷积核的核心无法顾及到原图像的边缘，如下   解决方法：  法一：边缘列（行）取均值或均值  法二（官方给的理论可能性）：paddng（边缘加一行 ”补0” ）   padding为0不改变原图像，此法可以顾及到每一个像素点       梯度计算  利用3  3 的卷积核与原图上顺序遍历的3 ...</div></div></div></a><a class="pagination-related" href="/2025/08/24/Week6/" title="Week6"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-24</div><div class="info-item-2">Week6</div></div><div class="info-2"><div class="info-item-1">模型基础一、语义分割概念 学习视频 语义分割前言_哔哩哔哩_bilibili  目标：  什么是语义分割 暂定的学习规划 语义分割任务常见数据集格式 语义分割得到结果的具体形式 语义分割常见评价标准 语义分割标注工具 （一）常见分割任务 语义分割（FCN）：对每一个像素进行分类  实例分割（Mask R-CNN）：针对同一个类别的不同目标也采用不同颜色进行分类，结果更精细，只关注目标背景  全景分割（Panoptic FPN）语义 + 实例 + 背景划分  精细程度逐级递增   （二）pytorch 官方提供的语义分割网络     （三）语义分割任务常见数据集格式 Pascal VOC  PASCAL VOC2012数据集介绍_pascal voc 2012-CSDN博客  语义分割中提供的是png图片（记录每个像素所属的一个类别信息），这个png图片使用调色板的模式进行存储。 图片（第二张图片）实际是一个一通道的图片（黑白图片），但看到的确实彩色的。 用 python 的 Pillow 去读取 png...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info-name">SolitudeAB</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/SolitudeAB"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2"><span class="toc-number">1.</span> <span class="toc-text">语义分割</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%89%8D%E8%A8%80"><span class="toc-number">1.1.</span> <span class="toc-text">一、前言</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%B8%B8%E8%A7%81%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.1.1.</span> <span class="toc-text">1. 常见分割任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-pytorch-%E5%AE%98%E6%96%B9%E6%8F%90%E4%BE%9B%E7%9A%84%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C"><span class="toc-number">1.1.2.</span> <span class="toc-text">2. pytorch 官方提供的语义分割网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A0%BC%E5%BC%8F"><span class="toc-number">1.1.3.</span> <span class="toc-text">3. 语义分割任务常见数据集格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%BE%97%E5%88%B0%E7%BB%93%E6%9E%9C%E7%9A%84%E5%85%B7%E4%BD%93%E5%BD%A2%E5%BC%8F"><span class="toc-number">1.1.4.</span> <span class="toc-text">4. 语义分割得到结果的具体形式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%B8%B8%E8%A7%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-number">1.1.5.</span> <span class="toc-text">5. 常见语义分割评价指标</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Pytorch-%E5%AE%98%E6%96%B9%E7%9A%84%E4%B8%80%E4%B8%AA%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E2%80%94%E2%80%94%E9%80%9A%E8%BF%87%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5%E6%9D%A5%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97"><span class="toc-number">1.1.5.1.</span> <span class="toc-text">Pytorch 官方的一个计算方法——通过构建一个混淆矩阵来进行计算</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7"><span class="toc-number">1.1.6.</span> <span class="toc-text">6. 标注工具</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF%EF%BC%88Transposed-Convolution%EF%BC%89"><span class="toc-number">1.2.</span> <span class="toc-text">二、转置卷积（Transposed Convolution）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.2.1.</span> <span class="toc-text">1. 介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97%E6%AD%A5%E9%AA%A4"><span class="toc-number">1.2.2.</span> <span class="toc-text">2. 转置卷积运算步骤</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="toc-number">1.3.</span> <span class="toc-text">基本环境配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E9%AA%8C%E5%AE%A4Linux%E7%B3%BB%E7%BB%9F%E8%BF%9E%E6%8E%A5"><span class="toc-number">1.3.1.</span> <span class="toc-text">一、实验室Linux系统连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Anaconda-%E5%AE%89%E8%A3%85%E5%92%8C%E8%B7%AF%E5%BE%84%E8%AE%BE%E7%BD%AE"><span class="toc-number">1.3.2.</span> <span class="toc-text">二、Anaconda 安装和路径设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81Pytorch-%E5%92%8C-Opencv-%E4%BE%9D%E8%B5%96%E5%BA%93%E7%9A%84%E5%AE%89%E8%A3%85"><span class="toc-number">1.3.3.</span> <span class="toc-text">三、Pytorch 和 Opencv 依赖库的安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B%E3%80%81Pycharm-%E4%B8%8E-%E5%AE%9E%E9%AA%8C%E5%AE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%B4%E8%BF%9E%EF%BC%88%E5%8F%AF%E7%9B%B4%E6%8E%A5%E7%BC%96%E8%BE%91%E6%96%87%E4%BB%B6%E5%92%8C%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BC%96%E8%BE%91%E4%BB%A3%E7%A0%81%EF%BC%89"><span class="toc-number">1.3.4.</span> <span class="toc-text">四、Pycharm 与 实验室服务器直连（可直接编辑文件和可视化编辑代码）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Opencv%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94python%E7%89%88"><span class="toc-number">1.4.</span> <span class="toc-text">Opencv图像处理—python版</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%B8%B8%E8%A7%81%E7%9A%84%E5%9B%BE%E7%89%87%E6%A0%BC%E5%BC%8F%E5%8F%8A%E5%9B%BE%E7%89%87%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.4.1.</span> <span class="toc-text">一、常见的图片格式及图片类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E8%AF%BB%E5%8F%96%E7%AC%AC%E4%B8%80%E5%BC%A0%E9%BB%91%E7%99%BD%E7%85%A7%E7%89%87"><span class="toc-number">1.4.2.</span> <span class="toc-text">二、读取第一张黑白照片</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/24/CNN/" title="卷积神经网络（CNN）">卷积神经网络（CNN）</a><time datetime="2025-08-23T16:00:00.000Z" title="发表于 2025-08-24 00:00:00">2025-08-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/24/Week6/" title="Week6">Week6</a><time datetime="2025-08-23T16:00:00.000Z" title="发表于 2025-08-24 00:00:00">2025-08-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/24/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="神经网络">神经网络</a><time datetime="2025-08-23T16:00:00.000Z" title="发表于 2025-08-24 00:00:00">2025-08-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/17/Week5/" title="Week5">Week5</a><time datetime="2025-08-16T16:00:00.000Z" title="发表于 2025-08-17 00:00:00">2025-08-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/17/%E8%86%A8%E8%83%80%E4%B8%8E%E8%85%90%E8%9A%80/" title="OpenCV 图像处理之膨胀与腐蚀">OpenCV 图像处理之膨胀与腐蚀</a><time datetime="2025-08-16T16:00:00.000Z" title="发表于 2025-08-17 00:00:00">2025-08-17</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">©2024 - 2025 By SolitudeAB</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><div class="js-pjax"></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>