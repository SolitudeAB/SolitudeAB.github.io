<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>卷积神经网络（CNN） | SolitudeAB</title><meta name="author" content="SolitudeAB"><meta name="copyright" content="SolitudeAB"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="卷积神经网络（CNN）的原理">
<meta property="og:type" content="article">
<meta property="og:title" content="卷积神经网络（CNN）">
<meta property="og:url" content="http://example.com/2025/08/24/CNN/index.html">
<meta property="og:site_name" content="SolitudeAB">
<meta property="og:description" content="卷积神经网络（CNN）的原理">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar.jpg">
<meta property="article:published_time" content="2025-08-23T16:00:00.000Z">
<meta property="article:modified_time" content="2025-08-24T13:20:19.578Z">
<meta property="article:author" content="SolitudeAB">
<meta property="article:tag" content="504医学AI入门">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="http://example.com/2025/08/24/CNN/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/seach.xml","preload":false,"top_n_per_article":3,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'medium_zoom',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '卷积神经网络（CNN）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><link rel="stylesheet" href="/css/transpancy.css"><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="SolitudeAB" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="web_bg" style="background:url(/img/background1.jpg);background-attachment: local;background-position: center;background-size: cover;background-repeat: no-repeat;"></div><div id="web_bg" style="background-image: url(url(/img/background1.jpg));"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/avatar.jpg" alt="Logo"><span class="site-name">SolitudeAB</span></a><a class="nav-page-title" href="/"><span class="site-name">卷积神经网络（CNN）</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">卷积神经网络（CNN）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-23T16:00:00.000Z" title="发表于 2025-08-24 00:00:00">2025-08-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-24T13:20:19.578Z" title="更新于 2025-08-24 21:20:19">2025-08-24</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/504%E5%8C%BB%E5%AD%A6AI/">504医学AI</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="卷积神经网络（CNN）的原理"><a href="#卷积神经网络（CNN）的原理" class="headerlink" title="卷积神经网络（CNN）的原理"></a>卷积神经网络（CNN）的原理</h1><h2 id="引言："><a href="#引言：" class="headerlink" title="引言："></a>引言：</h2><blockquote>
<p>可查看前篇文章——神经网络：构建人工智能的基石</p>
</blockquote>
<p>卷积神经网络（Convolutional Neural Network，CNN）是一种在计算机视觉领域取得了巨大成功的深度学习模型。它们的设计灵感来自于生物学中的视觉系统，旨在模拟人类视觉处理的方式。在过去的几年中，CNN已经在图像识别、目标检测、图像生成和许多其他领域取得了显著的进展，成为了计算机视觉和深度学习研究的重要组成部分。</p>
<h2 id="一、图像原理"><a href="#一、图像原理" class="headerlink" title="一、图像原理"></a>一、图像原理</h2><p>在了解卷积神经网络前，我们先来看看图像的原理：</p>
<p>图像在计算机中是一堆按顺序排列的数字，<strong>数值为0到255</strong>。0表示最暗，255表示最亮。 如下图：</p>
<p><img src="287528d32ff227a9af61142bafa481a3.gif" alt="img"></p>
<p>上图是只有黑白颜色的灰度图，而更普遍的图片表达方式是RGB颜色模型，即红、绿、蓝三原色的色光以不同的比例相加，以产生多种多样的色光。RGB颜色模型中，单个矩阵就扩展成了有序排列的三个矩阵，也可以用三维张量去理解。</p>
<p>其中的<strong>每一个矩阵</strong>又叫这个图片的一个<strong>channel（通道），宽, 高, 深</strong>来描述。</p>
<p><img src="3ee4d843020005e6c6eca4a7fa1ae539.png" alt="img"></p>
<h2 id="二、为什么要学习卷积神经网络？"><a href="#二、为什么要学习卷积神经网络？" class="headerlink" title="二、为什么要学习卷积神经网络？"></a>二、为什么要学习卷积神经网络？</h2><p>在传统神经网络中，我们要识别下<strong>图红色框中</strong>的图像时，我们很可能识别不出来，因为这六张图的<img src="d871cc8ec807852aab00f6e1595dbdd2.png" alt="img">位置都不同，计算机<strong>无法分辨出</strong>他们其实是一种形状或物体。</p>
<p><img src="4328b16077353c4f549246917d140cac.png" alt="img"></p>
<p> <strong>传统神经网络</strong>原理如下图：</p>
<p><img src="8cbc62e0ef1552e85c47a13cbbe57f08.png" alt="img"></p>
<p>我们希望一个物体不管在画面左侧还是右侧，都会被识别为同一物体，这一特点就是<strong>不变性</strong>。为了实现平移不变性，<strong>卷积神经网络</strong>（CNN）等深度学习模型<strong>在卷积层中使用了卷积操作</strong>，这个操作可以捕捉到图像中的局部特征而不受其位置的影响。</p>
<p><img src="6e3f9cbdf2b3caa4ca3e9b2ade9856bf.png" alt="img"></p>
<h2 id="三、什么是卷积？"><a href="#三、什么是卷积？" class="headerlink" title="三、什么是卷积？"></a>三、什么是卷积？</h2><p>在卷积神经网络中，卷积操作是指将一个<strong>可移动的小窗口</strong>（称为数据窗口，如下图绿色矩形）与图像进行<strong>逐元素相乘然后相加</strong>的操作。这个小窗口其实是<strong>一组固定的权重</strong>，它可以被看作是一个特定的<strong>滤波器</strong>（filter）或<strong>卷积核</strong>。这个操作的名称“卷积”，源自于这种元素级相乘和求和的过程。这一操作是卷积神经网络名字的来源。</p>
<p><img src="7e9292ea51a94bae998fc2a3239eedfc.png" alt="img"></p>
<p>上图这个绿色小窗就是数据窗口。简而言之，<strong>卷积操作就是用一个可移动的小窗口来提取图像中的特征</strong>，这个小窗口包含了一组特定的权重，通过与图像的不同位置进行卷积操作，网络能够学习并捕捉到不同特征的信息。文字解释可能太难懂，下面直接上动图：</p>
<p><img src="d0172774f7e42ae2f6310b63e59b4906.gif" alt="img"></p>
<p>这张图中<strong>蓝色的框</strong>就是指一个数据窗口，红色框为卷积核（滤波器），最后得到的绿色方形就是卷积的结果（数据窗口中的数据与卷积核逐个元素相乘再求和）</p>
<h4 id="一张图带你了解卷积计算过程："><a href="#一张图带你了解卷积计算过程：" class="headerlink" title="一张图带你了解卷积计算过程："></a>一张图带你了解卷积计算过程：</h4><p><img src="7b8af7c9507e7652df6ff7e3c14f8a1f.png" alt="img"></p>
<h4 id="卷积需要注意哪些问题？"><a href="#卷积需要注意哪些问题？" class="headerlink" title="卷积需要注意哪些问题？"></a>卷积需要注意哪些问题？</h4><p>a. <strong>步长stride</strong>：每次滑动的位置步长。</p>
<p>b. <strong>卷积核的个数</strong>：决定输出的depth厚度。同时代表卷积核的个数。</p>
<p>c. <strong>填充值zero-padding</strong>：在外围边缘补充若干圈0，方便从初始位置以步长为单位可以刚好滑倒末尾位置，通俗地讲就是为了总长能被步长整除。</p>
<p>以上图为例，那么：</p>
<ul>
<li>数据窗口每次移动两个步长取 3*3 的局部数据，即 stride=2 。</li>
<li>两个神经元，即 depth=2 ，意味着有两个滤波</li>
<li>zero-padding=1 。</li>
</ul>
<h4 id="为什么要进行数据填充："><a href="#为什么要进行数据填充：" class="headerlink" title="为什么要进行数据填充："></a>为什么要进行数据填充：</h4><p>假设有一个大小为 4x4 的输入图像：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[1,  2,  3,  4 ],</span><br><span class="line"> [5,  6,  7,  8 ], </span><br><span class="line"> [9,  10, 11, 12], </span><br><span class="line"> [13, 14, 15, 16]]</span><br></pre></td></tr></tbody></table></figure>
<p>现在，我们要应用一个 3x3 的卷积核进行卷积操作，步幅（stride）为 1，且要使用填充（padding）为 1。如果不使用填充，<strong>卷积核的中心将无法对齐到输入图像的边缘</strong>，导致输出特征图尺寸变小。假设我们使用步幅（stride）为 1 进行卷积，那么在不使用填充的情况下，输出特征图的尺寸将是 2x2。</p>
<p>所以我们要在它的周围填充一圈0，填充为 1 意味着在输入图像的周围添加一圈零值。添加填充后的图像：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[0, 0,  0,  0,  0,  0], </span><br><span class="line"> [0, 1,  2,  3,  4,  0], </span><br><span class="line"> [0, 5,  6,  7,  8,  0], </span><br><span class="line"> [0, 9,  10, 11, 12, 0], </span><br><span class="line"> [0, 13, 14, 15, 16, 0], </span><br><span class="line"> [0, 0,  0,  0,  0,  0]]</span><br></pre></td></tr></tbody></table></figure>
<p>现在，我们将 3x3 的卷积核应用于这个填充后的输入图像，计算卷积结果，得到大小不变的特征图。</p>
<p>数据填充的主要目的是<strong>确保卷积核能够覆盖输入图像的边缘区域，同时保持输出特征图的大小</strong>。这对于在CNN中保留空间信息和有效处理图像边缘信息非常重要。</p>
<h4 id="卷积神经网络的模型是什么样的？"><a href="#卷积神经网络的模型是什么样的？" class="headerlink" title="卷积神经网络的模型是什么样的？"></a>卷积神经网络的模型是什么样的？</h4><p><img src="e76acb80eeb8bff2a722727bcc090336.png" alt="img"></p>
<p>上面红框框起来的部分便可以<strong>理解为一个滤波器</strong>，即带着<strong>一组固定权重的神经元</strong>。<strong>多个滤波器叠加便成了卷积层</strong>。</p>
<h2 id="四、卷积神经网络的构造"><a href="#四、卷积神经网络的构造" class="headerlink" title="四、卷积神经网络的构造"></a>四、卷积神经网络的构造</h2><p><img src="3c266da23107494b04b09683b8427f0e.png" alt="img"></p>
<ol>
<li><p><strong>输入层</strong><br>输入层接收原始图像数据。图像通常由三个颜色通道（红、绿、蓝）组成，形成一个二维矩阵，表示像素的强度值。</p>
</li>
<li><p><strong>卷积和激活</strong><br>卷积层将输入图像与卷积核进行卷积操作。然后，通过应用激活函数（如ReLU）来引入非线性。这一步使网络能够学习复杂的特征。</p>
</li>
<li><p><strong>池化层</strong><br>池化层通过减小特征图的大小来减少计算复杂性。它通过选择池化窗口内的最大值或平均值来实现。这有助于提取最重要的特征。</p>
</li>
<li><p><strong>多层堆叠</strong><br>CNN通常由多个卷积和池化层的堆叠组成，以逐渐提取更高级别的特征。深层次的特征可以表示更复杂的模式。</p>
</li>
<li><p><strong>全连接和输出</strong><br>最后，全连接层将提取的特征映射转化为网络的最终输出。这可以是一个分类标签、回归值或其他任务的结果。</p>
</li>
</ol>
<p>形象的过程如下图：</p>
<div><table frame="void">    <!--用了<div>进行封装-->
    <tbody><tr>
        <td><div><center>    <!--每个格子内是图片加标题-->
            <img src="487282ce8ead390f92a390a1471bb65b-1756040177840-66.gif" alt="" height="300">    <!--高度设置-->
            <br>    <!--换行-->
            展开形式    <!--标题1-->
        </center></div></td>    
         <td><div><center>    <!--第二张图片-->
            <img src="22ee60a67e1fad3d7dba9cbef60c9c11.png" alt="Typora-Logo" height="300">    
            <br>
            未展开形式
        </center></div></td>
    </tr>
</tbody></table></div>

<h2 id="五、图片经过卷积后的样子"><a href="#五、图片经过卷积后的样子" class="headerlink" title="五、图片经过卷积后的样子"></a>五、图片经过卷积后的样子</h2><p>与人眼观看事物原理相似，卷积神经网络可以看到事物的轮廓</p>
<p><img src="34501738b7bedc58964269aef8305ee3.png" alt="img"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">SolitudeAB</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/08/24/CNN/">http://example.com/2025/08/24/CNN/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">SolitudeAB</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/504%E5%8C%BB%E5%AD%A6AI%E5%85%A5%E9%97%A8/">504医学AI入门</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/08/24/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="神经网络"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">神经网络</div></div><div class="info-2"><div class="info-item-1">神经网络：构建人工智能的基石引言：神经网络是一种受到生物神经系统启发的人工智能模型，它重现了大脑中神经元之间相互连接的方式。神经网络在诸多领域中取得了显著成就，如图像识别、自然语言处理和语音识别等。这篇博客将为您解释神经网络的构造，让您能够理解这个令人着迷的领域的基本工作原理。 第一部分：神经元 - 生物的灵感在理解神经网络之前，我们首先需要了解神经元，这是神经网络的基本构建块。神经元是生物神经系统的工作单位，也是人工神经网络的灵感来源。  神经元的结构：每个神经元都由细胞体、树突和轴突组成。细胞体包含核心部分，树突接收来自其他神经元的信号，而轴突将信号传递给其他神经元。    信号传递：神经元之间的通信是通过电化学信号完成的。当信号通过树突传递到细胞体时，如果达到一定阈值，神经元就会触发并将信号传递给下一个神经元。  第二部分：人工神经元 -...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/27/Week2/" title="Week2"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-27</div><div class="info-item-2">Week2</div></div><div class="info-2"><div class="info-item-1">Opencv一、常见的图片格式及图片类型 图片格式  bmp：比较老的格式|不常见|无损-&gt;基本上无压缩|体积大|被淘汰  jpg（jpeg）：用最少的磁盘空间得到较好的图片质量  png：无损压缩的位图片形格式（首选）    图片类型：[ 黑白 ]  [ 彩色 ]   ​    【gif(动图) -&gt; 一帧一帧拿出来】  图片的本质：由像素点组成的一个矩阵，每个元素（像素点）都是在 [0,255] 之间  二、读取第一张黑白图片12import cv2import numpy as np  读取和展示  path：路径 0：代表灰度图 1：彩色图  12345678path = r"./R-C.jpg"img = cv2.imread(path,0)print(type(img))print(img.shape)print(img)cv2.imshow('image', img)cv2.waitKey()cv2.destroyAllWindows()  需要注意的是这里的cv2.imshow('image',...</div></div></div></a><a class="pagination-related" href="/2025/08/10/Week4/" title="Week4"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-10</div><div class="info-item-2">Week4</div></div><div class="info-2"><div class="info-item-1">Opencv（二）一、图像基础知识复习 图像是由像素构成的 像素点的多少决定了图片的质量（相同图片大小，像素点越多，单个像素点越小，图片质量越好）   图像的分类   二值图像：像素点非0即1   灰度图像：像素点有256个结果   彩色图像：由三通道（三原色RGB）进行叠加的图像     Opencv读取彩色图像的特点  读取结果：BGR（注意顺序）  每个像素点由BGR三个分量构成 例：（245，168，200）-&gt; B：245 、G：168、R：200     二、灰度图片像素的选取与修改 源码 123456789101112131415161718192021import cv2gray_img = cv2.imread(r"/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg", 0)cv2.imshow('gray_img', gray_img)#...</div></div></div></a><a class="pagination-related" href="/2025/07/20/Week1/" title="Week1"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-20</div><div class="info-item-2">Week1</div></div><div class="info-2"><div class="info-item-1">语义分割 学习视频 语义分割前言_哔哩哔哩_bilibili  一、前言目标：  [x] 什么是语义分割 [x] 暂定的学习规划 [x] 语义分割任务常见数据集格式 [x] 语义分割得到结果的具体形式 [x] 语义分割常见评价标准 [x] 语义分割标注工具  1. 常见分割任务 语义分割（FCN）：对每一个像素进行分类  实例分割（Mask R-CNN）：针对同一个类别的不同目标也采用不同颜色进行分类，结果更精细，只关注目标背景  全景分割（Panoptic FPN）语义 + 实例 + 背景划分    精细程度逐级递增   2. pytorch 官方提供的语义分割网络 3. 语义分割任务常见数据集格式 Pascal VOC  PASCAL VOC2012数据集介绍_pascal voc 2012-CSDN博客  语义分割中提供的是png图片（记录每个像素所属的一个类别信息），这个png图片使用调色板的模式进行存储。 图片（第二张图片）实际是一个一通道的图片（黑白图片），但看到的确实彩色的。 用 python 的 Pillow 去读取 png...</div></div></div></a><a class="pagination-related" href="/2025/08/03/Week3/" title="Week3"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-03</div><div class="info-item-2">Week3</div></div><div class="info-2"><div class="info-item-1">Opencv（二） 上一周学到彩色图片像素点的统计，这一周就从纯黑纯白图片像素点统计开始  代码 1234567891011121314import cv2# 读取图片（默认以BGR格式加载）image = cv2.imread('image.jpg')# 查看矩阵内容print(image)  # 直接打印整个矩阵print(image.shape)  # 打印矩阵形状：(高度, 宽度, 通道数)# 查看特定像素值（例如第10行第20列的BGR值）print(image[10, 20])  # 输出格式：[B, G, R]# 查看部分矩阵（例如前10行前10列）print(image[:10, :10])   一、纯黑纯白图片像素点统计 以下为纯白图片(1080, 2298, 3)的像素点统计结果，可与纯黑图片做比对   不存在纯黑的图片（或者计算机很难实现），以下图片是(650, 650,...</div></div></div></a><a class="pagination-related" href="/2025/08/17/Week5/" title="Week5"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-17</div><div class="info-item-2">Week5</div></div><div class="info-2"><div class="info-item-1">图像处理方法一、Sobel算子 OpenCV 图像处理之膨胀与腐蚀 | SolitudeAB  （一）什么是Sobel算子？ Sobel 算子是图像一种图像边缘   图像边缘检测重要算子之一  与梯度密度密不可分 -&gt; 目的：图像边缘检测的方法，本质是==梯度运算==   （二）什么情况下会产生梯度？利用 3 * 3 的卷积核放在二值图像中有三种位置关系，如下   全黑全白的像素值是相同的，只有在边缘部位时会有梯度产生。所有，梯度是进行边缘你检测的一个核心(边缘的梯度：255 - 0 = 255)    （三）Sobel 算子原理 遍历过程  卷积核顺序放到原图上    卷积核固定（中间列都是0）  卷积核中心位置在中间4x3区域内（对于边缘位置，卷积核暂时无法顾及到）  但是卷积核的核心无法顾及到原图像的边缘，如下   解决方法：  法一：边缘列（行）取均值或均值  法二（官方给的理论可能性）：paddng（边缘加一行 ”补0” ）   padding为0不改变原图像，此法可以顾及到每一个像素点       梯度计算  利用3  3 的卷积核与原图上顺序遍历的3 ...</div></div></div></a><a class="pagination-related" href="/2025/08/24/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="神经网络"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-24</div><div class="info-item-2">神经网络</div></div><div class="info-2"><div class="info-item-1">神经网络：构建人工智能的基石引言：神经网络是一种受到生物神经系统启发的人工智能模型，它重现了大脑中神经元之间相互连接的方式。神经网络在诸多领域中取得了显著成就，如图像识别、自然语言处理和语音识别等。这篇博客将为您解释神经网络的构造，让您能够理解这个令人着迷的领域的基本工作原理。 第一部分：神经元 - 生物的灵感在理解神经网络之前，我们首先需要了解神经元，这是神经网络的基本构建块。神经元是生物神经系统的工作单位，也是人工神经网络的灵感来源。  神经元的结构：每个神经元都由细胞体、树突和轴突组成。细胞体包含核心部分，树突接收来自其他神经元的信号，而轴突将信号传递给其他神经元。    信号传递：神经元之间的通信是通过电化学信号完成的。当信号通过树突传递到细胞体时，如果达到一定阈值，神经元就会触发并将信号传递给下一个神经元。  第二部分：人工神经元 -...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info-name">SolitudeAB</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/SolitudeAB"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88CNN%EF%BC%89%E7%9A%84%E5%8E%9F%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">卷积神经网络（CNN）的原理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80%EF%BC%9A"><span class="toc-number">1.1.</span> <span class="toc-text">引言：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%9B%BE%E5%83%8F%E5%8E%9F%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">一、图像原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AD%A6%E4%B9%A0%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9F"><span class="toc-number">1.3.</span> <span class="toc-text">二、为什么要学习卷积神经网络？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%B7%E7%A7%AF%EF%BC%9F"><span class="toc-number">1.4.</span> <span class="toc-text">三、什么是卷积？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E5%BC%A0%E5%9B%BE%E5%B8%A6%E4%BD%A0%E4%BA%86%E8%A7%A3%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%EF%BC%9A"><span class="toc-number">1.4.0.1.</span> <span class="toc-text">一张图带你了解卷积计算过程：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E5%93%AA%E4%BA%9B%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">1.4.0.2.</span> <span class="toc-text">卷积需要注意哪些问题？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%A1%AB%E5%85%85%EF%BC%9A"><span class="toc-number">1.4.0.3.</span> <span class="toc-text">为什么要进行数据填充：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%A8%A1%E5%9E%8B%E6%98%AF%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%EF%BC%9F"><span class="toc-number">1.4.0.4.</span> <span class="toc-text">卷积神经网络的模型是什么样的？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%9E%84%E9%80%A0"><span class="toc-number">1.5.</span> <span class="toc-text">四、卷积神经网络的构造</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%9B%BE%E7%89%87%E7%BB%8F%E8%BF%87%E5%8D%B7%E7%A7%AF%E5%90%8E%E7%9A%84%E6%A0%B7%E5%AD%90"><span class="toc-number">1.6.</span> <span class="toc-text">五、图片经过卷积后的样子</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/24/CNN/" title="卷积神经网络（CNN）">卷积神经网络（CNN）</a><time datetime="2025-08-23T16:00:00.000Z" title="发表于 2025-08-24 00:00:00">2025-08-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/24/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="神经网络">神经网络</a><time datetime="2025-08-23T16:00:00.000Z" title="发表于 2025-08-24 00:00:00">2025-08-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/17/Week5/" title="Week5">Week5</a><time datetime="2025-08-16T16:00:00.000Z" title="发表于 2025-08-17 00:00:00">2025-08-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/17/%E8%86%A8%E8%83%80%E4%B8%8E%E8%85%90%E8%9A%80/" title="OpenCV 图像处理之膨胀与腐蚀">OpenCV 图像处理之膨胀与腐蚀</a><time datetime="2025-08-16T16:00:00.000Z" title="发表于 2025-08-17 00:00:00">2025-08-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/10/Week4/" title="Week4">Week4</a><time datetime="2025-08-09T16:00:00.000Z" title="发表于 2025-08-10 00:00:00">2025-08-10</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">©2024 - 2025 By SolitudeAB</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><div class="js-pjax"></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>