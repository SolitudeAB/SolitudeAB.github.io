<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Week7 | SolitudeAB</title><meta name="author" content="SolitudeAB"><meta name="copyright" content="SolitudeAB"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="三、Dilated Convolution膨胀卷积（空洞卷积）">
<meta property="og:type" content="article">
<meta property="og:title" content="Week7">
<meta property="og:url" content="http://example.com/2025/09/16/LearningSchedule/Week7/index.html">
<meta property="og:site_name" content="SolitudeAB">
<meta property="og:description" content="三、Dilated Convolution膨胀卷积（空洞卷积）">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar.jpg">
<meta property="article:published_time" content="2025-09-15T16:00:00.000Z">
<meta property="article:modified_time" content="2025-09-16T08:41:55.500Z">
<meta property="article:author" content="SolitudeAB">
<meta property="article:tag" content="504医学AI入门">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="http://example.com/2025/09/16/LearningSchedule/Week7/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/seach.xml","preload":false,"top_n_per_article":3,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'medium_zoom',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Week7',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><link rel="stylesheet" href="/css/transpancy.css"><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="SolitudeAB" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="web_bg" style="background:url(/img/background1.jpg);background-attachment: local;background-position: center;background-size: cover;background-repeat: no-repeat;"></div><div id="web_bg" style="background-image: url(url(/img/background1.jpg));"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/avatar.jpg" alt="Logo"><span class="site-name">SolitudeAB</span></a><a class="nav-page-title" href="/"><span class="site-name">Week7</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Week7</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-09-15T16:00:00.000Z" title="发表于 2025-09-16 00:00:00">2025-09-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-16T08:41:55.500Z" title="更新于 2025-09-16 16:41:55">2025-09-16</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/504%E5%8C%BB%E5%AD%A6AI/">504医学AI</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="三、Dilated-Convolution膨胀卷积（空洞卷积）"><a href="#三、Dilated-Convolution膨胀卷积（空洞卷积）" class="headerlink" title="三、Dilated Convolution膨胀卷积（空洞卷积）"></a>三、Dilated Convolution膨胀卷积（空洞卷积）</h1><h3 id="（一）膨胀卷积和一般卷积的区别"><a href="#（一）膨胀卷积和一般卷积的区别" class="headerlink" title="（一）膨胀卷积和一般卷积的区别"></a>（一）膨胀卷积和一般卷积的区别</h3><p><img src="image-20250828120139433.png" alt="image-20250828120139433"></p>
<p>r是普通卷积和空洞卷积的差别所在，我们称之为<strong>膨胀因子</strong>。当r=1时，表示卷积核各元素之前没有空隙，即相邻两个元素间位置相差1，此时其实就是我们正常的卷积，所以广义上说，普通的卷积是一种特殊的空洞卷积；当r=2时，表示卷积核各元素之前有一个空隙，即相邻两个元素间位置相差2，此时就是我们上图中的卷积核，为方便大家理解，我把上图r=2时的卷积核提取出来，如下图所示：</p>
<p><img src="3f109228860742978c8bd0a4709370fftplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="image-20220826220545773"></p>
<p>当然了当r=3、r=4都是同样的道理，这里就不过多叙述了。</p>
<h3 id="（二）为什么使用膨胀卷积？"><a href="#（二）为什么使用膨胀卷积？" class="headerlink" title="（二）为什么使用膨胀卷积？"></a>（二）为什么使用膨胀卷积？</h3><p>在语言分割任务当中，通常会使用分类网络作为网络的 <strong>backbone</strong><sup><a href="#fn_1" id="reffn_1">1</a></sup> 。</p>
<p>首先，通过backbone，将我们的图片进行一系列的下采样，然后再通过一系列的上采样还原我们原图的大小。平常在使用图像分类网络中，我们一般会将我们的高度和宽度下采样32倍。由于后续我们需要通过上采用还原回原图的尺寸，所以如果我们将特征图的高宽下采样倍率调的太大的话，对我们还原原因的影响是很大的。比如 <strong>VGG网络</strong>，它是通过最大池化下采样，即maxpooling层进行池化操作的。通过maxpooling操作之后，首先会降低特征图或者特征层的高度和宽度。其次，最大池化会丢失一些细节信息记忆一些比较小的目标，导致无法通过后续的上采样进行还原，造成语义分割中分割的效果不是特别的理想。</p>
<p><strong>简单粗暴的去掉最大池化下采样层？</strong></p>
<p>这会导致得到特征图对应原图的感受野变小（因为最大池化下采样层是能够增大图层的感受野的），而对于最大池化下采样层之后的一系列卷积层又是在之前所对应的感受野之上进一步的操作。如果简单粗暴的去掉最大池化下采样层，肯定会后面的卷积层也会带来一定的问题。</p>
<p>因此，需要使用到膨胀卷积。</p>
<p><strong>优势</strong>：既能增大感受野，有你保持输入输出特征矩阵或特征图的高和宽不会发生变化</p>
<p>那么，是不是只要在语义分割任务当中简单粗暴的堆叠膨胀卷积层就可以？很明显不是</p>
<h3 id="（三）膨胀卷积的缺点"><a href="#（三）膨胀卷积的缺点" class="headerlink" title="（三）膨胀卷积的缺点"></a>（三）膨胀卷积的缺点</h3><p>在使用膨胀卷积的过程中经常会遇到一个名为 <strong>gridding effect</strong><sup><a href="#fn_2" id="reffn_2">2</a></sup> 的问题</p>
<p><img src="image-20250828121841132.png" alt="image-20250828121841132"></p>
<p><strong>gridding effect</strong></p>
<ol>
<li><p>膨胀系数均为2</p>
<p><img src="image-20250828151504404.png" alt="image-20250828151504404"></p>
<ul>
<li><p>Layer4 上的 pixel 利用的Layer1的数据并不是连续的，每个非零元素之间都有一定的间隔</p>
</li>
<li><p>Layer4 上的像素并没有利用到范围内所有的像素值，而是利用到了期间的一部分，这样肯定会导致缺失一些细节上的信息</p>
</li>
</ul>
</li>
<li><p>膨胀系数分别为1，2，3</p>
<p><img src="image-20250828151932930.png" alt="image-20250828151932930"></p>
<ul>
<li>Layer4 利用到了13 * 13 像素的参数，且这些参数间是相邻的</li>
<li>该实验的卷积核和膨胀卷积均为2的尺寸是一样的，参数一样的，只不过膨胀系数是不一样的</li>
<li>该图的视野和膨胀卷积均为2的一样，不过膨胀卷积均为2的很多像素并没有利用到，所以更倾向于使用膨胀系数分别为1，2，3。</li>
<li>如此对于高层的pixel而言，使用到的低层的数据是一个<strong>连续</strong>的区域</li>
</ul>
</li>
<li><p>全部用普通卷积，即膨胀系数全部为1</p>
<p><img src="image-20250828202706685.png" alt="image-20250828202706685"></p>
<ul>
<li>在参数数量相同的情况下，很明显使用了膨胀卷积之后的感受野增大了很多，从7 <em> 7（全部普通卷积） 变成了13 </em> 13（有膨胀卷积，不过根据设置的不用，像素的利用率也不同）</li>
</ul>
</li>
</ol>
<h3 id="（四）常见的Hybrid-Dilated-Convolution-HDC-膨胀因子的设计准则"><a href="#（四）常见的Hybrid-Dilated-Convolution-HDC-膨胀因子的设计准则" class="headerlink" title="（四）常见的Hybrid Dilated Convolution (HDC)膨胀因子的设计准则"></a>（四）常见的Hybrid Dilated Convolution (HDC)膨胀因子的设计准则</h3><h4 id="建议一："><a href="#建议一：" class="headerlink" title="建议一："></a>建议一：</h4><p>根据前面几次的实验可以轻松得到，第二次实验中膨胀系数为1，2，3的膨胀卷积得到的效果比最开始采用三个系数均为2的膨胀卷积的效果要更好，因为引出合理的膨胀系数——<strong>Hybrid Dilated Convolution(HDC)。</strong></p>
<p><img src="image-20250828203604250.png" alt="image-20250828203604250"></p>
<p>假设堆叠n个膨胀卷积，每个卷积核都是 <script type="math/tex">k * k</script>，如何每一个膨胀卷积的膨胀系数分别对应 <script type="math/tex">r_1</script> 到  <script type="math/tex">r_n</script> 。这里的HDC目标其实就是通过一系列膨胀卷积在之后，是能够完全覆盖底层特征层的一个方形区域的，而且这个方形区域没有任何的孔洞。定义为 <strong>“maximum distance between two nonzero values”</strong> 。（即先前实验图示当中非零元素距离为一的，就是没有间隔一列或行零元素）。</p>
<p>因为希望在高层特征层当中的一个pixel利用到底层整个区域的所有像素的话，<strong>$M_1$应该要等于1</strong>（意味着非零元素之间没有间隙）。因为$M_1$是三个数中取最大，那么$M_1$应该大于或等于$r_1$，所以$r_1$要从1开始。</p>
<p>$M_i$：表示对应第$i$层两非零元素之间的最大距离</p>
<p>$r_i$：对应的是第$i$层的膨胀系数</p>
<p>$M_n$：表示最后一次非零元素之间的最大距离等于2n</p>
<h5 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h5><ol>
<li><p><code>dilated_rates = [1, 2, 5]</code></p>
<ul>
<li><p><strong>统计实验像素的代码</strong></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from matplotlib.colors import LinearSegmentedColormap</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dilated_conv_one_pixel(center: (int, int),</span><br><span class="line">                           feature_map: np.ndarray,</span><br><span class="line">                           k: int = 3,</span><br><span class="line">                           r: int = 1,</span><br><span class="line">                           v: int = 1):</span><br><span class="line">    """</span><br><span class="line">    膨胀卷积核中心在指定坐标center处时，统计哪些像素被利用到，</span><br><span class="line">    并在利用到的像素位置处加上增量v</span><br><span class="line">    Args:</span><br><span class="line">        center: 膨胀卷积核中心的坐标</span><br><span class="line">        feature_map: 记录每个像素使用次数的特征图</span><br><span class="line">        k: 膨胀卷积核的kernel大小</span><br><span class="line">        r: 膨胀卷积的dilation rate</span><br><span class="line">        v: 使用次数增量</span><br><span class="line">    """</span><br><span class="line">    assert divmod(3, 2)[1] == 1</span><br><span class="line"></span><br><span class="line">    # left-top: (x, y)</span><br><span class="line">    left_top = (center[0] - ((k - 1) // 2) * r, center[1] - ((k - 1) // 2) * r)</span><br><span class="line">    for i in range(k):</span><br><span class="line">        for j in range(k):</span><br><span class="line">            feature_map[left_top[1] + i * r][left_top[0] + j * r] += v</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dilated_conv_all_map(dilated_map: np.ndarray,</span><br><span class="line">                         k: int = 3,</span><br><span class="line">                         r: int = 1):</span><br><span class="line">    """</span><br><span class="line">    根据输出特征矩阵中哪些像素被使用以及使用次数，</span><br><span class="line">    配合膨胀卷积k和r计算输入特征矩阵哪些像素被使用以及使用次数</span><br><span class="line">    Args:</span><br><span class="line">        dilated_map: 记录输出特征矩阵中每个像素被使用次数的特征图</span><br><span class="line">        k: 膨胀卷积核的kernel大小</span><br><span class="line">        r: 膨胀卷积的dilation rate</span><br><span class="line">    """</span><br><span class="line">    new_map = np.zeros_like(dilated_map)</span><br><span class="line">    for i in range(dilated_map.shape[0]):</span><br><span class="line">        for j in range(dilated_map.shape[1]):</span><br><span class="line">            if dilated_map[i][j] &gt; 0:</span><br><span class="line">                dilated_conv_one_pixel((j, i), new_map, k=k, r=r, v=dilated_map[i][j])</span><br><span class="line"></span><br><span class="line">    return new_map</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot_map(matrix: np.ndarray):</span><br><span class="line">    plt.figure()</span><br><span class="line"></span><br><span class="line">    c_list = ['white', 'blue', 'red']</span><br><span class="line">    new_cmp = LinearSegmentedColormap.from_list('chaos', c_list)</span><br><span class="line">    plt.imshow(matrix, cmap=new_cmp)</span><br><span class="line"></span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    ax.set_xticks(np.arange(-0.5, matrix.shape[1], 1), minor=True)</span><br><span class="line">    ax.set_yticks(np.arange(-0.5, matrix.shape[0], 1), minor=True)</span><br><span class="line"></span><br><span class="line">    # 显示color bar</span><br><span class="line">    plt.colorbar()</span><br><span class="line"></span><br><span class="line">    # 在图中标注数量</span><br><span class="line">    thresh = 5</span><br><span class="line">    for x in range(matrix.shape[1]):</span><br><span class="line">        for y in range(matrix.shape[0]):</span><br><span class="line">            # 注意这里的matrix[y, x]不是matrix[x, y]</span><br><span class="line">            info = int(matrix[y, x])</span><br><span class="line">            ax.text(x, y, info,</span><br><span class="line">                    verticalalignment='center',</span><br><span class="line">                    horizontalalignment='center',</span><br><span class="line">                    color="white" if info &gt; thresh else "black")</span><br><span class="line">    ax.grid(which='minor', color='black', linestyle='-', linewidth=1.5)</span><br><span class="line">    plt.show()</span><br><span class="line">    plt.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    # bottom to top</span><br><span class="line">    dilated_rates = [1, 2, 3]</span><br><span class="line">    # init feature map</span><br><span class="line">    size = 31</span><br><span class="line">    m = np.zeros(shape=(size, size), dtype=np.int32)</span><br><span class="line">    center = size // 2</span><br><span class="line">    m[center][center] = 1</span><br><span class="line">    # print(m)</span><br><span class="line">    # plot_map(m)</span><br><span class="line"></span><br><span class="line">    for index, dilated_r in enumerate(dilated_rates[::-1]):</span><br><span class="line">        new_map = dilated_conv_all_map(m, r=dilated_r)</span><br><span class="line">        m = new_map</span><br><span class="line">    print(m)</span><br><span class="line">    plot_map(m)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    main()</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p><strong>执行效果</strong>：</p>
<p><img src="image-20250828210735163.png" alt="image-20250828210735163"></p>
</li>
<li><p>解析：</p>
<p>很明显，已经将整个区域当中的所有的像素都利用到了，即不存在 gridding effect 的我呢提</p>
</li>
</ul>
</li>
<li><p><code>dilated_rates = [1, 2, 9]</code></p>
<ul>
<li><p>效果</p>
<p><img src="image-20250828211147137.png" alt="image-20250828211147137"></p>
</li>
<li><p>解析</p>
<p>很明显在整个区域内，非零元素之间的最大距离应该等于3，即元素与元素之间有两个或者两列零</p>
</li>
</ul>
</li>
</ol>
<h4 id="建议二："><a href="#建议二：" class="headerlink" title="建议二："></a>建议二：</h4><p><img src="image-20250828211918136.png" alt="image-20250828211918136"></p>
<p>但是以下情况仍存在gridding effect效应：</p>
<p><img src="image-20250828212114344.png" alt="image-20250828212114344"></p>
<p>实例：<code>dilated_rates = [2, 4, 8]</code></p>
<p><img src="image-20250828212212906.png" alt="image-20250828212212906"></p>
<p>可见非零元素之间还是存在零的，即高层当中依然没有使用到第一层当中的部分信息，故而这种情况是不行的。</p>
<h3 id="（五）效果对比"><a href="#（五）效果对比" class="headerlink" title="（五）效果对比"></a>（五）效果对比</h3><p><img src="image-20250828212417327.png" alt="image-20250828212417327"></p>
<h2 id="四、U-Net网络结构讲解（语义分割）"><a href="#四、U-Net网络结构讲解（语义分割）" class="headerlink" title="四、U-Net网络结构讲解（语义分割）"></a>四、U-Net网络结构讲解（语义分割）</h2><blockquote>
<p>论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1505.04597">https://arxiv.org/abs/1505.04597</a></p>
</blockquote>
<p><img src="image-20250829122819822.png" alt="image-20250829122819822"></p>
<h3 id="结构图示"><a href="#结构图示" class="headerlink" title="结构图示"></a>结构图示</h3><p><img src="image-20250831211132316.png" alt="image-20250831211132316"></p>
<ul>
<li>Encoder：U形左半部分（contracting path），特征提取以及下采样的部分</li>
<li>Decoder：U形右半部分（expansive path），解码以及通过上采样得到最终的分割图的分割图</li>
<li>图中每一个长条都表示一个特征层，箭头表示一种操作（图示右下角有标注箭头对应的操作类型）</li>
</ul>
<h3 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h3><ul>
<li><p>输入为572 * 572 的单通道图片</p>
</li>
<li><p>首先通过卷积核为3 <em> 3、激励函数为ReLU、步距为1、没有进行 padding 的卷积层，此后图像的高和宽都会减少，（572 </em> 572）-&gt;（570 <em> 570）- &gt;（568 </em> 568）</p>
</li>
</ul>
<blockquote id="fn_1">
<sup>1</sup>. 指的是提取特征的网络，其作用就是提取图片中的信息，共后面的网络使用。这些网络经常使用的是resnet、VGG等，而不是我们自己设计的网络，因为这些网络已经证明了在分类等问题上的特征提取能力是很强的。在用这些网络作为backbone的时候，都是直接加载官方已经训练好的模型参数，后面接着我们自己的网络。让网络的这两个部分同时进行训练，因为加载的backbone模型已经具有提取特征的能力了，在我们的训练过程中，会对他进行微调，使得其更适合于我们自己的任务。<a href="#reffn_1" title="Jump back to footnote [1] in the text."> ↩</a>
</blockquote>
<blockquote id="fn_2">
<sup>2</sup>. Understanding Convolution for Semantic Segmentation<a href="#reffn_2" title="Jump back to footnote [2] in the text."> ↩</a>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/93643523">【基础算法】六问透彻理解BN(Batch Normalization） - 知乎</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">SolitudeAB</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/09/16/LearningSchedule/Week7/">http://example.com/2025/09/16/LearningSchedule/Week7/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">SolitudeAB</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/504%E5%8C%BB%E5%AD%A6AI%E5%85%A5%E9%97%A8/">504医学AI入门</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/09/16/BasicKnowledge/BN/" title="BN（Batch Normalization）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">BN（Batch Normalization）</div></div><div class="info-2"><div class="info-item-1">一、什么是BN？Batch Normalization是2015年一篇论文中提出的数据归一化方法，往往用在深度神经网络中激活层之前。其作用可以加快模型训练时的收敛速度，使得模型训练过程更加稳定，避免梯度爆炸或者梯度消失。并且起到一定的正则化作用，几乎代替了Dropout。 二、BN核心公式是什么？如下：  Input:B=\{x_{1...m}\};\gamma ,\beta (parameters\ to\ be\ learned)\\ Output:\{y_i=BN_{\gamma ,\beta}(x_i)\}\\ u_{B} \leftarrow\frac{1}{m}\sum_{i=1}^{m}{x_i}\\ \sigma_{B}^2\leftarrow\frac{1}{m}\sum_{i=1}^m(x_i-\mu_B)^2\\ \tilde{x}_i\leftarrow\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}\\...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/27/LearningSchedule/Week2/" title="Week2"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-27</div><div class="info-item-2">Week2</div></div><div class="info-2"><div class="info-item-1">Opencv一、常见的图片格式及图片类型 图片格式  bmp：比较老的格式|不常见|无损-&gt;基本上无压缩|体积大|被淘汰  jpg（jpeg）：用最少的磁盘空间得到较好的图片质量  png：无损压缩的位图片形格式（首选）    图片类型：[ 黑白 ]  [ 彩色 ]   ​    【gif(动图) -&gt; 一帧一帧拿出来】  图片的本质：由像素点组成的一个矩阵，每个元素（像素点）都是在 [0,255] 之间  二、读取第一张黑白图片12import cv2import numpy as np  读取和展示  path：路径 0：代表灰度图 1：彩色图  12345678path = r"./R-C.jpg"img = cv2.imread(path,0)print(type(img))print(img.shape)print(img)cv2.imshow('image', img)cv2.waitKey()cv2.destroyAllWindows()  需要注意的是这里的cv2.imshow('image',...</div></div></div></a><a class="pagination-related" href="/2025/07/20/LearningSchedule/Week1/" title="Week1"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-20</div><div class="info-item-2">Week1</div></div><div class="info-2"><div class="info-item-1">语义分割 学习视频 语义分割前言_哔哩哔哩_bilibili  一、前言目标：  [x] 什么是语义分割 [x] 暂定的学习规划 [x] 语义分割任务常见数据集格式 [x] 语义分割得到结果的具体形式 [x] 语义分割常见评价标准 [x] 语义分割标注工具  1. 常见分割任务 语义分割（FCN）：对每一个像素进行分类  实例分割（Mask R-CNN）：针对同一个类别的不同目标也采用不同颜色进行分类，结果更精细，只关注目标背景  全景分割（Panoptic FPN）语义 + 实例 + 背景划分    精细程度逐级递增   2. pytorch 官方提供的语义分割网络 3. 语义分割任务常见数据集格式 Pascal VOC  PASCAL VOC2012数据集介绍_pascal voc 2012-CSDN博客  语义分割中提供的是png图片（记录每个像素所属的一个类别信息），这个png图片使用调色板的模式进行存储。 图片（第二张图片）实际是一个一通道的图片（黑白图片），但看到的确实彩色的。 用 python 的 Pillow 去读取 png...</div></div></div></a><a class="pagination-related" href="/2025/08/10/LearningSchedule/Week4/" title="Week4"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-10</div><div class="info-item-2">Week4</div></div><div class="info-2"><div class="info-item-1">Opencv（二）一、图像基础知识复习 图像是由像素构成的 像素点的多少决定了图片的质量（相同图片大小，像素点越多，单个像素点越小，图片质量越好）   图像的分类   二值图像：像素点非0即1   灰度图像：像素点有256个结果   彩色图像：由三通道（三原色RGB）进行叠加的图像     Opencv读取彩色图像的特点  读取结果：BGR（注意顺序）  每个像素点由BGR三个分量构成 例：（245，168，200）-&gt; B：245 、G：168、R：200     二、灰度图片像素的选取与修改 源码 123456789101112131415161718192021import cv2gray_img = cv2.imread(r"/home/jiax/workspace/Python Learning/Opencv-course/R-C.jpg", 0)cv2.imshow('gray_img', gray_img)#...</div></div></div></a><a class="pagination-related" href="/2025/08/03/LearningSchedule/Week3/" title="Week3"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-03</div><div class="info-item-2">Week3</div></div><div class="info-2"><div class="info-item-1">Opencv（二） 上一周学到彩色图片像素点的统计，这一周就从纯黑纯白图片像素点统计开始  代码 1234567891011121314import cv2# 读取图片（默认以BGR格式加载）image = cv2.imread('image.jpg')# 查看矩阵内容print(image)  # 直接打印整个矩阵print(image.shape)  # 打印矩阵形状：(高度, 宽度, 通道数)# 查看特定像素值（例如第10行第20列的BGR值）print(image[10, 20])  # 输出格式：[B, G, R]# 查看部分矩阵（例如前10行前10列）print(image[:10, :10])   一、纯黑纯白图片像素点统计 以下为纯白图片(1080, 2298, 3)的像素点统计结果，可与纯黑图片做比对   不存在纯黑的图片（或者计算机很难实现），以下图片是(650, 650,...</div></div></div></a><a class="pagination-related" href="/2025/08/17/LearningSchedule/Week5/" title="Week5"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-17</div><div class="info-item-2">Week5</div></div><div class="info-2"><div class="info-item-1">图像处理方法一、Sobel算子 OpenCV 图像处理之膨胀与腐蚀 | SolitudeAB  （一）什么是Sobel算子？ Sobel 算子是图像一种图像边缘   图像边缘检测重要算子之一  与梯度密度密不可分 -&gt; 目的：图像边缘检测的方法，本质是==梯度运算==   （二）什么情况下会产生梯度？利用 3 * 3 的卷积核放在二值图像中有三种位置关系，如下   全黑全白的像素值是相同的，只有在边缘部位时会有梯度产生。所有，梯度是进行边缘你检测的一个核心(边缘的梯度：255 - 0 = 255)    （三）Sobel 算子原理 遍历过程  卷积核顺序放到原图上    卷积核固定（中间列都是0）  卷积核中心位置在中间4x3区域内（对于边缘位置，卷积核暂时无法顾及到）  但是卷积核的核心无法顾及到原图像的边缘，如下   解决方法：  法一：边缘列（行）取均值或均值  法二（官方给的理论可能性）：paddng（边缘加一行 ”补0” ）   padding为0不改变原图像，此法可以顾及到每一个像素点       梯度计算  利用3  3 的卷积核与原图上顺序遍历的3 ...</div></div></div></a><a class="pagination-related" href="/2025/08/24/LearningSchedule/Week6/" title="Week6"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-24</div><div class="info-item-2">Week6</div></div><div class="info-2"><div class="info-item-1">模型基础一、语义分割概念 学习视频 语义分割前言_哔哩哔哩_bilibili  目标：  什么是语义分割 暂定的学习规划 语义分割任务常见数据集格式 语义分割得到结果的具体形式 语义分割常见评价标准 语义分割标注工具 （一）常见分割任务 语义分割（FCN）：对每一个像素进行分类  实例分割（Mask R-CNN）：针对同一个类别的不同目标也采用不同颜色进行分类，结果更精细，只关注目标背景  全景分割（Panoptic FPN）语义 + 实例 + 背景划分  精细程度逐级递增   （二）pytorch 官方提供的语义分割网络     （三）语义分割任务常见数据集格式 Pascal VOC  PASCAL VOC2012数据集介绍_pascal voc 2012-CSDN博客  语义分割中提供的是png图片（记录每个像素所属的一个类别信息），这个png图片使用调色板的模式进行存储。 图片（第二张图片）实际是一个一通道的图片（黑白图片），但看到的确实彩色的。 用 python 的 Pillow 去读取 png...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info-name">SolitudeAB</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/SolitudeAB"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81Dilated-Convolution%E8%86%A8%E8%83%80%E5%8D%B7%E7%A7%AF%EF%BC%88%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">三、Dilated Convolution膨胀卷积（空洞卷积）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E4%B8%80%EF%BC%89%E8%86%A8%E8%83%80%E5%8D%B7%E7%A7%AF%E5%92%8C%E4%B8%80%E8%88%AC%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">1.0.1.</span> <span class="toc-text">（一）膨胀卷积和一般卷积的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E4%BA%8C%EF%BC%89%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E8%86%A8%E8%83%80%E5%8D%B7%E7%A7%AF%EF%BC%9F"><span class="toc-number">1.0.2.</span> <span class="toc-text">（二）为什么使用膨胀卷积？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E4%B8%89%EF%BC%89%E8%86%A8%E8%83%80%E5%8D%B7%E7%A7%AF%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="toc-number">1.0.3.</span> <span class="toc-text">（三）膨胀卷积的缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E5%9B%9B%EF%BC%89%E5%B8%B8%E8%A7%81%E7%9A%84Hybrid-Dilated-Convolution-HDC-%E8%86%A8%E8%83%80%E5%9B%A0%E5%AD%90%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%87%86%E5%88%99"><span class="toc-number">1.0.4.</span> <span class="toc-text">（四）常见的Hybrid Dilated Convolution (HDC)膨胀因子的设计准则</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BB%BA%E8%AE%AE%E4%B8%80%EF%BC%9A"><span class="toc-number">1.0.4.1.</span> <span class="toc-text">建议一：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B"><span class="toc-number">1.0.4.1.1.</span> <span class="toc-text">实例</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BB%BA%E8%AE%AE%E4%BA%8C%EF%BC%9A"><span class="toc-number">1.0.4.2.</span> <span class="toc-text">建议二：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E4%BA%94%EF%BC%89%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94"><span class="toc-number">1.0.5.</span> <span class="toc-text">（五）效果对比</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81U-Net%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AE%B2%E8%A7%A3%EF%BC%88%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%EF%BC%89"><span class="toc-number">1.1.</span> <span class="toc-text">四、U-Net网络结构讲解（语义分割）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%84%E5%9B%BE%E7%A4%BA"><span class="toc-number">1.1.1.</span> <span class="toc-text">结构图示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E8%BF%87%E7%A8%8B"><span class="toc-number">1.1.2.</span> <span class="toc-text">实现过程</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/16/LearningSchedule/Week7/" title="Week7">Week7</a><time datetime="2025-09-15T16:00:00.000Z" title="发表于 2025-09-16 00:00:00">2025-09-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/16/BasicKnowledge/BN/" title="BN（Batch Normalization）">BN（Batch Normalization）</a><time datetime="2025-09-15T16:00:00.000Z" title="发表于 2025-09-16 00:00:00">2025-09-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/16/BasicKnowledge/%E5%8D%B7%E7%A7%AF/" title="卷积">卷积</a><time datetime="2025-09-15T16:00:00.000Z" title="发表于 2025-09-16 00:00:00">2025-09-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/16/BasicKnowledge/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" title="卷积神经网络基础">卷积神经网络基础</a><time datetime="2025-09-15T16:00:00.000Z" title="发表于 2025-09-16 00:00:00">2025-09-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/16/BasicKnowledge/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E8%A1%A5%E5%85%85/" title="卷积神经网络基础补充">卷积神经网络基础补充</a><time datetime="2025-09-15T16:00:00.000Z" title="发表于 2025-09-16 00:00:00">2025-09-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">©2024 - 2025 By SolitudeAB</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><div class="js-pjax"></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>